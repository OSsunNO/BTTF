{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ae5cae",
   "metadata": {},
   "source": [
    "# Environment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "52d6ecec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c42c5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of GPU: 4\n",
      "Total GPU memory: 51.033931776 GB\n",
      "GPU ID: 0\n",
      "GPU Name: NVIDIA RTX A6000\n",
      "GPU Compute Capability: (8, 6)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_id = torch.cuda.current_device()\n",
    "    gpu_name = torch.cuda.get_device_name(gpu_id)\n",
    "    gpu_capability = torch.cuda.get_device_capability(gpu_id)\n",
    "    total_memory = torch.cuda.get_device_properties(gpu_id).total_memory\n",
    "    \n",
    "    print(f\"Total number of GPU: {torch.cuda.device_count()}\")  \n",
    "    print(f\"Total GPU memory: {total_memory / 1e9} GB\")\n",
    "    print(f\"GPU ID: {gpu_id}\")\n",
    "    print(f\"GPU Name: {gpu_name}\")\n",
    "    print(f\"GPU Compute Capability: {gpu_capability}\")\n",
    "else:\n",
    "    print(\"No GPU is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce3ac63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device: 0\n",
      "Device Name: NVIDIA RTX A6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "\n",
    "print(\"Current Device:\", torch.cuda.current_device())\n",
    "print(\"Device Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "322d4fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97c661c",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b45d7f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4c1215d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../dataset/national_illness.csv', index_col='date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c7012d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% WEIGHTED ILI</th>\n",
       "      <th>%UNWEIGHTED ILI</th>\n",
       "      <th>AGE 0-4</th>\n",
       "      <th>AGE 5-24</th>\n",
       "      <th>ILITOTAL</th>\n",
       "      <th>NUM. OF PROVIDERS</th>\n",
       "      <th>OT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-01-01</th>\n",
       "      <td>1.22262</td>\n",
       "      <td>1.16668</td>\n",
       "      <td>582</td>\n",
       "      <td>805</td>\n",
       "      <td>2060</td>\n",
       "      <td>754</td>\n",
       "      <td>176569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-08</th>\n",
       "      <td>1.33344</td>\n",
       "      <td>1.21650</td>\n",
       "      <td>683</td>\n",
       "      <td>872</td>\n",
       "      <td>2267</td>\n",
       "      <td>785</td>\n",
       "      <td>186355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-15</th>\n",
       "      <td>1.31929</td>\n",
       "      <td>1.13057</td>\n",
       "      <td>642</td>\n",
       "      <td>878</td>\n",
       "      <td>2176</td>\n",
       "      <td>831</td>\n",
       "      <td>192469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-22</th>\n",
       "      <td>1.49484</td>\n",
       "      <td>1.25246</td>\n",
       "      <td>728</td>\n",
       "      <td>1045</td>\n",
       "      <td>2599</td>\n",
       "      <td>863</td>\n",
       "      <td>207512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-29</th>\n",
       "      <td>1.47195</td>\n",
       "      <td>1.30237</td>\n",
       "      <td>823</td>\n",
       "      <td>1189</td>\n",
       "      <td>2907</td>\n",
       "      <td>909</td>\n",
       "      <td>223208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            % WEIGHTED ILI  %UNWEIGHTED ILI  AGE 0-4  AGE 5-24  ILITOTAL  \\\n",
       "date                                                                       \n",
       "2002-01-01         1.22262          1.16668      582       805      2060   \n",
       "2002-01-08         1.33344          1.21650      683       872      2267   \n",
       "2002-01-15         1.31929          1.13057      642       878      2176   \n",
       "2002-01-22         1.49484          1.25246      728      1045      2599   \n",
       "2002-01-29         1.47195          1.30237      823      1189      2907   \n",
       "\n",
       "            NUM. OF PROVIDERS      OT  \n",
       "date                                   \n",
       "2002-01-01                754  176569  \n",
       "2002-01-08                785  186355  \n",
       "2002-01-15                831  192469  \n",
       "2002-01-22                863  207512  \n",
       "2002-01-29                909  223208  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3f104fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% WEIGHTED ILI       float64\n",
      "%UNWEIGHTED ILI      float64\n",
      "AGE 0-4                int64\n",
      "AGE 5-24               int64\n",
      "ILITOTAL               int64\n",
      "NUM. OF PROVIDERS      int64\n",
      "OT                     int64\n",
      "dtype: object\n",
      "shape:  (966, 7)\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes)\n",
    "print('shape: ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "440732bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['OT']\n",
    "features = data.drop(['OT'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7e7099f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['DATE'] = features.index.strftime('%Y%m%d%H').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cb6a1e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2002-01-01', '2002-01-08', '2002-01-15', '2002-01-22',\n",
       "               '2002-01-29', '2002-02-05', '2002-02-12', '2002-02-19',\n",
       "               '2002-02-26', '2002-03-05',\n",
       "               ...\n",
       "               '2020-04-28', '2020-05-05', '2020-05-12', '2020-05-19',\n",
       "               '2020-05-26', '2020-06-02', '2020-06-09', '2020-06-16',\n",
       "               '2020-06-23', '2020-06-30'],\n",
       "              dtype='datetime64[ns]', name='date', length=966, freq=None)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c485d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)                           \n",
    "    np.random.seed(seed)                        \n",
    "    torch.manual_seed(seed)                     \n",
    "    torch.cuda.manual_seed(seed)                \n",
    "    torch.cuda.manual_seed_all(seed)            \n",
    "    torch.backends.cudnn.deterministic = True   \n",
    "    torch.backends.cudnn.benchmark = False      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ef112f",
   "metadata": {},
   "source": [
    "# Model Modification for Linear (Look-ahead Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e61b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Linear model with prediction-based augmentation (attach_pv)\n",
    "    \"\"\"\n",
    "    def __init__(self, configs):\n",
    "        super(Model, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.channels = configs.enc_in\n",
    "\n",
    "        \n",
    "        self.attach_pv = getattr(configs, \"attach_pv\", False)\n",
    "\n",
    "        \n",
    "        self.extra_len = self.pred_len // 3\n",
    "\n",
    "        \n",
    "        self.seq_len_aug = self.seq_len + (self.extra_len if self.attach_pv else 0)\n",
    "\n",
    "        self.individual = configs.individual\n",
    "\n",
    "        \n",
    "        if self.individual:\n",
    "            self.Linear = nn.ModuleList()\n",
    "            for i in range(self.channels):\n",
    "                self.Linear.append(nn.Linear(self.seq_len_aug, self.pred_len))\n",
    "        else:\n",
    "            self.Linear = nn.Linear(self.seq_len_aug, self.pred_len)\n",
    "\n",
    "\n",
    "    def forward(self, x, ground_truth=None):\n",
    "        \"\"\"\n",
    "        x: [B, L, C]\n",
    "        ground_truth: [B, L_gt, C] or None\n",
    "        \"\"\"\n",
    "        B, L, C = x.size()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.attach_pv and (ground_truth is not None):\n",
    "            \n",
    "            gt_part = ground_truth[:, :self.extra_len, :]  \n",
    "\n",
    "            \n",
    "            x = torch.cat([x, gt_part], dim=1)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.individual:\n",
    "            out = torch.zeros([B, self.pred_len, C], dtype=x.dtype).to(x.device)\n",
    "            for i in range(C):\n",
    "                out[:, :, i] = self.Linear[i](x[:, :, i])\n",
    "            return out\n",
    "\n",
    "        else:\n",
    "            \n",
    "            out = self.Linear(x.permute(0, 2, 1))\n",
    "            return out.permute(0, 2, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fc4b33",
   "metadata": {},
   "source": [
    "# Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf7230f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sequences: torch.Size([549, 104, 1])\n",
      "Train Labels:    torch.Size([549, 24, 1])\n",
      "Val Sequences:   torch.Size([74, 104, 1])\n",
      "Val Labels:      torch.Size([74, 24, 1])\n",
      "Test Sequences:  torch.Size([170, 104, 1])\n",
      "Test Labels:     torch.Size([170, 24, 1])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "target = data['OT'].values.reshape(-1, 1)  \n",
    "\n",
    "\n",
    "seq_len  = 104\n",
    "pred_len = 24\n",
    "\n",
    "\n",
    "total_len  = len(target)\n",
    "num_train  = int(total_len * 0.7)\n",
    "num_test   = int(total_len * 0.2)\n",
    "num_val    = total_len - num_train - num_test\n",
    "\n",
    "border1s = [\n",
    "    0,\n",
    "    num_train - seq_len,\n",
    "    total_len - num_test - seq_len\n",
    "]\n",
    "border2s = [\n",
    "    num_train,\n",
    "    num_train + num_val,\n",
    "    total_len\n",
    "]\n",
    "\n",
    "\n",
    "train = target[border1s[0]:border2s[0]]\n",
    "val   = target[border1s[1]:border2s[1]]\n",
    "test  = target[border1s[2]:border2s[2]]\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "val   = scaler.transform(val)\n",
    "test  = scaler.transform(test)\n",
    "\n",
    "\n",
    "def create_inout_sequences_univariate(data, seq_len, pred_len):\n",
    "    seqs = []\n",
    "    for i in range(len(data) - seq_len - pred_len + 1):\n",
    "        seq_x = data[i : i + seq_len]\n",
    "        seq_y = data[i + seq_len : i + seq_len + pred_len]\n",
    "        seqs.append((seq_x, seq_y))\n",
    "    return seqs\n",
    "\n",
    "train_data = create_inout_sequences_univariate(train, seq_len, pred_len)\n",
    "val_data   = create_inout_sequences_univariate(val,   seq_len, pred_len)\n",
    "test_data  = create_inout_sequences_univariate(test,  seq_len, pred_len)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_sequences = torch.tensor([x[0] for x in train_data]).float().to(device)\n",
    "train_labels    = torch.tensor([x[1] for x in train_data]).float().to(device)\n",
    "\n",
    "val_sequences   = torch.tensor([x[0] for x in val_data]).float().to(device)\n",
    "val_labels      = torch.tensor([x[1] for x in val_data]).float().to(device)\n",
    "\n",
    "test_sequences  = torch.tensor([x[0] for x in test_data]).float().to(device)\n",
    "test_labels     = torch.tensor([x[1] for x in test_data]).float().to(device)\n",
    "\n",
    "\n",
    "print(\"Train Sequences:\", train_sequences.shape)\n",
    "print(\"Train Labels:   \", train_labels.shape)\n",
    "print(\"Val Sequences:  \", val_sequences.shape)\n",
    "print(\"Val Labels:     \", val_labels.shape)\n",
    "print(\"Test Sequences: \", test_sequences.shape)\n",
    "print(\"Test Labels:    \", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d5b2857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a843049",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(train_sequences, train_labels)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "val_dataset = TensorDataset(val_sequences, val_labels)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "test_dataset = TensorDataset(test_sequences, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd0c4b1",
   "metadata": {},
   "source": [
    "# 1st Model Training (Early Stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aa8e4f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b9784a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating learning rate to 0.001\n",
      "Epoch 0 | Train Loss: 0.6823838800191879 | Val Loss: 0.29419268667697906\n",
      "Validation loss decreased (inf --> 0.294193).  Saving model ...\n",
      "Updating learning rate to 0.0005\n",
      "Epoch 1 | Train Loss: 0.3307967765463723 | Val Loss: 0.22692332168420157\n",
      "Validation loss decreased (0.294193 --> 0.226923).  Saving model ...\n",
      "Updating learning rate to 0.00025\n",
      "Epoch 2 | Train Loss: 0.27964923199680114 | Val Loss: 0.2108168601989746\n",
      "Validation loss decreased (0.226923 --> 0.210817).  Saving model ...\n",
      "Updating learning rate to 0.000125\n",
      "Epoch 3 | Train Loss: 0.26222767101393807 | Val Loss: 0.20356648166974387\n",
      "Validation loss decreased (0.210817 --> 0.203566).  Saving model ...\n",
      "Updating learning rate to 6.25e-05\n",
      "Epoch 4 | Train Loss: 0.25579850872357685 | Val Loss: 0.2003830373287201\n",
      "Validation loss decreased (0.203566 --> 0.200383).  Saving model ...\n",
      "Updating learning rate to 3.125e-05\n",
      "Epoch 5 | Train Loss: 0.25541077968147063 | Val Loss: 0.19928896923859915\n",
      "Validation loss decreased (0.200383 --> 0.199289).  Saving model ...\n",
      "Updating learning rate to 1.5625e-05\n",
      "Epoch 6 | Train Loss: 0.24664389590422311 | Val Loss: 0.1977891872326533\n",
      "Validation loss decreased (0.199289 --> 0.197789).  Saving model ...\n",
      "Updating learning rate to 7.8125e-06\n",
      "Epoch 7 | Train Loss: 0.24307207514842352 | Val Loss: 0.19757006565729776\n",
      "Validation loss decreased (0.197789 --> 0.197570).  Saving model ...\n",
      "Updating learning rate to 3.90625e-06\n",
      "Epoch 8 | Train Loss: 0.24362015393045214 | Val Loss: 0.1972997784614563\n",
      "Validation loss decreased (0.197570 --> 0.197300).  Saving model ...\n",
      "Updating learning rate to 1.953125e-06\n",
      "Epoch 9 | Train Loss: 0.2387611654897531 | Val Loss: 0.1971231053272883\n",
      "Validation loss decreased (0.197300 --> 0.197123).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "\n",
    "seq_len = 104\n",
    "pred_len = 24  \n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual, learning_rate, lradj, patience, save_path, attach_pv):\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len  \n",
    "        self.enc_in = enc_in\n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv = attach_pv\n",
    "\n",
    "configs = Configs(seq_len=seq_len, pred_len=pred_len, enc_in=1, individual=False,\n",
    "                   learning_rate=0.0005, lradj='type1',  patience=3, save_path=\"./model_ILI\", attach_pv=False) \n",
    "\n",
    "\n",
    "model = Model(configs).to(device)\n",
    "loss_function = nn.MSELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=configs.learning_rate)\n",
    "\n",
    "if not os.path.exists(configs.save_path):\n",
    "    os.makedirs(configs.save_path)\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model, path):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, path):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), os.path.join(path, 'checkpoint_ES.pth'))\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    if args.lradj == 'type1':\n",
    "        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "    elif args.lradj == 'type2':\n",
    "        lr_adjust = {\n",
    "            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "            10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "        }\n",
    "    elif args.lradj == '3':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 10 else args.learning_rate*0.1}\n",
    "    elif args.lradj == '4':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 15 else args.learning_rate*0.1}\n",
    "    elif args.lradj == '5':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 25 else args.learning_rate*0.1}\n",
    "    elif args.lradj == '6':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 5 else args.learning_rate*0.1}  \n",
    "\n",
    "    if epoch in lr_adjust.keys():\n",
    "        lr = lr_adjust[epoch]\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        print(f'Updating learning rate to {lr}')\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, val_dataloader, optimizer, loss_function, epochs, pred_len, args):\n",
    "    early_stopping = EarlyStopping(patience=args.patience, verbose=True)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        \n",
    "        adjust_learning_rate(optimizer, epoch, args)\n",
    "        \n",
    "        for batch_sequences, batch_labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            output = model(batch_sequences)\n",
    "            \n",
    "            \n",
    "            \n",
    "            output = output[:, -pred_len:, :]  \n",
    "            batch_labels = batch_labels[:, -pred_len:, :]  \n",
    "            \n",
    "            \n",
    "            assert output.shape == batch_labels.shape, f\"Output shape {output.shape} and batch_labels shape {batch_labels.shape} must match\"\n",
    "            \n",
    "            loss = loss_function(output, batch_labels)  \n",
    "            \n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        \n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_batch_sequences, val_batch_labels in val_dataloader:\n",
    "                val_output = model(val_batch_sequences)\n",
    "                val_output = val_output[:, -args.pred_len:, :]\n",
    "                val_batch_labels = val_batch_labels[:, -args.pred_len:, :]\n",
    "                \n",
    "                val_loss += loss_function(val_output, val_batch_labels).item()\n",
    "        \n",
    "        val_loss /= len(val_dataloader)\n",
    "\n",
    "        \n",
    "        print(f'Epoch {epoch} | Train Loss: {total_loss / len(dataloader)} | Val Loss: {val_loss}')\n",
    "        \n",
    "        \n",
    "        early_stopping(val_loss, model, args.save_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered. Stopping training.\")\n",
    "            break\n",
    "\n",
    "\n",
    "train_model(model, train_dataloader, val_dataloader, optimizer, loss_function, epochs=10, pred_len=configs.pred_len, args=configs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cbe912",
   "metadata": {},
   "source": [
    "# 1st Model Training (1 Epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddbd2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating learning rate to 0.001\n",
      "Epoch 0 | Train Loss: 0.5581811798943414 | Val Loss: 0.22393699487050375\n",
      "Model saved at epoch 1\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "seq_len = 104\n",
    "pred_len = 24  \n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual, learning_rate, lradj, patience, save_path, attach_pv):\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len  \n",
    "        self.enc_in = enc_in\n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv = attach_pv\n",
    "\n",
    "configs = Configs(seq_len=seq_len, pred_len=pred_len, enc_in=1, individual=False,\n",
    "                   learning_rate=0.0005, lradj='type1',  patience=3, save_path=\"./model_ILI\", attach_pv=False) \n",
    "\n",
    "\n",
    "model = Model(configs).to(device)\n",
    "loss_function = nn.MSELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=configs.learning_rate)\n",
    "\n",
    "if not os.path.exists(configs.save_path):\n",
    "    os.makedirs(configs.save_path)\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    if args.lradj == 'type1':\n",
    "        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "    elif args.lradj == 'type2':\n",
    "        lr_adjust = {\n",
    "            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "            10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "        }\n",
    "    elif args.lradj == '3':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 10 else args.learning_rate*0.1}\n",
    "    elif args.lradj == '4':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 15 else args.learning_rate*0.1}\n",
    "    elif args.lradj == '5':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 25 else args.learning_rate*0.1}\n",
    "    elif args.lradj == '6':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 5 else args.learning_rate*0.1}  \n",
    "\n",
    "    if epoch in lr_adjust.keys():\n",
    "        lr = lr_adjust[epoch]\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        print(f'Updating learning rate to {lr}')\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, val_dataloader, optimizer, loss_function, epochs, pred_len, args):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        if epoch == 1:\n",
    "            torch.save(model.state_dict(), os.path.join(args.save_path, 'checkpoint_1.pth'))\n",
    "            print(\"Model saved at epoch 1\")\n",
    "\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        \n",
    "        adjust_learning_rate(optimizer, epoch, args)\n",
    "        \n",
    "        for batch_sequences, batch_labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            output = model(batch_sequences)\n",
    "            \n",
    "            \n",
    "            \n",
    "            output = output[:, -pred_len:, :]  \n",
    "            batch_labels = batch_labels[:, -pred_len:, :]  \n",
    "            \n",
    "            \n",
    "            assert output.shape == batch_labels.shape, f\"Output shape {output.shape} and batch_labels shape {batch_labels.shape} must match\"\n",
    "            \n",
    "            loss = loss_function(output, batch_labels)  \n",
    "            \n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        \n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_batch_sequences, val_batch_labels in val_dataloader:\n",
    "                val_output = model(val_batch_sequences)\n",
    "                val_output = val_output[:, -args.pred_len:, :]\n",
    "                val_batch_labels = val_batch_labels[:, -args.pred_len:, :]\n",
    "                \n",
    "                val_loss += loss_function(val_output, val_batch_labels).item()\n",
    "        \n",
    "        val_loss /= len(val_dataloader)\n",
    "\n",
    "        \n",
    "        print(f'Epoch {epoch} | Train Loss: {total_loss / len(dataloader)} | Val Loss: {val_loss}')\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(args.save_path, f'checkpoint_{epochs}.pth'))\n",
    "    print(f\"Model saved at epoch {epochs}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "train_model(model, train_dataloader, val_dataloader, optimizer, loss_function, epochs=1, pred_len=configs.pred_len, args=configs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4752521c",
   "metadata": {},
   "source": [
    "# Perform Inference and Form Predicted Value (PV) Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7cbe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Predicting with model from epoch ES]\n",
      "Epoch ES | MSE: 1.6197344064712524 | MAE: 1.13153076171875\n",
      "\n",
      "[Predicting with model from epoch 1]\n",
      "Epoch 1 | MSE: 1.6609952449798584 | MAE: 1.0907728672027588\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "\n",
    "\n",
    "checkpoint_epochs = ['ES', 1]\n",
    "\n",
    "\n",
    "test_1st_results = {}\n",
    "\n",
    "for ckpt_epoch in checkpoint_epochs:\n",
    "    print(f'\\n[Predicting with model from epoch {ckpt_epoch}]')\n",
    "\n",
    "    \n",
    "    model_path = os.path.join(configs.save_path, f'checkpoint_{ckpt_epoch}.pth')\n",
    "    \n",
    "    model = Model(configs).to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_sequence, batch_label in test_dataloader:\n",
    "            batch_sequence = batch_sequence.float().to(device)\n",
    "            batch_label = batch_label.float().to(device)\n",
    "\n",
    "            output = model(batch_sequence)\n",
    "            output = output[:, -configs.pred_len:, :]\n",
    "            batch_label = batch_label[:, -configs.pred_len:, :]\n",
    "\n",
    "            predictions.append(output.detach().cpu().numpy())\n",
    "            actuals.append(batch_label.detach().cpu().numpy())\n",
    "\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)  \n",
    "    actuals = np.concatenate(actuals, axis=0)\n",
    "\n",
    "    \n",
    "    predictions_flatten = predictions.flatten()\n",
    "    actuals_flatten = actuals.flatten()\n",
    "\n",
    "    \n",
    "    mse = mean_squared_error(actuals_flatten, predictions_flatten)\n",
    "    mae = mean_absolute_error(actuals_flatten, predictions_flatten)\n",
    "\n",
    "    print(f'Epoch {ckpt_epoch} | MSE: {mse} | MAE: {mae}')\n",
    "\n",
    "    \n",
    "    num_samples = len(predictions_flatten) // configs.pred_len\n",
    "    test_pv = torch.tensor(\n",
    "        predictions_flatten.reshape(num_samples, configs.pred_len, 1),\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    \n",
    "    test_1st_results[ckpt_epoch] = {\n",
    "        f'mse_test_E{ckpt_epoch}': mse,\n",
    "        f'mae_test_E{ckpt_epoch}': mae,\n",
    "        f'test_pv_E{ckpt_epoch}': test_pv\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98562878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ES', 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1st_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed25e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Predicting with model from epoch ES]\n",
      "Epoch ES | MSE: 0.19474202394485474 | MAE: 0.3691202700138092\n",
      "\n",
      "[Predicting with model from epoch 1]\n",
      "Epoch 1 | MSE: 0.23640912771224976 | MAE: 0.3977566361427307\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "\n",
    "\n",
    "checkpoint_epochs = ['ES', 1]\n",
    "\n",
    "\n",
    "val_1st_results = {}\n",
    "\n",
    "for ckpt_epoch in checkpoint_epochs:\n",
    "    print(f'\\n[Predicting with model from epoch {ckpt_epoch}]')\n",
    "\n",
    "    \n",
    "    model_path = os.path.join(configs.save_path, f'checkpoint_{ckpt_epoch}.pth')\n",
    "    \n",
    "    model = Model(configs).to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_sequence, batch_label in val_dataloader:\n",
    "            batch_sequence = batch_sequence.float().to(device)\n",
    "            batch_label = batch_label.float().to(device)\n",
    "\n",
    "            output = model(batch_sequence)\n",
    "            output = output[:, -configs.pred_len:, :]\n",
    "            batch_label = batch_label[:, -configs.pred_len:, :]\n",
    "\n",
    "            predictions.append(output.detach().cpu().numpy())\n",
    "            actuals.append(batch_label.detach().cpu().numpy())\n",
    "\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)  \n",
    "    actuals = np.concatenate(actuals, axis=0)\n",
    "\n",
    "    \n",
    "    predictions_flatten = predictions.flatten()\n",
    "    actuals_flatten = actuals.flatten()\n",
    "\n",
    "    \n",
    "    mse = mean_squared_error(actuals_flatten, predictions_flatten)\n",
    "    mae = mean_absolute_error(actuals_flatten, predictions_flatten)\n",
    "\n",
    "    print(f'Epoch {ckpt_epoch} | MSE: {mse} | MAE: {mae}')\n",
    "\n",
    "    \n",
    "    num_samples = len(predictions_flatten) // configs.pred_len\n",
    "    val_pv = torch.tensor(\n",
    "        predictions_flatten.reshape(num_samples, configs.pred_len, 1),\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    \n",
    "    val_1st_results[ckpt_epoch] = {\n",
    "        f'mse_val_E{ckpt_epoch}': mse,\n",
    "        f'mae_val_E{ckpt_epoch}': mae,\n",
    "        f'val_pv_E{ckpt_epoch}': val_pv\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7796b0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Predicting with model from epoch ES]\n",
      "Epoch ES | MSE: 0.24496497213840485 | MAE: 0.39543667435646057\n",
      "\n",
      "[Predicting with model from epoch 1]\n",
      "Epoch 1 | MSE: 0.3498726487159729 | MAE: 0.4747239649295807\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "\n",
    "\n",
    "train_dataloader_infer = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "checkpoint_epochs = ['ES', 1]\n",
    "\n",
    "\n",
    "train_1st_results = {}\n",
    "\n",
    "for ckpt_epoch in checkpoint_epochs:\n",
    "    print(f'\\n[Predicting with model from epoch {ckpt_epoch}]')\n",
    "\n",
    "    \n",
    "    model_path = os.path.join(configs.save_path, f'checkpoint_{ckpt_epoch}.pth')\n",
    "    \n",
    "    model = Model(configs).to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_sequence, batch_label in train_dataloader_infer:\n",
    "            batch_sequence = batch_sequence.float().to(device)\n",
    "            batch_label = batch_label.float().to(device)\n",
    "\n",
    "            output = model(batch_sequence)\n",
    "            output = output[:, -configs.pred_len:, :]\n",
    "            batch_label = batch_label[:, -configs.pred_len:, :]\n",
    "\n",
    "            predictions.append(output.detach().cpu().numpy())\n",
    "            actuals.append(batch_label.detach().cpu().numpy())\n",
    "\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)  \n",
    "    actuals = np.concatenate(actuals, axis=0)\n",
    "\n",
    "    \n",
    "    predictions_flatten = predictions.flatten()\n",
    "    actuals_flatten = actuals.flatten()\n",
    "\n",
    "    \n",
    "    mse = mean_squared_error(actuals_flatten, predictions_flatten)\n",
    "    mae = mean_absolute_error(actuals_flatten, predictions_flatten)\n",
    "\n",
    "    print(f'Epoch {ckpt_epoch} | MSE: {mse} | MAE: {mae}')\n",
    "\n",
    "    \n",
    "    num_samples = len(predictions_flatten) // configs.pred_len\n",
    "    train_pv = torch.tensor(\n",
    "        predictions_flatten.reshape(num_samples, configs.pred_len, 1),\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    \n",
    "    train_1st_results[ckpt_epoch] = {\n",
    "        f'mse_train_E{ckpt_epoch}': mse,\n",
    "        f'mae_train_E{ckpt_epoch}': mae,\n",
    "        f'train_pv_E{ckpt_epoch}': train_pv\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c1c9fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sequences shape:  torch.Size([549, 104, 1])\n",
      "val_sequences shape:  torch.Size([74, 104, 1])\n",
      "test_sequences shape:  torch.Size([170, 104, 1])\n",
      "---------------------------------------------\n",
      "train_pv shape:  torch.Size([549, 24, 1])\n",
      "val_pv shape:  torch.Size([74, 24, 1])\n",
      "test_pv shape:  torch.Size([170, 24, 1])\n",
      "---------------------------------------------\n",
      "train_labels shape:  torch.Size([549, 24, 1])\n",
      "val_labels shape:  torch.Size([74, 24, 1])\n",
      "test_labels shape:  torch.Size([170, 24, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"train_sequences shape: \",train_sequences.shape)\n",
    "print(\"val_sequences shape: \",val_sequences.shape)\n",
    "print(\"test_sequences shape: \",test_sequences.shape)\n",
    "\n",
    "print('---------------------------------------------')\n",
    "\n",
    "print(\"train_pv shape: \",train_pv.shape)\n",
    "print(\"val_pv shape: \",val_pv.shape)\n",
    "print(\"test_pv shape: \",test_pv.shape)\n",
    "\n",
    "\n",
    "print('---------------------------------------------')\n",
    "\n",
    "print(\"train_labels shape: \",train_labels.shape)\n",
    "print(\"val_labels shape: \",val_labels.shape)\n",
    "print(\"test_labels shape: \",test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14675cb",
   "metadata": {},
   "source": [
    "# Segment Generation Function (sliding window-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53e810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_segments(predictions, labels, segment_length, stride=1):\n",
    "    \"\"\"\n",
    "    시퀀스에 슬라이딩 윈도우를 stride 간격으로 적용하여\n",
    "    (B, num_segments, segment_length, C) 형태로 반환합니다.\n",
    "\n",
    "    Args:\n",
    "        predictions: Tensor of shape (B, T, C)\n",
    "        labels: Tensor of shape (B, T, C)\n",
    "        segment_length: int, 각 세그먼트의 길이 (예: pred_len // 3)\n",
    "        stride: int, 슬라이딩 윈도우 stride 간격\n",
    "\n",
    "    Returns:\n",
    "        pred_segments: (B, num_segments, segment_length, C)\n",
    "        label_segments: (B, num_segments, segment_length, C)\n",
    "    \"\"\"\n",
    "    B, T, C = predictions.shape\n",
    "    num_segments = (T - segment_length) // stride + 1\n",
    "\n",
    "    pred_segments = []\n",
    "    label_segments = []\n",
    "\n",
    "    for i in range(0, T - segment_length + 1, stride):\n",
    "        pred_seg = predictions[:, i:i+segment_length, :]  \n",
    "        label_seg = labels[:, i:i+segment_length, :]      \n",
    "        pred_segments.append(pred_seg.unsqueeze(1))       \n",
    "        label_segments.append(label_seg.unsqueeze(1))\n",
    "\n",
    "    pred_segments = torch.cat(pred_segments, dim=1)       \n",
    "    label_segments = torch.cat(label_segments, dim=1)     \n",
    "\n",
    "    return pred_segments, label_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5668d2",
   "metadata": {},
   "source": [
    "# Segmentation for PV Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8640e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs.pred_len "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d392a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch ES] Train seg shape: torch.Size([549, 17, 8, 1]), Val: torch.Size([74, 17, 8, 1]), Test: torch.Size([170, 17, 8, 1])\n",
      "[Epoch 1] Train seg shape: torch.Size([549, 17, 8, 1]), Val: torch.Size([74, 17, 8, 1]), Test: torch.Size([170, 17, 8, 1])\n"
     ]
    }
   ],
   "source": [
    "segment_len = configs.pred_len // 3\n",
    "stride = 1  \n",
    "\n",
    "train_segments_by_epoch = {}\n",
    "val_segments_by_epoch = {}\n",
    "test_segments_by_epoch = {}\n",
    "\n",
    "for epoch in checkpoint_epochs:\n",
    "    train_pv = train_1st_results[epoch][f'train_pv_E{epoch}']  \n",
    "    val_pv = val_1st_results[epoch][f'val_pv_E{epoch}']        \n",
    "    test_pv = test_1st_results[epoch][f'test_pv_E{epoch}']     \n",
    "\n",
    "    \n",
    "    train_pred_segments, train_label_segments = create_sliding_segments(train_pv, train_labels, segment_len,stride)\n",
    "    val_pred_segments, val_label_segments = create_sliding_segments(val_pv, val_labels, segment_len, stride)\n",
    "    test_pred_segments, test_label_segments = create_sliding_segments(test_pv, test_labels, segment_len, stride)\n",
    "\n",
    "    train_segments_by_epoch[epoch] = {\n",
    "        f'train_pred_segments_E{epoch}': train_pred_segments,  \n",
    "        f'train_label_segments_E{epoch}': train_label_segments\n",
    "    }\n",
    "\n",
    "    val_segments_by_epoch[epoch] = {\n",
    "        f'val_pred_segments_E{epoch}': val_pred_segments,\n",
    "        f'val_label_segments_E{epoch}': val_label_segments\n",
    "    }\n",
    "\n",
    "    test_segments_by_epoch[epoch] = {\n",
    "        f'test_pred_segments_E{epoch}': test_pred_segments,\n",
    "        f'test_label_segments_E{epoch}': test_label_segments\n",
    "    }\n",
    "\n",
    "    \n",
    "    print(f\"[Epoch {epoch}] Train seg shape: {train_pred_segments.shape}, Val: {val_pred_segments.shape}, Test: {test_pred_segments.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c324c2",
   "metadata": {},
   "source": [
    "## Save 1st Performance Metrics, PV, and Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbf8d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All dictionaries saved successfully in ./saved_results\n"
     ]
    }
   ],
   "source": [
    "save_dir = './1st_results_ILI'  \n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "torch.save(train_1st_results, os.path.join(save_dir, 'train_1st_results.pt'))\n",
    "torch.save(val_1st_results, os.path.join(save_dir, 'val_1st_results.pt'))\n",
    "torch.save(test_1st_results, os.path.join(save_dir, 'test_1st_results.pt'))\n",
    "\n",
    "\n",
    "torch.save(train_segments_by_epoch, os.path.join(save_dir, 'train_segments_by_epoch.pt'))\n",
    "torch.save(val_segments_by_epoch, os.path.join(save_dir, 'val_segments_by_epoch.pt'))\n",
    "torch.save(test_segments_by_epoch, os.path.join(save_dir, 'test_segments_by_epoch.pt'))\n",
    "\n",
    "print(\"✅ All dictionaries saved successfully in ./saved_results\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e3850",
   "metadata": {},
   "source": [
    "# 2nd Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c40dc9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_segments_by_epoch = torch.load('./1st_results_ILI/train_segments_by_epoch.pt', weights_only=False)\n",
    "val_segments_by_epoch = torch.load('./1st_results_ILI/val_segments_by_epoch.pt', weights_only=False)\n",
    "test_segments_by_epoch = torch.load('./1st_results_ILI/test_segments_by_epoch.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c99eaced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ES', 1])\n",
      "dict_keys(['train_pred_segments_EES', 'train_label_segments_EES'])\n",
      "dict_keys(['train_pred_segments_E1', 'train_label_segments_E1'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_segments_by_epoch.keys())\n",
    "print(train_segments_by_epoch['ES'].keys())\n",
    "print(train_segments_by_epoch[1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df456ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_pred_segments_ES = train_segments_by_epoch['ES']['train_pred_segments_EES']  \n",
    "train_label_segments_ES = train_segments_by_epoch['ES']['train_label_segments_EES']\n",
    "val_pred_segments_ES = val_segments_by_epoch['ES']['val_pred_segments_EES']  \n",
    "val_label_segments_ES = val_segments_by_epoch['ES']['val_label_segments_EES']\n",
    "test_pred_segments_ES = test_segments_by_epoch['ES']['test_pred_segments_EES']  \n",
    "test_label_segments_ES = test_segments_by_epoch['ES']['test_label_segments_EES']\n",
    "\n",
    "\n",
    "train_pred_segments_E1 = train_segments_by_epoch[1]['train_pred_segments_E1']  \n",
    "train_label_segments_E1 = train_segments_by_epoch[1]['train_label_segments_E1']\n",
    "val_pred_segments_E1 = val_segments_by_epoch[1]['val_pred_segments_E1']  \n",
    "val_label_segments_E1 = val_segments_by_epoch[1]['val_label_segments_E1']\n",
    "test_pred_segments_E1 = test_segments_by_epoch[1]['test_pred_segments_E1']  \n",
    "test_label_segments_E1 = test_segments_by_epoch[1]['test_label_segments_E1']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aef16fe",
   "metadata": {},
   "source": [
    "## ES->1E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96d05c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== Segment 0 ===========\n",
      "[Segment 0] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 0] Training Time = 0.11 sec\n",
      "[Segment 0] GPU Memory Start = 17.93 MB\n",
      "[Segment 0] GPU Memory End   = 17.97 MB\n",
      "[Segment 0] GPU Peak Memory  = 19.01 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 1 ===========\n",
      "[Segment 1] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 1] Training Time = 0.08 sec\n",
      "[Segment 1] GPU Memory Start = 17.97 MB\n",
      "[Segment 1] GPU Memory End   = 17.98 MB\n",
      "[Segment 1] GPU Peak Memory  = 19.02 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 2 ===========\n",
      "[Segment 2] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 2] Training Time = 0.05 sec\n",
      "[Segment 2] GPU Memory Start = 17.98 MB\n",
      "[Segment 2] GPU Memory End   = 17.99 MB\n",
      "[Segment 2] GPU Peak Memory  = 19.03 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 3 ===========\n",
      "[Segment 3] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 3] Training Time = 0.05 sec\n",
      "[Segment 3] GPU Memory Start = 17.99 MB\n",
      "[Segment 3] GPU Memory End   = 17.97 MB\n",
      "[Segment 3] GPU Peak Memory  = 19.01 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 4 ===========\n",
      "[Segment 4] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 4] Training Time = 0.05 sec\n",
      "[Segment 4] GPU Memory Start = 17.97 MB\n",
      "[Segment 4] GPU Memory End   = 17.98 MB\n",
      "[Segment 4] GPU Peak Memory  = 19.02 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 5 ===========\n",
      "[Segment 5] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 5] Training Time = 0.06 sec\n",
      "[Segment 5] GPU Memory Start = 17.98 MB\n",
      "[Segment 5] GPU Memory End   = 17.99 MB\n",
      "[Segment 5] GPU Peak Memory  = 19.03 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 6 ===========\n",
      "[Segment 6] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 6] Training Time = 0.06 sec\n",
      "[Segment 6] GPU Memory Start = 17.99 MB\n",
      "[Segment 6] GPU Memory End   = 18.00 MB\n",
      "[Segment 6] GPU Peak Memory  = 19.04 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 7 ===========\n",
      "[Segment 7] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 7] Training Time = 0.03 sec\n",
      "[Segment 7] GPU Memory Start = 18.00 MB\n",
      "[Segment 7] GPU Memory End   = 18.01 MB\n",
      "[Segment 7] GPU Peak Memory  = 19.05 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 8 ===========\n",
      "[Segment 8] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 8] Training Time = 0.03 sec\n",
      "[Segment 8] GPU Memory Start = 18.01 MB\n",
      "[Segment 8] GPU Memory End   = 18.02 MB\n",
      "[Segment 8] GPU Peak Memory  = 19.06 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 9 ===========\n",
      "[Segment 9] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 9] Training Time = 0.02 sec\n",
      "[Segment 9] GPU Memory Start = 18.02 MB\n",
      "[Segment 9] GPU Memory End   = 18.03 MB\n",
      "[Segment 9] GPU Peak Memory  = 19.07 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 10 ===========\n",
      "[Segment 10] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 10] Training Time = 0.04 sec\n",
      "[Segment 10] GPU Memory Start = 18.03 MB\n",
      "[Segment 10] GPU Memory End   = 18.04 MB\n",
      "[Segment 10] GPU Peak Memory  = 19.08 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 11 ===========\n",
      "[Segment 11] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 11] Training Time = 0.04 sec\n",
      "[Segment 11] GPU Memory Start = 18.04 MB\n",
      "[Segment 11] GPU Memory End   = 18.05 MB\n",
      "[Segment 11] GPU Peak Memory  = 19.09 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 12 ===========\n",
      "[Segment 12] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 12] Training Time = 0.04 sec\n",
      "[Segment 12] GPU Memory Start = 18.05 MB\n",
      "[Segment 12] GPU Memory End   = 17.97 MB\n",
      "[Segment 12] GPU Peak Memory  = 19.01 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 13 ===========\n",
      "[Segment 13] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 13] Training Time = 0.04 sec\n",
      "[Segment 13] GPU Memory Start = 17.97 MB\n",
      "[Segment 13] GPU Memory End   = 17.98 MB\n",
      "[Segment 13] GPU Peak Memory  = 19.02 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 14 ===========\n",
      "[Segment 14] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 14] Training Time = 0.03 sec\n",
      "[Segment 14] GPU Memory Start = 17.98 MB\n",
      "[Segment 14] GPU Memory End   = 17.99 MB\n",
      "[Segment 14] GPU Peak Memory  = 19.03 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 15 ===========\n",
      "[Segment 15] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 15] Training Time = 0.04 sec\n",
      "[Segment 15] GPU Memory Start = 17.99 MB\n",
      "[Segment 15] GPU Memory End   = 18.00 MB\n",
      "[Segment 15] GPU Peak Memory  = 19.04 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 16 ===========\n",
      "[Segment 16] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 16] Training Time = 0.04 sec\n",
      "[Segment 16] GPU Memory Start = 18.00 MB\n",
      "[Segment 16] GPU Memory End   = 18.01 MB\n",
      "[Segment 16] GPU Peak Memory  = 19.05 MB\n",
      "\n",
      "============= Done =============\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "\n",
    "epo = 'ES'\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual,\n",
    "                 learning_rate, lradj, patience,\n",
    "                 save_path, attach_pv):\n",
    "        self.seq_len  = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in   = enc_in          \n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv    = attach_pv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "base_cfg = Configs(\n",
    "    seq_len          = 104 ,\n",
    "    pred_len         = 24,\n",
    "    enc_in           = 1,\n",
    "    individual       = True,\n",
    "    learning_rate    = 0.01,\n",
    "    lradj            = 'type1',\n",
    "    patience         = 3,\n",
    "    save_path        = f\"./model2_ILI_E{epo}_1E\",\n",
    "    attach_pv  = True,\n",
    "\n",
    ")\n",
    "Path(base_cfg.save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "for seg in range(len(train_pred_segments_ES[0])):\n",
    "    print(f\"\\n=========== Segment {seg} ===========\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    mem_start = torch.cuda.memory_allocated(device)\n",
    "\n",
    "    \n",
    "    tr_pv = train_pred_segments_ES[:, seg, :, :]   \n",
    "    va_pv = val_pred_segments_ES[:,  seg, :, :]\n",
    "\n",
    "    tr_ds = TensorDataset(train_sequences, train_labels, tr_pv)\n",
    "    va_ds = TensorDataset(val_sequences,   val_labels,   va_pv)\n",
    "    tr_dl = DataLoader(tr_ds, batch_size=32, shuffle=True)\n",
    "    va_dl = DataLoader(va_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "    \n",
    "    model = Model(base_cfg).to(device)\n",
    "    C     = model.channels                                    \n",
    "\n",
    "    opts = []\n",
    "    for c in range(C):\n",
    "        params = list(model.Linear[c].parameters())\n",
    "        opts.append(optim.Adam(params, lr=base_cfg.learning_rate))\n",
    "        path = Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{c}\"\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    active = set(range(C))            \n",
    "\n",
    "    \n",
    "    for epoch in range(1, 2):\n",
    "        if not active: break          \n",
    "\n",
    "        \n",
    "        model.train()\n",
    "        for c in active:                              \n",
    "            if base_cfg.lradj=='type1':\n",
    "                lr = base_cfg.learning_rate * 0.5**((epoch-1)//1)\n",
    "                for g in opts[c].param_groups: g['lr'] = lr\n",
    "\n",
    "        printed_tensor_info = False  \n",
    "\n",
    "        for xb, yb, pv in tr_dl:\n",
    "            xb, yb, pv = xb.float().to(device), yb.float().to(device), pv.float().to(device)\n",
    "\n",
    "            if not printed_tensor_info:\n",
    "                \n",
    "                xb_size = xb.numel() * xb.element_size() / 1024**2\n",
    "                yb_size = yb.numel() * yb.element_size() / 1024**2\n",
    "                pv_size = pv.numel() * pv.element_size() / 1024**2\n",
    "\n",
    "                \n",
    "                \n",
    "                num_batches = len(tr_dl)\n",
    "\n",
    "                \n",
    "                total_xb_MB = num_batches * xb_size\n",
    "                total_yb_MB = num_batches * yb_size\n",
    "                total_pv_MB = num_batches * pv_size\n",
    "                \n",
    "\n",
    "\n",
    "                print(f\"[Segment {seg}] Batch Size Info:\")\n",
    "                print(f\"  xb per batch = {xb_size:.4f} MB, total = {total_xb_MB:.4f} MB\")\n",
    "                print(f\"  yb per batch = {yb_size:.4f} MB, total = {total_yb_MB:.4f} MB\")\n",
    "                print(f\"  pv per batch = {pv_size:.4f} MB, total = {total_pv_MB:.4f} MB\")\n",
    "\n",
    "                printed_tensor_info = True\n",
    "\n",
    "\n",
    "            out = model(xb, pv)                       \n",
    "\n",
    "            loss_list = []\n",
    "            for c in active:\n",
    "                pred = out[:, -base_cfg.pred_len:, c]\n",
    "                tgt  = yb[:, -base_cfg.pred_len:, c]\n",
    "                loss_list.append(loss_fn(pred, tgt))\n",
    "\n",
    "            total = torch.stack(loss_list).sum()\n",
    "            for opt in opts:\n",
    "                if opt: opt.zero_grad()\n",
    "            total.backward()\n",
    "            for c in active:\n",
    "                opts[c].step()\n",
    "        \n",
    "    elapsed = time.time() - start_time\n",
    "    mem_end = torch.cuda.memory_allocated(device)\n",
    "    peak_mem = torch.cuda.max_memory_allocated(device)\n",
    "\n",
    "\n",
    "    print(f\"[Segment {seg}] Training Time = {elapsed:.2f} sec\")\n",
    "    print(f\"[Segment {seg}] GPU Memory Start = {mem_start/1024**2:.2f} MB\")\n",
    "    print(f\"[Segment {seg}] GPU Memory End   = {mem_end/1024**2:.2f} MB\")\n",
    "    print(f\"[Segment {seg}] GPU Peak Memory  = {peak_mem/1024**2:.2f} MB\")\n",
    "\n",
    "    print(f\"\\n============= Done =============\")\n",
    "\n",
    "    \n",
    "    torch.save(model.state_dict(),\n",
    "                Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{c}\" / \"checkpoint.pth\")\n",
    "    del model, opts; torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da22d0",
   "metadata": {},
   "source": [
    "## 1E->1E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1736b191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== Segment 0 ===========\n",
      "[Segment 0] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 0] Training Time = 0.11 sec\n",
      "[Segment 0] GPU Memory Start = 17.97 MB\n",
      "[Segment 0] GPU Memory End   = 17.97 MB\n",
      "[Segment 0] GPU Peak Memory  = 19.01 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 1 ===========\n",
      "[Segment 1] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 1] Training Time = 0.08 sec\n",
      "[Segment 1] GPU Memory Start = 17.97 MB\n",
      "[Segment 1] GPU Memory End   = 17.98 MB\n",
      "[Segment 1] GPU Peak Memory  = 19.02 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 2 ===========\n",
      "[Segment 2] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 2] Training Time = 0.09 sec\n",
      "[Segment 2] GPU Memory Start = 17.98 MB\n",
      "[Segment 2] GPU Memory End   = 17.99 MB\n",
      "[Segment 2] GPU Peak Memory  = 19.03 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 3 ===========\n",
      "[Segment 3] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 3] Training Time = 0.08 sec\n",
      "[Segment 3] GPU Memory Start = 17.99 MB\n",
      "[Segment 3] GPU Memory End   = 18.00 MB\n",
      "[Segment 3] GPU Peak Memory  = 19.04 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 4 ===========\n",
      "[Segment 4] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 4] Training Time = 0.08 sec\n",
      "[Segment 4] GPU Memory Start = 18.00 MB\n",
      "[Segment 4] GPU Memory End   = 18.01 MB\n",
      "[Segment 4] GPU Peak Memory  = 19.05 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 5 ===========\n",
      "[Segment 5] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 5] Training Time = 0.09 sec\n",
      "[Segment 5] GPU Memory Start = 18.01 MB\n",
      "[Segment 5] GPU Memory End   = 18.02 MB\n",
      "[Segment 5] GPU Peak Memory  = 19.06 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 6 ===========\n",
      "[Segment 6] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 6] Training Time = 0.09 sec\n",
      "[Segment 6] GPU Memory Start = 17.97 MB\n",
      "[Segment 6] GPU Memory End   = 17.98 MB\n",
      "[Segment 6] GPU Peak Memory  = 19.02 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 7 ===========\n",
      "[Segment 7] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 7] Training Time = 0.08 sec\n",
      "[Segment 7] GPU Memory Start = 17.98 MB\n",
      "[Segment 7] GPU Memory End   = 17.99 MB\n",
      "[Segment 7] GPU Peak Memory  = 19.03 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 8 ===========\n",
      "[Segment 8] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 8] Training Time = 0.08 sec\n",
      "[Segment 8] GPU Memory Start = 17.99 MB\n",
      "[Segment 8] GPU Memory End   = 18.00 MB\n",
      "[Segment 8] GPU Peak Memory  = 19.04 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 9 ===========\n",
      "[Segment 9] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 9] Training Time = 0.08 sec\n",
      "[Segment 9] GPU Memory Start = 18.00 MB\n",
      "[Segment 9] GPU Memory End   = 18.01 MB\n",
      "[Segment 9] GPU Peak Memory  = 19.05 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 10 ===========\n",
      "[Segment 10] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 10] Training Time = 0.08 sec\n",
      "[Segment 10] GPU Memory Start = 18.01 MB\n",
      "[Segment 10] GPU Memory End   = 18.02 MB\n",
      "[Segment 10] GPU Peak Memory  = 19.06 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 11 ===========\n",
      "[Segment 11] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 11] Training Time = 0.04 sec\n",
      "[Segment 11] GPU Memory Start = 18.02 MB\n",
      "[Segment 11] GPU Memory End   = 18.03 MB\n",
      "[Segment 11] GPU Peak Memory  = 19.07 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 12 ===========\n",
      "[Segment 12] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 12] Training Time = 0.05 sec\n",
      "[Segment 12] GPU Memory Start = 18.03 MB\n",
      "[Segment 12] GPU Memory End   = 18.04 MB\n",
      "[Segment 12] GPU Peak Memory  = 19.08 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 13 ===========\n",
      "[Segment 13] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 13] Training Time = 0.05 sec\n",
      "[Segment 13] GPU Memory Start = 18.04 MB\n",
      "[Segment 13] GPU Memory End   = 18.05 MB\n",
      "[Segment 13] GPU Peak Memory  = 19.09 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 14 ===========\n",
      "[Segment 14] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 14] Training Time = 0.05 sec\n",
      "[Segment 14] GPU Memory Start = 18.05 MB\n",
      "[Segment 14] GPU Memory End   = 18.06 MB\n",
      "[Segment 14] GPU Peak Memory  = 19.10 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 15 ===========\n",
      "[Segment 15] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 15] Training Time = 0.05 sec\n",
      "[Segment 15] GPU Memory Start = 18.06 MB\n",
      "[Segment 15] GPU Memory End   = 18.07 MB\n",
      "[Segment 15] GPU Peak Memory  = 19.12 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 16 ===========\n",
      "[Segment 16] Batch Size Info:\n",
      "  xb per batch = 0.0127 MB, total = 0.2285 MB\n",
      "  yb per batch = 0.0029 MB, total = 0.0527 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.0176 MB\n",
      "[Segment 16] Training Time = 0.04 sec\n",
      "[Segment 16] GPU Memory Start = 17.97 MB\n",
      "[Segment 16] GPU Memory End   = 17.98 MB\n",
      "[Segment 16] GPU Peak Memory  = 19.02 MB\n",
      "\n",
      "============= Done =============\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "epo = 1\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual,\n",
    "                 learning_rate, lradj, patience,\n",
    "                 save_path, attach_pv):\n",
    "        self.seq_len  = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in   = enc_in          \n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv    = attach_pv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "base_cfg = Configs(\n",
    "    seq_len          = 104 ,\n",
    "    pred_len         = 24,\n",
    "    enc_in           = 1,\n",
    "    individual       = True,\n",
    "    learning_rate    = 0.01,\n",
    "    lradj            = 'type1',\n",
    "    patience         = 3,\n",
    "    save_path        = f\"./model2_ILI_E{epo}_1E/\",\n",
    "    attach_pv  = True,\n",
    "\n",
    ")\n",
    "Path(base_cfg.save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "for seg in range(len(train_pred_segments_E1[0])):\n",
    "    print(f\"\\n=========== Segment {seg} ===========\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    mem_start = torch.cuda.memory_allocated(device)\n",
    "\n",
    "    \n",
    "    tr_pv = train_pred_segments_E1[:, seg, :, :]   \n",
    "    va_pv = val_pred_segments_E1[:,  seg, :, :]\n",
    "\n",
    "    tr_ds = TensorDataset(train_sequences, train_labels, tr_pv)\n",
    "    va_ds = TensorDataset(val_sequences,   val_labels,   va_pv)\n",
    "    tr_dl = DataLoader(tr_ds, batch_size=32, shuffle=True)\n",
    "    va_dl = DataLoader(va_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "    \n",
    "    model = Model(base_cfg).to(device)\n",
    "    C     = model.channels                                    \n",
    "\n",
    "    opts = []\n",
    "    for c in range(C):\n",
    "        params = list(model.Linear[c].parameters())\n",
    "        opts.append(optim.Adam(params, lr=base_cfg.learning_rate))\n",
    "        path = Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{c}\"\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    active = set(range(C))            \n",
    "\n",
    "    \n",
    "    for epoch in range(1, 2):\n",
    "        if not active: break          \n",
    "\n",
    "        \n",
    "        model.train()\n",
    "        for c in active:                              \n",
    "            if base_cfg.lradj=='type1':\n",
    "                lr = base_cfg.learning_rate * 0.5**((epoch-1)//1)\n",
    "                for g in opts[c].param_groups: g['lr'] = lr\n",
    "\n",
    "        printed_tensor_info = False\n",
    "        \n",
    "        for xb, yb, pv in tr_dl:\n",
    "            xb, yb, pv = xb.float().to(device), yb.float().to(device), pv.float().to(device)\n",
    "\n",
    "            if not printed_tensor_info:\n",
    "                \n",
    "                xb_size = xb.numel() * xb.element_size() / 1024**2\n",
    "                yb_size = yb.numel() * yb.element_size() / 1024**2\n",
    "                pv_size = pv.numel() * pv.element_size() / 1024**2\n",
    "\n",
    "                \n",
    "                \n",
    "                num_batches = len(tr_dl)\n",
    "\n",
    "                \n",
    "                total_xb_MB = num_batches * xb_size\n",
    "                total_yb_MB = num_batches * yb_size\n",
    "                total_pv_MB = num_batches * pv_size\n",
    "                \n",
    "\n",
    "\n",
    "                print(f\"[Segment {seg}] Batch Size Info:\")\n",
    "                print(f\"  xb per batch = {xb_size:.4f} MB, total = {total_xb_MB:.4f} MB\")\n",
    "                print(f\"  yb per batch = {yb_size:.4f} MB, total = {total_yb_MB:.4f} MB\")\n",
    "                print(f\"  pv per batch = {pv_size:.4f} MB, total = {total_pv_MB:.4f} MB\")\n",
    "\n",
    "                printed_tensor_info = True\n",
    "\n",
    "\n",
    "\n",
    "            out = model(xb, pv)                       \n",
    "\n",
    "            loss_list = []\n",
    "            for c in active:\n",
    "                pred = out[:, -base_cfg.pred_len:, c]\n",
    "                tgt  = yb[:, -base_cfg.pred_len:, c]\n",
    "                loss_list.append(loss_fn(pred, tgt))\n",
    "\n",
    "            total = torch.stack(loss_list).sum()\n",
    "            for opt in opts:\n",
    "                if opt: opt.zero_grad()\n",
    "            total.backward()\n",
    "            for c in active:\n",
    "                opts[c].step()\n",
    "\n",
    "        \n",
    "    elapsed = time.time() - start_time\n",
    "    mem_end = torch.cuda.memory_allocated(device)\n",
    "    peak_mem = torch.cuda.max_memory_allocated(device)\n",
    "\n",
    "\n",
    "    print(f\"[Segment {seg}] Training Time = {elapsed:.2f} sec\")\n",
    "    print(f\"[Segment {seg}] GPU Memory Start = {mem_start/1024**2:.2f} MB\")\n",
    "    print(f\"[Segment {seg}] GPU Memory End   = {mem_end/1024**2:.2f} MB\")\n",
    "    print(f\"[Segment {seg}] GPU Peak Memory  = {peak_mem/1024**2:.2f} MB\")\n",
    "\n",
    "    print(f\"\\n============= Done =============\")\n",
    "\n",
    "    \n",
    "    torch.save(model.state_dict(),\n",
    "                Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{c}\" / \"checkpoint.pth\")\n",
    "    del model, opts; torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9781d0",
   "metadata": {},
   "source": [
    "# 2nd Inference for Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1892e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_segments_by_epoch = torch.load('./1st_results_ILI/train_segments_by_epoch.pt', weights_only=False)\n",
    "val_segments_by_epoch = torch.load('./1st_results_ILI/val_segments_by_epoch.pt', weights_only=False)\n",
    "test_segments_by_epoch = torch.load('./1st_results_ILI/test_segments_by_epoch.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd3aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_segments_ES = train_segments_by_epoch['ES']['train_pred_segments_EES']  \n",
    "train_label_segments_ES = train_segments_by_epoch['ES']['train_label_segments_EES']\n",
    "val_pred_segments_ES = val_segments_by_epoch['ES']['val_pred_segments_EES']  \n",
    "val_label_segments_ES = val_segments_by_epoch['ES']['val_label_segments_EES']\n",
    "test_pred_segments_ES = test_segments_by_epoch['ES']['test_pred_segments_EES']  \n",
    "test_label_segments_ES = test_segments_by_epoch['ES']['test_label_segments_EES']\n",
    "\n",
    "\n",
    "train_pred_segments_E1 = train_segments_by_epoch[1]['train_pred_segments_E1']  \n",
    "train_label_segments_E1 = train_segments_by_epoch[1]['train_label_segments_E1']\n",
    "val_pred_segments_E1 = val_segments_by_epoch[1]['val_pred_segments_E1']  \n",
    "val_label_segments_E1 = val_segments_by_epoch[1]['val_label_segments_E1']\n",
    "test_pred_segments_E1 = test_segments_by_epoch[1]['test_pred_segments_E1']  \n",
    "test_label_segments_E1 = test_segments_by_epoch[1]['test_label_segments_E1']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a58c5",
   "metadata": {},
   "source": [
    "## ES->1E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cc0945",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7783ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual,\n",
    "                 learning_rate, lradj, patience,\n",
    "                 save_path, attach_pv):\n",
    "        self.seq_len  = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in   = enc_in          \n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv    = attach_pv\n",
    "\n",
    "\n",
    "\n",
    "base_cfg = Configs(\n",
    "    pred_len         = 24,\n",
    "    seq_len          = 104 ,\n",
    "    enc_in           = 1,\n",
    "    individual       = True,\n",
    "    learning_rate    = 0.01,\n",
    "    lradj            = 'type1',\n",
    "    patience         = 3,\n",
    "    save_path        = \"./model2_ILI_EES_1E\",\n",
    "    attach_pv  = True,\n",
    ")\n",
    "Path(base_cfg.save_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d172e7",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4799a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "―――― Inference  |  Segment 0 ――――\n",
      "  seg0-ch0  MSE:0.12478465586900711  MAE:0.27459514141082764\n",
      "▶ seg0  mean  MSE:0.12478465586900711  MAE:0.27459514141082764\n",
      "\n",
      "―――― Inference  |  Segment 1 ――――\n",
      "  seg1-ch0  MSE:0.18828940391540527  MAE:0.3553542494773865\n",
      "▶ seg1  mean  MSE:0.18828940391540527  MAE:0.3553542494773865\n",
      "\n",
      "―――― Inference  |  Segment 2 ――――\n",
      "  seg2-ch0  MSE:0.1458132565021515  MAE:0.3044063150882721\n",
      "▶ seg2  mean  MSE:0.1458132565021515  MAE:0.3044063150882721\n",
      "\n",
      "―――― Inference  |  Segment 3 ――――\n",
      "  seg3-ch0  MSE:0.13236959278583527  MAE:0.28297555446624756\n",
      "▶ seg3  mean  MSE:0.13236959278583527  MAE:0.28297555446624756\n",
      "\n",
      "―――― Inference  |  Segment 4 ――――\n",
      "  seg4-ch0  MSE:0.15361762046813965  MAE:0.31207138299942017\n",
      "▶ seg4  mean  MSE:0.15361762046813965  MAE:0.31207138299942017\n",
      "\n",
      "―――― Inference  |  Segment 5 ――――\n",
      "  seg5-ch0  MSE:0.13820680975914001  MAE:0.2987566292285919\n",
      "▶ seg5  mean  MSE:0.13820680975914001  MAE:0.2987566292285919\n",
      "\n",
      "―――― Inference  |  Segment 6 ――――\n",
      "  seg6-ch0  MSE:0.10806738585233688  MAE:0.25865253806114197\n",
      "▶ seg6  mean  MSE:0.10806738585233688  MAE:0.25865253806114197\n",
      "\n",
      "―――― Inference  |  Segment 7 ――――\n",
      "  seg7-ch0  MSE:0.1138397604227066  MAE:0.2664267122745514\n",
      "▶ seg7  mean  MSE:0.1138397604227066  MAE:0.2664267122745514\n",
      "\n",
      "―――― Inference  |  Segment 8 ――――\n",
      "  seg8-ch0  MSE:0.1456475853919983  MAE:0.3021526038646698\n",
      "▶ seg8  mean  MSE:0.1456475853919983  MAE:0.3021526038646698\n",
      "\n",
      "―――― Inference  |  Segment 9 ――――\n",
      "  seg9-ch0  MSE:0.12117372453212738  MAE:0.27775412797927856\n",
      "▶ seg9  mean  MSE:0.12117372453212738  MAE:0.27775412797927856\n",
      "\n",
      "―――― Inference  |  Segment 10 ――――\n",
      "  seg10-ch0  MSE:0.12088354676961899  MAE:0.27827003598213196\n",
      "▶ seg10  mean  MSE:0.12088354676961899  MAE:0.27827003598213196\n",
      "\n",
      "―――― Inference  |  Segment 11 ――――\n",
      "  seg11-ch0  MSE:0.14979073405265808  MAE:0.3074217736721039\n",
      "▶ seg11  mean  MSE:0.14979073405265808  MAE:0.3074217736721039\n",
      "\n",
      "―――― Inference  |  Segment 12 ――――\n",
      "  seg12-ch0  MSE:0.1113584041595459  MAE:0.26375558972358704\n",
      "▶ seg12  mean  MSE:0.1113584041595459  MAE:0.26375558972358704\n",
      "\n",
      "―――― Inference  |  Segment 13 ――――\n",
      "  seg13-ch0  MSE:0.13667578995227814  MAE:0.29064977169036865\n",
      "▶ seg13  mean  MSE:0.13667578995227814  MAE:0.29064977169036865\n",
      "\n",
      "―――― Inference  |  Segment 14 ――――\n",
      "  seg14-ch0  MSE:0.13747160136699677  MAE:0.2924034595489502\n",
      "▶ seg14  mean  MSE:0.13747160136699677  MAE:0.2924034595489502\n",
      "\n",
      "―――― Inference  |  Segment 15 ――――\n",
      "  seg15-ch0  MSE:0.11920347809791565  MAE:0.26392078399658203\n",
      "▶ seg15  mean  MSE:0.11920347809791565  MAE:0.26392078399658203\n",
      "\n",
      "―――― Inference  |  Segment 16 ――――\n",
      "  seg16-ch0  MSE:0.10887152701616287  MAE:0.2591340243816376\n",
      "▶ seg16  mean  MSE:0.10887152701616287  MAE:0.2591340243816376\n",
      "\n",
      "seg10 ch0 MSE : 0.12088355\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import r2_score\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "C        = 1                                \n",
    "P        = base_cfg.pred_len                \n",
    "seg_cnt  = 17\n",
    "batch_sz = 32\n",
    "\n",
    "results2_ILI_ES_val_1E = {}  \n",
    "\n",
    "for seg in range(seg_cnt):\n",
    "    print(f\"\\n―――― Inference  |  Segment {seg} ――――\")\n",
    "\n",
    "    \n",
    "    pv = val_pred_segments_ES[:, seg, :, :]         \n",
    "    ds = TensorDataset(val_sequences, val_labels, pv) \n",
    "    dl = DataLoader(ds, batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "    \n",
    "    pred_ch, true_ch, metrics = [], [], {}\n",
    "\n",
    "    \n",
    "    for ch in range(C):\n",
    "        ckpt = Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{ch}\" / \"checkpoint.pth\"\n",
    "        if not ckpt.exists():\n",
    "            print(f\"[Warn] seg{seg}-ch{ch} ckpt 없음 → skip\");  continue\n",
    "\n",
    "        \n",
    "        model = Model(base_cfg).to(device)\n",
    "        model.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        preds, trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, pv_batch in dl:                 \n",
    "                xb  = xb.float().to(device)\n",
    "                yb  = yb.float()      \n",
    "                pv_ = pv_batch.float().to(device)\n",
    "\n",
    "                out = model(xb, pv_)                     \n",
    "                preds.append(out[:, -P:, ch].cpu())\n",
    "                trues.append(yb[:, -P:, ch])\n",
    "\n",
    "        preds = torch.cat(preds, 0)     \n",
    "        trues = torch.cat(trues, 0)\n",
    "        pred_ch.append(preds)\n",
    "        true_ch.append(trues)\n",
    "\n",
    "        \n",
    "        p, t = preds.reshape(-1).cpu().numpy(), trues.reshape(-1).cpu().numpy()\n",
    "        mse  = np.mean((p - t)**2)\n",
    "        mae  = np.mean(np.abs(p - t))\n",
    "        metrics[ch] = (mse, mae)\n",
    "\n",
    "        print(f\"  seg{seg}-ch{ch}  MSE:{mse}  MAE:{mae}\")\n",
    "\n",
    "        del model; torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "    pred_all = torch.stack(pred_ch,  dim=2)   \n",
    "    true_all = torch.stack(true_ch,  dim=2)\n",
    "\n",
    "    \n",
    "    mse_avg = np.mean([m for m,_ in metrics.values()])\n",
    "    mae_avg = np.mean([a for _,a in metrics.values()])\n",
    "    print(f\"▶ seg{seg}  mean  MSE:{mse_avg}  MAE:{mae_avg}\")\n",
    "\n",
    "    \n",
    "    results2_ILI_ES_val_1E[seg] = {\n",
    "        \"pred2_ES_val_1E\"    : pred_all,   \n",
    "        \"true2_ES_val_1E\"    : true_all,   \n",
    "        \"metrics2_ES_val_1E\" : metrics     \n",
    "    }\n",
    "\n",
    "\n",
    "seg10_ch0_mse = results2_ILI_ES_val_1E[10][\"metrics2_ES_val_1E\"][0][0]\n",
    "print(\"\\nseg10 ch0 MSE :\", seg10_ch0_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59447756",
   "metadata": {},
   "source": [
    "## 1E->1E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5967f3d",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cc99fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual,\n",
    "                 learning_rate, lradj, patience,\n",
    "                 save_path, attach_pv):\n",
    "        self.seq_len  = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in   = enc_in          \n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv    = attach_pv\n",
    "\n",
    "\n",
    "\n",
    "base_cfg = Configs(\n",
    "    pred_len         = 24,\n",
    "    seq_len          = 104 ,\n",
    "    enc_in           = 1,\n",
    "    individual       = True,\n",
    "    learning_rate    = 0.01,\n",
    "    lradj            = 'type1',\n",
    "    patience         = 3,\n",
    "    save_path        = \"./model2_ILI_E1_1E\",\n",
    "    attach_pv  = True,\n",
    "\n",
    ")\n",
    "Path(base_cfg.save_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2442c3de",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75844a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "―――― Inference  |  Segment 0 ――――\n",
      "  seg0-ch0  MSE:0.1412416696548462  MAE:0.2955261766910553\n",
      "▶ seg0  mean  MSE:0.1412416696548462  MAE:0.2955261766910553\n",
      "\n",
      "―――― Inference  |  Segment 1 ――――\n",
      "  seg1-ch0  MSE:0.1259918510913849  MAE:0.2818455696105957\n",
      "▶ seg1  mean  MSE:0.1259918510913849  MAE:0.2818455696105957\n",
      "\n",
      "―――― Inference  |  Segment 2 ――――\n",
      "  seg2-ch0  MSE:0.1386192888021469  MAE:0.2960178554058075\n",
      "▶ seg2  mean  MSE:0.1386192888021469  MAE:0.2960178554058075\n",
      "\n",
      "―――― Inference  |  Segment 3 ――――\n",
      "  seg3-ch0  MSE:0.13771328330039978  MAE:0.29401105642318726\n",
      "▶ seg3  mean  MSE:0.13771328330039978  MAE:0.29401105642318726\n",
      "\n",
      "―――― Inference  |  Segment 4 ――――\n",
      "  seg4-ch0  MSE:0.14374977350234985  MAE:0.30189022421836853\n",
      "▶ seg4  mean  MSE:0.14374977350234985  MAE:0.30189022421836853\n",
      "\n",
      "―――― Inference  |  Segment 5 ――――\n",
      "  seg5-ch0  MSE:0.13375601172447205  MAE:0.2904060184955597\n",
      "▶ seg5  mean  MSE:0.13375601172447205  MAE:0.2904060184955597\n",
      "\n",
      "―――― Inference  |  Segment 6 ――――\n",
      "  seg6-ch0  MSE:0.09520833194255829  MAE:0.23527471721172333\n",
      "▶ seg6  mean  MSE:0.09520833194255829  MAE:0.23527471721172333\n",
      "\n",
      "―――― Inference  |  Segment 7 ――――\n",
      "  seg7-ch0  MSE:0.11303267627954483  MAE:0.2685169279575348\n",
      "▶ seg7  mean  MSE:0.11303267627954483  MAE:0.2685169279575348\n",
      "\n",
      "―――― Inference  |  Segment 8 ――――\n",
      "  seg8-ch0  MSE:0.10542264580726624  MAE:0.2567225992679596\n",
      "▶ seg8  mean  MSE:0.10542264580726624  MAE:0.2567225992679596\n",
      "\n",
      "―――― Inference  |  Segment 9 ――――\n",
      "  seg9-ch0  MSE:0.10719612240791321  MAE:0.25784915685653687\n",
      "▶ seg9  mean  MSE:0.10719612240791321  MAE:0.25784915685653687\n",
      "\n",
      "―――― Inference  |  Segment 10 ――――\n",
      "  seg10-ch0  MSE:0.12111229449510574  MAE:0.2763288915157318\n",
      "▶ seg10  mean  MSE:0.12111229449510574  MAE:0.2763288915157318\n",
      "\n",
      "―――― Inference  |  Segment 11 ――――\n",
      "  seg11-ch0  MSE:0.1218334287405014  MAE:0.27399614453315735\n",
      "▶ seg11  mean  MSE:0.1218334287405014  MAE:0.27399614453315735\n",
      "\n",
      "―――― Inference  |  Segment 12 ――――\n",
      "  seg12-ch0  MSE:0.1180218905210495  MAE:0.2732047438621521\n",
      "▶ seg12  mean  MSE:0.1180218905210495  MAE:0.2732047438621521\n",
      "\n",
      "―――― Inference  |  Segment 13 ――――\n",
      "  seg13-ch0  MSE:0.16980762779712677  MAE:0.3160283863544464\n",
      "▶ seg13  mean  MSE:0.16980762779712677  MAE:0.3160283863544464\n",
      "\n",
      "―――― Inference  |  Segment 14 ――――\n",
      "  seg14-ch0  MSE:0.1135585606098175  MAE:0.27303242683410645\n",
      "▶ seg14  mean  MSE:0.1135585606098175  MAE:0.27303242683410645\n",
      "\n",
      "―――― Inference  |  Segment 15 ――――\n",
      "  seg15-ch0  MSE:0.1675199419260025  MAE:0.33001187443733215\n",
      "▶ seg15  mean  MSE:0.1675199419260025  MAE:0.33001187443733215\n",
      "\n",
      "―――― Inference  |  Segment 16 ――――\n",
      "  seg16-ch0  MSE:0.15193715691566467  MAE:0.3165465295314789\n",
      "▶ seg16  mean  MSE:0.15193715691566467  MAE:0.3165465295314789\n",
      "\n",
      "seg10 ch0 MSE : 0.121112294\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import r2_score\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "C        = 1                                \n",
    "P        = base_cfg.pred_len                \n",
    "seg_cnt  = 17\n",
    "batch_sz = 32\n",
    "\n",
    "results2_ILI_E1_val_1E = {}  \n",
    "\n",
    "for seg in range(seg_cnt):\n",
    "    print(f\"\\n―――― Inference  |  Segment {seg} ――――\")\n",
    "\n",
    "    \n",
    "    pv = val_pred_segments_E1[:, seg, :, :]         \n",
    "    ds = TensorDataset(val_sequences, val_labels, pv) \n",
    "    dl = DataLoader(ds, batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "    \n",
    "    pred_ch, true_ch, metrics = [], [], {}\n",
    "\n",
    "    \n",
    "    for ch in range(C):\n",
    "        ckpt = Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{ch}\" / \"checkpoint.pth\"\n",
    "        if not ckpt.exists():\n",
    "            print(f\"[Warn] seg{seg}-ch{ch} ckpt 없음 → skip\");  continue\n",
    "\n",
    "        \n",
    "        model = Model(base_cfg).to(device)\n",
    "        model.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        preds, trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, pv_batch in dl:                 \n",
    "                xb  = xb.float().to(device)\n",
    "                yb  = yb.float()        \n",
    "                pv_ = pv_batch.float().to(device)\n",
    "\n",
    "                out = model(xb, pv_)                     \n",
    "                preds.append(out[:, -P:, ch].cpu())\n",
    "                trues.append(yb[:, -P:, ch])\n",
    "\n",
    "        preds = torch.cat(preds, 0)     \n",
    "        trues = torch.cat(trues, 0)\n",
    "        pred_ch.append(preds)\n",
    "        true_ch.append(trues)\n",
    "\n",
    "        \n",
    "        p, t = preds.reshape(-1).cpu().numpy(), trues.reshape(-1).cpu().numpy()\n",
    "        mse  = np.mean((p - t)**2)\n",
    "        mae  = np.mean(np.abs(p - t))\n",
    "        metrics[ch] = (mse, mae)\n",
    "\n",
    "        print(f\"  seg{seg}-ch{ch}  MSE:{mse}  MAE:{mae}\")\n",
    "\n",
    "        del model; torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "    pred_all = torch.stack(pred_ch,  dim=2)   \n",
    "    true_all = torch.stack(true_ch,  dim=2)\n",
    "\n",
    "    \n",
    "    mse_avg = np.mean([m for m,_ in metrics.values()])\n",
    "    mae_avg = np.mean([a for _,a in metrics.values()])\n",
    "    print(f\"▶ seg{seg}  mean  MSE:{mse_avg}  MAE:{mae_avg}\")\n",
    "\n",
    "    \n",
    "    results2_ILI_E1_val_1E[seg] = {\n",
    "        \"pred2_E1_val_1E\"    : pred_all,   \n",
    "        \"true2_E1_val_1E\"    : true_all,   \n",
    "        \"metrics2_E1_val_1E\" : metrics     \n",
    "    }\n",
    "\n",
    "\n",
    "seg10_ch0_mse = results2_ILI_E1_val_1E[10][\"metrics2_E1_val_1E\"][0][0]\n",
    "print(\"\\nseg10 ch0 MSE :\", seg10_ch0_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfa4e00",
   "metadata": {},
   "source": [
    "# 2nd Inference for Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666d95d8",
   "metadata": {},
   "source": [
    "## ES->1E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f376a81",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79138473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "\n",
    "pred_len = 24\n",
    "seq_len = 104\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual,\n",
    "                 learning_rate, lradj, patience,\n",
    "                 save_path, attach_pv):\n",
    "        self.seq_len  = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in   = enc_in          \n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv    = attach_pv\n",
    "\n",
    "\n",
    "\n",
    "base_cfg = Configs(\n",
    "    pred_len         = 24,\n",
    "    seq_len          = 104 ,\n",
    "    enc_in           = 1,\n",
    "    individual       = True,\n",
    "    learning_rate    = 0.01,\n",
    "    lradj            = 'type1',\n",
    "    patience         = 3,\n",
    "    save_path        = \"./model2_ILI_EES_1E\",\n",
    "    attach_pv  = True,\n",
    "\n",
    ")\n",
    "Path(base_cfg.save_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d899e21c",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f01d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "―――― Inference  |  Segment 0 ――――\n",
      "  seg0-ch0  MSE:0.8665820360183716  MAE:0.7259783744812012\n",
      "▶ seg0  mean  MSE:0.8665820360183716  MAE:0.7259783744812012\n",
      "\n",
      "―――― Inference  |  Segment 1 ――――\n",
      "  seg1-ch0  MSE:1.344844102859497  MAE:0.9524053931236267\n",
      "▶ seg1  mean  MSE:1.344844102859497  MAE:0.9524053931236267\n",
      "\n",
      "―――― Inference  |  Segment 2 ――――\n",
      "  seg2-ch0  MSE:1.0389562845230103  MAE:0.7997047305107117\n",
      "▶ seg2  mean  MSE:1.0389562845230103  MAE:0.7997047305107117\n",
      "\n",
      "―――― Inference  |  Segment 3 ――――\n",
      "  seg3-ch0  MSE:0.8701668977737427  MAE:0.6764236688613892\n",
      "▶ seg3  mean  MSE:0.8701668977737427  MAE:0.6764236688613892\n",
      "\n",
      "―――― Inference  |  Segment 4 ――――\n",
      "  seg4-ch0  MSE:1.1269663572311401  MAE:0.838163435459137\n",
      "▶ seg4  mean  MSE:1.1269663572311401  MAE:0.838163435459137\n",
      "\n",
      "―――― Inference  |  Segment 5 ――――\n",
      "  seg5-ch0  MSE:0.8994731903076172  MAE:0.7213382720947266\n",
      "▶ seg5  mean  MSE:0.8994731903076172  MAE:0.7213382720947266\n",
      "\n",
      "―――― Inference  |  Segment 6 ――――\n",
      "  seg6-ch0  MSE:0.890601634979248  MAE:0.7136557102203369\n",
      "▶ seg6  mean  MSE:0.890601634979248  MAE:0.7136557102203369\n",
      "\n",
      "―――― Inference  |  Segment 7 ――――\n",
      "  seg7-ch0  MSE:0.8151116967201233  MAE:0.6687591671943665\n",
      "▶ seg7  mean  MSE:0.8151116967201233  MAE:0.6687591671943665\n",
      "\n",
      "―――― Inference  |  Segment 8 ――――\n",
      "  seg8-ch0  MSE:0.8546766042709351  MAE:0.7007929682731628\n",
      "▶ seg8  mean  MSE:0.8546766042709351  MAE:0.7007929682731628\n",
      "\n",
      "―――― Inference  |  Segment 9 ――――\n",
      "  seg9-ch0  MSE:0.9392221570014954  MAE:0.7675066590309143\n",
      "▶ seg9  mean  MSE:0.9392221570014954  MAE:0.7675066590309143\n",
      "\n",
      "―――― Inference  |  Segment 10 ――――\n",
      "  seg10-ch0  MSE:1.0836138725280762  MAE:0.8415315747261047\n",
      "▶ seg10  mean  MSE:1.0836138725280762  MAE:0.8415315747261047\n",
      "\n",
      "―――― Inference  |  Segment 11 ――――\n",
      "  seg11-ch0  MSE:1.2525047063827515  MAE:0.9006502628326416\n",
      "▶ seg11  mean  MSE:1.2525047063827515  MAE:0.9006502628326416\n",
      "\n",
      "―――― Inference  |  Segment 12 ――――\n",
      "  seg12-ch0  MSE:1.0258427858352661  MAE:0.7977389693260193\n",
      "▶ seg12  mean  MSE:1.0258427858352661  MAE:0.7977389693260193\n",
      "\n",
      "―――― Inference  |  Segment 13 ――――\n",
      "  seg13-ch0  MSE:0.7888205051422119  MAE:0.6838732957839966\n",
      "▶ seg13  mean  MSE:0.7888205051422119  MAE:0.6838732957839966\n",
      "\n",
      "―――― Inference  |  Segment 14 ――――\n",
      "  seg14-ch0  MSE:0.9439018964767456  MAE:0.7700115442276001\n",
      "▶ seg14  mean  MSE:0.9439018964767456  MAE:0.7700115442276001\n",
      "\n",
      "―――― Inference  |  Segment 15 ――――\n",
      "  seg15-ch0  MSE:0.7751615643501282  MAE:0.6830235719680786\n",
      "▶ seg15  mean  MSE:0.7751615643501282  MAE:0.6830235719680786\n",
      "\n",
      "―――― Inference  |  Segment 16 ――――\n",
      "  seg16-ch0  MSE:0.9951745271682739  MAE:0.8147066831588745\n",
      "▶ seg16  mean  MSE:0.9951745271682739  MAE:0.8147066831588745\n",
      "\n",
      "seg10 ch0 MSE : 1.0836139\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import r2_score\n",
    "from pathlib import Path\n",
    "\n",
    "C        = 1                                \n",
    "P        = base_cfg.pred_len                \n",
    "seg_cnt  = 17\n",
    "batch_sz = 32\n",
    "\n",
    "results2_ILI_ES_test_1E = {}  \n",
    "\n",
    "for seg in range(seg_cnt):\n",
    "    print(f\"\\n―――― Inference  |  Segment {seg} ――――\")\n",
    "\n",
    "    \n",
    "    pv = test_pred_segments_ES[:, seg, :, :]         \n",
    "    ds = TensorDataset(test_sequences, test_labels, pv) \n",
    "    dl = DataLoader(ds, batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "    \n",
    "    pred_ch, true_ch, metrics = [], [], {}\n",
    "\n",
    "    \n",
    "    for ch in range(C):\n",
    "        ckpt = Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{ch}\" / \"checkpoint.pth\"\n",
    "        if not ckpt.exists():\n",
    "            print(f\"[Warn] seg{seg}-ch{ch} ckpt 없음 → skip\");  continue\n",
    "\n",
    "        \n",
    "        model = Model(base_cfg).to(device)\n",
    "        model.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        preds, trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, pv_batch in dl:                 \n",
    "                xb  = xb.float().to(device)\n",
    "                yb  = yb.float()        \n",
    "                pv_ = pv_batch.float().to(device)\n",
    "\n",
    "                out = model(xb, pv_)                     \n",
    "                preds.append(out[:, -P:, ch].cpu())\n",
    "                trues.append(yb[:, -P:, ch])\n",
    "\n",
    "        preds = torch.cat(preds, 0)     \n",
    "        trues = torch.cat(trues, 0)\n",
    "        pred_ch.append(preds)\n",
    "        true_ch.append(trues)\n",
    "\n",
    "        \n",
    "        p, t = preds.reshape(-1).cpu().numpy(), trues.reshape(-1).cpu().numpy()\n",
    "        mse  = np.mean((p - t)**2)\n",
    "        mae  = np.mean(np.abs(p - t))\n",
    "        metrics[ch] = (mse, mae)\n",
    "\n",
    "        print(f\"  seg{seg}-ch{ch}  MSE:{mse}  MAE:{mae}\")\n",
    "\n",
    "        del model; torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "    pred_all = torch.stack(pred_ch,  dim=2)   \n",
    "    true_all = torch.stack(true_ch,  dim=2)\n",
    "\n",
    "    \n",
    "    mse_avg = np.mean([m for m,_ in metrics.values()])\n",
    "    mae_avg = np.mean([a for _,a in metrics.values()])\n",
    "    print(f\"▶ seg{seg}  mean  MSE:{mse_avg}  MAE:{mae_avg}\")\n",
    "\n",
    "    \n",
    "    results2_ILI_ES_test_1E[seg] = {\n",
    "        \"pred2_ES_test_1E\"    : pred_all,   \n",
    "        \"true2_ES_test_1E\"    : true_all,   \n",
    "        \"metrics2_ES_test_1E\" : metrics     \n",
    "    }\n",
    "\n",
    "\n",
    "seg10_ch0_mse = results2_ILI_ES_test_1E[10][\"metrics2_ES_test_1E\"][0][0]\n",
    "print(\"\\nseg10 ch0 MSE :\", seg10_ch0_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce44755",
   "metadata": {},
   "source": [
    "## 1E->1E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5fa2c",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c40ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "\n",
    "pred_len = 24\n",
    "seq_len = 104\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual,\n",
    "                 learning_rate, lradj, patience,\n",
    "                 save_path, attach_pv):\n",
    "        self.seq_len  = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in   = enc_in          \n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv    = attach_pv\n",
    "\n",
    "\n",
    "\n",
    "base_cfg = Configs(\n",
    "    pred_len         = 24,\n",
    "    seq_len          = 104 ,\n",
    "    enc_in           = 1,\n",
    "    individual       = True,\n",
    "    learning_rate    = 0.01,\n",
    "    lradj            = 'type1',\n",
    "    patience         = 3,\n",
    "    save_path        = \"./model2_ILI_E1_1E\",\n",
    "    attach_pv  = True,\n",
    "\n",
    ")\n",
    "Path(base_cfg.save_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fc6195",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa7012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "―――― Inference  |  Segment 0 ――――\n",
      "  seg0-ch0  MSE:1.1126106977462769  MAE:0.8401137590408325\n",
      "▶ seg0  mean  MSE:1.1126106977462769  MAE:0.8401137590408325\n",
      "\n",
      "―――― Inference  |  Segment 1 ――――\n",
      "  seg1-ch0  MSE:0.9754028916358948  MAE:0.7732838988304138\n",
      "▶ seg1  mean  MSE:0.9754028916358948  MAE:0.7732838988304138\n",
      "\n",
      "―――― Inference  |  Segment 2 ――――\n",
      "  seg2-ch0  MSE:0.997130811214447  MAE:0.7638860940933228\n",
      "▶ seg2  mean  MSE:0.997130811214447  MAE:0.7638860940933228\n",
      "\n",
      "―――― Inference  |  Segment 3 ――――\n",
      "  seg3-ch0  MSE:0.9811787009239197  MAE:0.7595154643058777\n",
      "▶ seg3  mean  MSE:0.9811787009239197  MAE:0.7595154643058777\n",
      "\n",
      "―――― Inference  |  Segment 4 ――――\n",
      "  seg4-ch0  MSE:0.8504533171653748  MAE:0.6989489793777466\n",
      "▶ seg4  mean  MSE:0.8504533171653748  MAE:0.6989489793777466\n",
      "\n",
      "―――― Inference  |  Segment 5 ――――\n",
      "  seg5-ch0  MSE:1.0125285387039185  MAE:0.7848453521728516\n",
      "▶ seg5  mean  MSE:1.0125285387039185  MAE:0.7848453521728516\n",
      "\n",
      "―――― Inference  |  Segment 6 ――――\n",
      "  seg6-ch0  MSE:0.741868793964386  MAE:0.6545413136482239\n",
      "▶ seg6  mean  MSE:0.741868793964386  MAE:0.6545413136482239\n",
      "\n",
      "―――― Inference  |  Segment 7 ――――\n",
      "  seg7-ch0  MSE:0.926762580871582  MAE:0.731191098690033\n",
      "▶ seg7  mean  MSE:0.926762580871582  MAE:0.731191098690033\n",
      "\n",
      "―――― Inference  |  Segment 8 ――――\n",
      "  seg8-ch0  MSE:0.9323791265487671  MAE:0.776055097579956\n",
      "▶ seg8  mean  MSE:0.9323791265487671  MAE:0.776055097579956\n",
      "\n",
      "―――― Inference  |  Segment 9 ――――\n",
      "  seg9-ch0  MSE:0.7905591726303101  MAE:0.6630880832672119\n",
      "▶ seg9  mean  MSE:0.7905591726303101  MAE:0.6630880832672119\n",
      "\n",
      "―――― Inference  |  Segment 10 ――――\n",
      "  seg10-ch0  MSE:0.8614709973335266  MAE:0.7023818492889404\n",
      "▶ seg10  mean  MSE:0.8614709973335266  MAE:0.7023818492889404\n",
      "\n",
      "―――― Inference  |  Segment 11 ――――\n",
      "  seg11-ch0  MSE:0.9544209837913513  MAE:0.7566232681274414\n",
      "▶ seg11  mean  MSE:0.9544209837913513  MAE:0.7566232681274414\n",
      "\n",
      "―――― Inference  |  Segment 12 ――――\n",
      "  seg12-ch0  MSE:0.888995885848999  MAE:0.7198874354362488\n",
      "▶ seg12  mean  MSE:0.888995885848999  MAE:0.7198874354362488\n",
      "\n",
      "―――― Inference  |  Segment 13 ――――\n",
      "  seg13-ch0  MSE:0.8592728972434998  MAE:0.7008649110794067\n",
      "▶ seg13  mean  MSE:0.8592728972434998  MAE:0.7008649110794067\n",
      "\n",
      "―――― Inference  |  Segment 14 ――――\n",
      "  seg14-ch0  MSE:1.15617036819458  MAE:0.8571239709854126\n",
      "▶ seg14  mean  MSE:1.15617036819458  MAE:0.8571239709854126\n",
      "\n",
      "―――― Inference  |  Segment 15 ――――\n",
      "  seg15-ch0  MSE:1.250561237335205  MAE:0.9089001417160034\n",
      "▶ seg15  mean  MSE:1.250561237335205  MAE:0.9089001417160034\n",
      "\n",
      "―――― Inference  |  Segment 16 ――――\n",
      "  seg16-ch0  MSE:1.1700440645217896  MAE:0.8661432266235352\n",
      "▶ seg16  mean  MSE:1.1700440645217896  MAE:0.8661432266235352\n",
      "\n",
      "seg10 ch0 MSE : 0.861471\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import r2_score\n",
    "from pathlib import Path\n",
    "\n",
    "C        = 1                                \n",
    "P        = base_cfg.pred_len                \n",
    "seg_cnt  = 17\n",
    "batch_sz = 32\n",
    "\n",
    "results2_ILI_E1_test_1E = {}  \n",
    "\n",
    "for seg in range(seg_cnt):\n",
    "    print(f\"\\n―――― Inference  |  Segment {seg} ――――\")\n",
    "\n",
    "    \n",
    "    pv = test_pred_segments_E1[:, seg, :, :]         \n",
    "    ds = TensorDataset(test_sequences, test_labels, pv) \n",
    "    dl = DataLoader(ds, batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "    \n",
    "    pred_ch, true_ch, metrics = [], [], {}\n",
    "\n",
    "    \n",
    "    for ch in range(C):\n",
    "        ckpt = Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{ch}\" / \"checkpoint.pth\"\n",
    "        if not ckpt.exists():\n",
    "            print(f\"[Warn] seg{seg}-ch{ch} ckpt 없음 → skip\");  continue\n",
    "\n",
    "        \n",
    "        model = Model(base_cfg).to(device)\n",
    "        model.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        preds, trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, pv_batch in dl:                 \n",
    "                xb  = xb.float().to(device)\n",
    "                yb  = yb.float()        \n",
    "                pv_ = pv_batch.float().to(device)\n",
    "\n",
    "                out = model(xb, pv_)                     \n",
    "                preds.append(out[:, -P:, ch].cpu())\n",
    "                trues.append(yb[:, -P:, ch])\n",
    "\n",
    "        preds = torch.cat(preds, 0)     \n",
    "        trues = torch.cat(trues, 0)\n",
    "        pred_ch.append(preds)\n",
    "        true_ch.append(trues)\n",
    "\n",
    "        \n",
    "        p, t = preds.reshape(-1).cpu().numpy(), trues.reshape(-1).cpu().numpy()\n",
    "        mse  = np.mean((p - t)**2)\n",
    "        mae  = np.mean(np.abs(p - t))\n",
    "        metrics[ch] = (mse, mae)\n",
    "\n",
    "        print(f\"  seg{seg}-ch{ch}  MSE:{mse}  MAE:{mae}\")\n",
    "\n",
    "        del model; torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "    pred_all = torch.stack(pred_ch,  dim=2)   \n",
    "    true_all = torch.stack(true_ch,  dim=2)\n",
    "\n",
    "    \n",
    "    mse_avg = np.mean([m for m,_ in metrics.values()])\n",
    "    mae_avg = np.mean([a for _,a in metrics.values()])\n",
    "    print(f\"▶ seg{seg}  mean  MSE:{mse_avg}  MAE:{mae_avg}\")\n",
    "\n",
    "    \n",
    "    results2_ILI_E1_test_1E[seg] = {\n",
    "        \"pred2_E1_test_1E\"    : pred_all,   \n",
    "        \"true2_E1_test_1E\"    : true_all,   \n",
    "        \"metrics2_E1_test_1E\" : metrics     \n",
    "    }\n",
    "\n",
    "\n",
    "seg10_ch0_mse = results2_ILI_E1_test_1E[10][\"metrics2_E1_test_1E\"][0][0]\n",
    "print(\"\\nseg10 ch0 MSE :\", seg10_ch0_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5eb158",
   "metadata": {},
   "source": [
    "# Rank Models (by 2nd validation performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43d996a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1_ILI_train = torch.load(\"./1st_results_ILI/train_1st_results.pt\")\n",
    "results1_ILI_val = torch.load(\"./1st_results_ILI/val_1st_results.pt\")\n",
    "results1_ILI_test = torch.load(\"./1st_results_ILI/test_1st_results.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d936fd",
   "metadata": {},
   "source": [
    "### ES->1E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22293de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Train-set  Per-Channel  Top-N  MSE\n",
      "\n",
      "=== Channel 0 ===\n",
      "Vanilla MSE : 0.236409\n",
      "\n",
      "  Top  1 | seg 06 | MSE 0.108067 (+0.128342)\n",
      "  Top  2 | seg 16 | MSE 0.108872 (+0.127538)\n",
      "  Top  3 | seg 12 | MSE 0.111358 (+0.125051)\n",
      "  Top  4 | seg 07 | MSE 0.113840 (+0.122569)\n",
      "  Top  5 | seg 15 | MSE 0.119203 (+0.117206)\n",
      "  Top  6 | seg 10 | MSE 0.120884 (+0.115526)\n",
      "  Top  7 | seg 09 | MSE 0.121174 (+0.115235)\n",
      "  Top  8 | seg 00 | MSE 0.124785 (+0.111624)\n",
      "  Top  9 | seg 03 | MSE 0.132370 (+0.104040)\n",
      "  Top 10 | seg 13 | MSE 0.136676 (+0.099733)\n",
      "  Top 11 | seg 14 | MSE 0.137472 (+0.098938)\n",
      "  Top 12 | seg 05 | MSE 0.138207 (+0.098202)\n",
      "  Top 13 | seg 08 | MSE 0.145648 (+0.090762)\n",
      "  Top 14 | seg 02 | MSE 0.145813 (+0.090596)\n",
      "  Top 15 | seg 11 | MSE 0.149791 (+0.086618)\n",
      "  Top 16 | seg 04 | MSE 0.153618 (+0.082792)\n",
      "  Top 17 | seg 01 | MSE 0.188289 (+0.048120)\n",
      "\n",
      "Saved top segment indices per channel:\n",
      "Channel 0: [6, 16, 12, 7, 15, 10, 9, 0, 3, 13, 14, 5, 8, 2, 11, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TOP_N       = 17\n",
    "SEG_CNT     = 17\n",
    "CH_CNT      = 1\n",
    "metric_idx  = 0          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mse_table = np.full((SEG_CNT, CH_CNT), np.inf)\n",
    "\n",
    "for seg in range(SEG_CNT):\n",
    "    if seg not in results2_ILI_ES_val_1E:\n",
    "        continue\n",
    "    for ch in range(CH_CNT):\n",
    "        if ch in results2_ILI_ES_val_1E[seg][\"metrics2_ES_val_1E\"]:\n",
    "            mse_table[seg, ch] = results2_ILI_ES_val_1E[seg][\"metrics2_ES_val_1E\"][ch][metric_idx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n▶ Train-set  Per-Channel  Top-N  MSE\\n\")\n",
    "top_seg_idx_ES_val_1E = {}                       \n",
    "\n",
    "for ch in range(CH_CNT):\n",
    "    print(f\"=== Channel {ch} ===\")\n",
    "    v_mse = results1_ILI_val[1]['mse_val_E1']\n",
    "    print(f\"Vanilla MSE : {v_mse:.6f}\\n\")\n",
    "\n",
    "    \n",
    "    pairs = [(seg, mse_table[seg, ch]) for seg in range(SEG_CNT)\n",
    "             if np.isfinite(mse_table[seg, ch])]\n",
    "    top   = sorted(pairs, key=lambda x: x[1])[:TOP_N]\n",
    "\n",
    "    \n",
    "    top_seg_idx_ES_val_1E[ch] = [seg for seg, _ in top]   \n",
    "\n",
    "    \n",
    "    for rank, (seg_id, mse_val) in enumerate(top, 1):\n",
    "        delta = v_mse - mse_val\n",
    "        sign  = \"+\" if delta > 0 else \"-\"\n",
    "        print(f\"  Top {rank:2d} | seg {seg_id:02d} | MSE {mse_val:.6f} \"\n",
    "              f\"({sign}{abs(delta):.6f})\")\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Saved top segment indices per channel:\")\n",
    "for ch, seg_list in top_seg_idx_ES_val_1E.items():\n",
    "    print(f\"Channel {ch}: {seg_list}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d239ab",
   "metadata": {},
   "source": [
    "### 1E->1E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99574559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Train-set  Per-Channel  Top-N  MSE\n",
      "\n",
      "=== Channel 0 ===\n",
      "Vanilla MSE : 0.236409\n",
      "\n",
      "  Top  1 | seg 06 | MSE 0.095208 (+0.141201)\n",
      "  Top  2 | seg 08 | MSE 0.105423 (+0.130986)\n",
      "  Top  3 | seg 09 | MSE 0.107196 (+0.129213)\n",
      "  Top  4 | seg 07 | MSE 0.113033 (+0.123376)\n",
      "  Top  5 | seg 14 | MSE 0.113559 (+0.122851)\n",
      "  Top  6 | seg 12 | MSE 0.118022 (+0.118387)\n",
      "  Top  7 | seg 10 | MSE 0.121112 (+0.115297)\n",
      "  Top  8 | seg 11 | MSE 0.121833 (+0.114576)\n",
      "  Top  9 | seg 01 | MSE 0.125992 (+0.110417)\n",
      "  Top 10 | seg 05 | MSE 0.133756 (+0.102653)\n",
      "  Top 11 | seg 03 | MSE 0.137713 (+0.098696)\n",
      "  Top 12 | seg 02 | MSE 0.138619 (+0.097790)\n",
      "  Top 13 | seg 00 | MSE 0.141242 (+0.095167)\n",
      "  Top 14 | seg 04 | MSE 0.143750 (+0.092659)\n",
      "  Top 15 | seg 16 | MSE 0.151937 (+0.084472)\n",
      "  Top 16 | seg 15 | MSE 0.167520 (+0.068889)\n",
      "  Top 17 | seg 13 | MSE 0.169808 (+0.066601)\n",
      "\n",
      "Saved top segment indices per channel:\n",
      "Channel 0: [6, 8, 9, 7, 14, 12, 10, 11, 1, 5, 3, 2, 0, 4, 16, 15, 13]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TOP_N       = 17\n",
    "SEG_CNT     = 17\n",
    "CH_CNT      = 1\n",
    "metric_idx  = 0          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mse_table = np.full((SEG_CNT, CH_CNT), np.inf)\n",
    "\n",
    "for seg in range(SEG_CNT):\n",
    "    if seg not in results2_ILI_E1_val_1E:\n",
    "        continue\n",
    "    for ch in range(CH_CNT):\n",
    "        if ch in results2_ILI_E1_val_1E[seg][\"metrics2_E1_val_1E\"]:\n",
    "            mse_table[seg, ch] = results2_ILI_E1_val_1E[seg][\"metrics2_E1_val_1E\"][ch][metric_idx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n▶ Train-set  Per-Channel  Top-N  MSE\\n\")\n",
    "top_seg_idx_E1_val_1E = {}                       \n",
    "\n",
    "for ch in range(CH_CNT):\n",
    "    print(f\"=== Channel {ch} ===\")\n",
    "    v_mse = results1_ILI_val[1]['mse_val_E1']\n",
    "    print(f\"Vanilla MSE : {v_mse:.6f}\\n\")\n",
    "\n",
    "    \n",
    "    pairs = [(seg, mse_table[seg, ch]) for seg in range(SEG_CNT)\n",
    "             if np.isfinite(mse_table[seg, ch])]\n",
    "    top   = sorted(pairs, key=lambda x: x[1])[:TOP_N]\n",
    "\n",
    "    \n",
    "    top_seg_idx_E1_val_1E[ch] = [seg for seg, _ in top]   \n",
    "\n",
    "    \n",
    "    for rank, (seg_id, mse_val) in enumerate(top, 1):\n",
    "        delta = v_mse - mse_val\n",
    "        sign  = \"+\" if delta > 0 else \"-\"\n",
    "        print(f\"  Top {rank:2d} | seg {seg_id:02d} | MSE {mse_val:.6f} \"\n",
    "              f\"({sign}{abs(delta):.6f})\")\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Saved top segment indices per channel:\")\n",
    "for ch, seg_list in top_seg_idx_E1_val_1E.items():\n",
    "    print(f\"Channel {ch}: {seg_list}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c709e6",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1348b000",
   "metadata": {},
   "source": [
    "## ES->1E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64be0d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Channel 0 ===\n",
      "[Vanilla]   MSE : 1.619734 | MAE : 1.131531\n",
      "  — Var / |Corr| / Score —\n",
      "   K= 5 | Var=2.383e-01 | |ρ|=0.8141 | S=1.0000 <- pick\n",
      "   K=10 | Var=2.556e-01 | |ρ|=0.8037 | S=1.0492 \n",
      "   K=15 | Var=2.837e-01 | |ρ|=0.7826 | S=1.0000 \n",
      "[Var-Corr]  K=5\n",
      "  MSE = 0.709704 | Δ = +0.910030 | Δ% = +56.18%\n",
      "  MAE = 0.670330 | Δ = +0.461201 | Δ% = +40.76%\n",
      "\n",
      "──────── Summary (Var-Corr) ───────\n",
      "Vanilla  mean MSE : 1.619734\n",
      "Ensemble mean MSE : 0.709704\n",
      "Average Δ MSE     : +0.910030\n",
      "Average Δ MSE (%) : +56.18%\n",
      "\n",
      "Vanilla  mean MAE : 1.131531\n",
      "Ensemble mean MAE : 0.670330\n",
      "Average Δ MAE     : +0.461201\n",
      "Average Δ MAE (%) : +40.76%\n"
     ]
    }
   ],
   "source": [
    "import torch, os, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "TOP_K    = 17\n",
    "CH_CNT   = 1\n",
    "batch_sz = 32\n",
    "\n",
    "def infer_one(model, loader, ch):\n",
    "    buf = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb, pv in loader:\n",
    "            xb, pv = xb.to(device), pv.to(device)\n",
    "            buf.append(model(xb, pv)[:, :, ch].cpu())   \n",
    "    return torch.cat(buf, 0)   \n",
    "\n",
    "\n",
    "van_mse_list, ens_mse_list, delta_mse_list, delta_mse_pct_list = [], [], [], []\n",
    "van_mae_list, ens_mae_list, delta_mae_list, delta_mae_pct_list = [], [], [], []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for ch in range(CH_CNT):\n",
    "    print(f\"\\n=== Channel {ch} ===\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    v_mse = results1_ILI_test['ES']['mse_test_EES']\n",
    "    v_mae = results1_ILI_test['ES']['mae_test_EES']\n",
    "\n",
    "    print(f\"[Vanilla]   MSE : {v_mse:.6f} | MAE : {v_mae:.6f}\")\n",
    "\n",
    "    van_mse_list.append(v_mse)\n",
    "    van_mae_list.append(v_mae)\n",
    "\n",
    "    preds_test_arr = []\n",
    "    ok_segs = []\n",
    "\n",
    "    \n",
    "    for seg in top_seg_idx_ES_val_1E[ch][:TOP_K]:\n",
    "        ckpt = f\"./model2_ILI_EES_1E/seg{seg}/ch{ch}/checkpoint.pth\"\n",
    "        if not os.path.exists(ckpt):\n",
    "            print(f\"  [skip] ckpt missing : seg{seg}\")\n",
    "            continue\n",
    "\n",
    "        pv_seg = test_pred_segments_ES[:, seg, :, :]\n",
    "        dl     = DataLoader(TensorDataset(test_sequences, test_labels, pv_seg),\n",
    "                            batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "        mdl = Model(base_cfg).to(device)\n",
    "        mdl.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "\n",
    "        preds_test_arr.append(infer_one(mdl, dl, ch))   \n",
    "        ok_segs.append(seg)\n",
    "\n",
    "    if len(preds_test_arr) < 5:\n",
    "        print(\"  Not enough valid models.\")\n",
    "        continue\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    step = 5\n",
    "    Ks = list(range(step, len(preds_test_arr)+1, step))\n",
    "\n",
    "    var_list, rho_list = [], []\n",
    "\n",
    "    for K in Ks:\n",
    "        F = torch.stack(preds_test_arr[:K], dim=0)\n",
    "\n",
    "        V = torch.var(F, dim=0).mean().item()\n",
    "        var_list.append(V)\n",
    "\n",
    "        flat = F.reshape(K, -1).numpy()\n",
    "        corr = np.corrcoef(flat)\n",
    "        R = np.mean(np.abs(corr[np.triu_indices(K, 1)]))\n",
    "        rho_list.append(R)\n",
    "\n",
    "    \n",
    "    V_min, V_max = min(var_list), max(var_list)\n",
    "    R_min, R_max = min(rho_list), max(rho_list)\n",
    "\n",
    "    V_norm = [(v - V_min)/(V_max - V_min + 1e-12) for v in var_list]\n",
    "    R_norm = [(r - R_min)/(R_max - R_min + 1e-12) for r in rho_list]\n",
    "\n",
    "    alpha, beta = 1, 1\n",
    "    scores = [alpha*v + beta*r for v, r in zip(V_norm, R_norm)]\n",
    "\n",
    "    best_K = Ks[int(np.argmin(scores))]\n",
    "\n",
    "    print(\"  — Var / |Corr| / Score —\")\n",
    "    for k, v, r, s in zip(Ks, var_list, rho_list, scores):\n",
    "        tag = \"<- pick\" if k == best_K else \"\"\n",
    "        print(f\"   K={k:2d} | Var={v:.3e} | |ρ|={r:.4f} | S={s:.4f} {tag}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ens_pred = torch.mean(torch.stack(preds_test_arr[:best_K]), dim=0)\n",
    "    y_true   = test_labels[:, -base_cfg.pred_len:, ch].cpu()\n",
    "\n",
    "    mse_ens = torch.mean((ens_pred - y_true)**2).item()\n",
    "    mae_ens = torch.mean(torch.abs(ens_pred - y_true)).item()\n",
    "\n",
    "    ens_mse_list.append(mse_ens)\n",
    "    ens_mae_list.append(mae_ens)\n",
    "\n",
    "    \n",
    "    delta_mse = v_mse - mse_ens\n",
    "    delta_mae = v_mae - mae_ens\n",
    "\n",
    "    \n",
    "    delta_mse_pct = (delta_mse / v_mse) * 100\n",
    "    delta_mae_pct = (delta_mae / v_mae) * 100\n",
    "\n",
    "    delta_mse_list.append(delta_mse)\n",
    "    delta_mae_list.append(delta_mae)\n",
    "\n",
    "    delta_mse_pct_list.append(delta_mse_pct)\n",
    "    delta_mae_pct_list.append(delta_mae_pct)\n",
    "\n",
    "    print(f\"[Var-Corr]  K={best_K}\")\n",
    "    print(f\"  MSE = {mse_ens:.6f} | Δ = {delta_mse:+.6f} | Δ% = {delta_mse_pct:+.2f}%\")\n",
    "    print(f\"  MAE = {mae_ens:.6f} | Δ = {delta_mae:+.6f} | Δ% = {delta_mae_pct:+.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if ens_mse_list:\n",
    "    print(\"\\n──────── Summary (Var-Corr) ───────\")\n",
    "    print(f\"Vanilla  mean MSE : {np.mean(van_mse_list):.6f}\")\n",
    "    print(f\"Ensemble mean MSE : {np.mean(ens_mse_list):.6f}\")\n",
    "    print(f\"Average Δ MSE     : {np.mean(delta_mse_list):+.6f}\")\n",
    "    print(f\"Average Δ MSE (%) : {np.mean(delta_mse_pct_list):+.2f}%\\n\")\n",
    "\n",
    "    print(f\"Vanilla  mean MAE : {np.mean(van_mae_list):.6f}\")\n",
    "    print(f\"Ensemble mean MAE : {np.mean(ens_mae_list):.6f}\")\n",
    "    print(f\"Average Δ MAE     : {np.mean(delta_mae_list):+.6f}\")\n",
    "    print(f\"Average Δ MAE (%) : {np.mean(delta_mae_pct_list):+.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a5e65",
   "metadata": {},
   "source": [
    "## 1E->1E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae13e17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.13153076171875"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1_ILI_test['ES']['mae_test_EES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0054776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Channel 0 ===\n",
      "[Vanilla]   MSE : 1.619734 | MAE : 1.131531\n",
      "  — Var / |Corr| / Score —\n",
      "   K= 5 | Var=2.356e-01 | |ρ|=0.8124 | S=1.1000 \n",
      "   K=10 | Var=2.842e-01 | |ρ|=0.7735 | S=0.9165 <- pick\n",
      "   K=15 | Var=2.977e-01 | |ρ|=0.7681 | S=1.0000 \n",
      "[Var-Corr]  K=10\n",
      "   MSE = 0.668246 | Δ = +0.951488 | Δ% = +58.74%\n",
      "   MAE = 0.654698 | Δ = +0.476833 | Δ% = +42.14%\n",
      "\n",
      "──────── Summary (Var-Corr) ───────\n",
      "Vanilla  mean MSE  : 1.619734\n",
      "Ensemble mean MSE  : 0.668246\n",
      "Average Δ MSE      : +0.951488\n",
      "Average Δ MSE (%)  : +58.74%\n",
      "\n",
      "Vanilla  mean MAE  : 1.131531\n",
      "Ensemble mean MAE  : 0.654698\n",
      "Average Δ MAE      : +0.476833\n",
      "Average Δ MAE (%)  : +42.14%\n"
     ]
    }
   ],
   "source": [
    "import torch, os, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "TOP_K    = 17\n",
    "CH_CNT   = 1\n",
    "batch_sz = 32\n",
    "\n",
    "def infer_one(model, loader, ch):\n",
    "    buf = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb, pv in loader:\n",
    "            xb, pv = xb.to(device), pv.to(device)\n",
    "            buf.append(model(xb, pv)[:, :, ch].cpu())   \n",
    "    return torch.cat(buf, 0)    \n",
    "\n",
    "\n",
    "\n",
    "van_mse_list, ens_mse_list, delta_mse_list, delta_mse_pct_list = [], [], [], []\n",
    "van_mae_list, ens_mae_list, delta_mae_list, delta_mae_pct_list = [], [], [], []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for ch in range(CH_CNT):\n",
    "\n",
    "    print(f\"\\n=== Channel {ch} ===\")\n",
    "\n",
    "    \n",
    "    v_mse = results1_ILI_test['ES']['mse_test_EES']\n",
    "    v_mae = results1_ILI_test['ES']['mae_test_EES']\n",
    "\n",
    "    print(f\"[Vanilla]   MSE : {v_mse:.6f} | MAE : {v_mae:.6f}\")\n",
    "\n",
    "    van_mse_list.append(v_mse)\n",
    "    van_mae_list.append(v_mae)\n",
    "\n",
    "    preds_test_arr = []\n",
    "    ok_segs = []\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    for seg in top_seg_idx_E1_val_1E[ch][:TOP_K]:\n",
    "\n",
    "        ckpt = f\"./model2_ILI_E1_1E/seg{seg}/ch{ch}/checkpoint.pth\"\n",
    "        if not os.path.exists(ckpt):\n",
    "            print(f\"  [skip] missing checkpoint : seg{seg}\")\n",
    "            continue\n",
    "\n",
    "        mdl = Model(base_cfg).to(device)\n",
    "        mdl.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "\n",
    "        pv_seg = test_pred_segments_E1[:, seg, :, :]\n",
    "        dl = DataLoader(\n",
    "            TensorDataset(test_sequences, test_labels, pv_seg),\n",
    "            batch_size=batch_sz, shuffle=False\n",
    "        )\n",
    "\n",
    "        preds_test_arr.append(infer_one(mdl, dl, ch))\n",
    "        ok_segs.append(seg)\n",
    "\n",
    "    if len(preds_test_arr) < 5:\n",
    "        print(\"  Not enough valid models.\")\n",
    "        continue\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    step = 5\n",
    "    Ks = list(range(step, len(preds_test_arr)+1, step))\n",
    "\n",
    "    var_list = []\n",
    "    rho_list = []\n",
    "\n",
    "    for K in Ks:\n",
    "        F = torch.stack(preds_test_arr[:K], dim=0)   \n",
    "\n",
    "        \n",
    "        V = torch.var(F, dim=0).mean().item()\n",
    "        var_list.append(V)\n",
    "\n",
    "        \n",
    "        flat = F.reshape(K, -1).numpy()\n",
    "        corr = np.corrcoef(flat)\n",
    "        R    = np.mean(np.abs(corr[np.triu_indices(K, 1)]))\n",
    "        rho_list.append(R)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    V_min, V_max = min(var_list), max(var_list)\n",
    "    R_min, R_max = min(rho_list), max(rho_list)\n",
    "\n",
    "    V_norm = [(v - V_min) / (V_max - V_min + 1e-12) for v in var_list]\n",
    "    R_norm = [(r - R_min) / (R_max - R_min + 1e-12) for r in rho_list]\n",
    "\n",
    "    alpha, beta = 1, 1.1   \n",
    "\n",
    "    scores = [alpha*v + beta*r for v, r in zip(V_norm, R_norm)]\n",
    "    best_K = Ks[int(np.argmin(scores))]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"  — Var / |Corr| / Score —\")\n",
    "    for k, v, r, s in zip(Ks, var_list, rho_list, scores):\n",
    "        tag = \"<- pick\" if k == best_K else \"\"\n",
    "        print(f\"   K={k:2d} | Var={v:.3e} | |ρ|={r:.4f} | S={s:.4f} {tag}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ens_pred = torch.mean(torch.stack(preds_test_arr[:best_K]), dim=0)  \n",
    "    y_true   = test_labels[:, -base_cfg.pred_len:, ch].cpu()\n",
    "\n",
    "    mse_ens = torch.mean((ens_pred - y_true)**2).item()\n",
    "    mae_ens = torch.mean(torch.abs(ens_pred - y_true)).item()\n",
    "\n",
    "    ens_mse_list.append(mse_ens)\n",
    "    ens_mae_list.append(mae_ens)\n",
    "\n",
    "    \n",
    "    delta_mse = v_mse - mse_ens\n",
    "    delta_mae = v_mae - mae_ens\n",
    "\n",
    "    \n",
    "    delta_mse_pct = (delta_mse / v_mse) * 100\n",
    "    delta_mae_pct = (delta_mae / v_mae) * 100\n",
    "\n",
    "    delta_mse_list.append(delta_mse)\n",
    "    delta_mae_list.append(delta_mae)\n",
    "    delta_mse_pct_list.append(delta_mse_pct)\n",
    "    delta_mae_pct_list.append(delta_mae_pct)\n",
    "\n",
    "    sign = \"+\" if delta_mse > 0 else \"-\"\n",
    "    print(f\"[Var-Corr]  K={best_K}\")\n",
    "    print(f\"   MSE = {mse_ens:.6f} | Δ = {delta_mse:+.6f} | Δ% = {delta_mse_pct:+.2f}%\")\n",
    "    print(f\"   MAE = {mae_ens:.6f} | Δ = {delta_mae:+.6f} | Δ% = {delta_mae_pct:+.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if ens_mse_list:\n",
    "    print(\"\\n──────── Summary (Var-Corr) ───────\")\n",
    "    print(f\"Vanilla  mean MSE  : {np.mean(van_mse_list):.6f}\")\n",
    "    print(f\"Ensemble mean MSE  : {np.mean(ens_mse_list):.6f}\")\n",
    "    print(f\"Average Δ MSE      : {np.mean(delta_mse_list):+.6f}\")\n",
    "    print(f\"Average Δ MSE (%)  : {np.mean(delta_mse_pct_list):+.2f}%\\n\")\n",
    "\n",
    "    print(f\"Vanilla  mean MAE  : {np.mean(van_mae_list):.6f}\")\n",
    "    print(f\"Ensemble mean MAE  : {np.mean(ens_mae_list):.6f}\")\n",
    "    print(f\"Average Δ MAE      : {np.mean(delta_mae_list):+.6f}\")\n",
    "    print(f\"Average Δ MAE (%)  : {np.mean(delta_mae_pct_list):+.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef942a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b60c5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sunho_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
