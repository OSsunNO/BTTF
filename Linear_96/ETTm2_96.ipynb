{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f06d9cd5",
   "metadata": {},
   "source": [
    "# Environment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2547132b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6578f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of GPU: 4\n",
      "Total GPU memory: 51.033931776 GB\n",
      "GPU ID: 3\n",
      "GPU Name: NVIDIA RTX A6000\n",
      "GPU Compute Capability: (8, 6)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_id = torch.cuda.current_device()\n",
    "    gpu_name = torch.cuda.get_device_name(gpu_id)\n",
    "    gpu_capability = torch.cuda.get_device_capability(gpu_id)\n",
    "    total_memory = torch.cuda.get_device_properties(gpu_id).total_memory\n",
    "    \n",
    "    print(f\"Total number of GPU: {torch.cuda.device_count()}\")  \n",
    "    print(f\"Total GPU memory: {total_memory / 1e9} GB\")\n",
    "    print(f\"GPU ID: {gpu_id}\")\n",
    "    print(f\"GPU Name: {gpu_name}\")\n",
    "    print(f\"GPU Compute Capability: {gpu_capability}\")\n",
    "else:\n",
    "    print(\"No GPU is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fed096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device: 3\n",
      "Device Name: NVIDIA RTX A6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "torch.cuda.set_device(3)\n",
    "\n",
    "\n",
    "print(\"Current Device:\", torch.cuda.current_device())\n",
    "print(\"Device Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9397d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bf0e69",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1431e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "badb7077",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../dataset/ETTm2.csv', index_col='date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00d136e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HUFL</th>\n",
       "      <th>HULL</th>\n",
       "      <th>MUFL</th>\n",
       "      <th>MULL</th>\n",
       "      <th>LUFL</th>\n",
       "      <th>LULL</th>\n",
       "      <th>OT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-01 00:00:00</th>\n",
       "      <td>41.130001</td>\n",
       "      <td>12.481</td>\n",
       "      <td>36.535999</td>\n",
       "      <td>9.355</td>\n",
       "      <td>4.424</td>\n",
       "      <td>1.311</td>\n",
       "      <td>38.661999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 00:15:00</th>\n",
       "      <td>39.622002</td>\n",
       "      <td>11.309</td>\n",
       "      <td>35.543999</td>\n",
       "      <td>8.551</td>\n",
       "      <td>3.209</td>\n",
       "      <td>1.258</td>\n",
       "      <td>38.223000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 00:30:00</th>\n",
       "      <td>38.868000</td>\n",
       "      <td>10.555</td>\n",
       "      <td>34.365002</td>\n",
       "      <td>7.586</td>\n",
       "      <td>4.435</td>\n",
       "      <td>1.258</td>\n",
       "      <td>37.344002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 00:45:00</th>\n",
       "      <td>35.518002</td>\n",
       "      <td>9.214</td>\n",
       "      <td>32.569000</td>\n",
       "      <td>8.712</td>\n",
       "      <td>4.435</td>\n",
       "      <td>1.215</td>\n",
       "      <td>37.124001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 01:00:00</th>\n",
       "      <td>37.528000</td>\n",
       "      <td>10.136</td>\n",
       "      <td>33.936001</td>\n",
       "      <td>7.532</td>\n",
       "      <td>4.435</td>\n",
       "      <td>1.215</td>\n",
       "      <td>37.124001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          HUFL    HULL       MUFL   MULL   LUFL   LULL  \\\n",
       "date                                                                     \n",
       "2016-07-01 00:00:00  41.130001  12.481  36.535999  9.355  4.424  1.311   \n",
       "2016-07-01 00:15:00  39.622002  11.309  35.543999  8.551  3.209  1.258   \n",
       "2016-07-01 00:30:00  38.868000  10.555  34.365002  7.586  4.435  1.258   \n",
       "2016-07-01 00:45:00  35.518002   9.214  32.569000  8.712  4.435  1.215   \n",
       "2016-07-01 01:00:00  37.528000  10.136  33.936001  7.532  4.435  1.215   \n",
       "\n",
       "                            OT  \n",
       "date                            \n",
       "2016-07-01 00:00:00  38.661999  \n",
       "2016-07-01 00:15:00  38.223000  \n",
       "2016-07-01 00:30:00  37.344002  \n",
       "2016-07-01 00:45:00  37.124001  \n",
       "2016-07-01 01:00:00  37.124001  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65ce6c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUFL    float64\n",
      "HULL    float64\n",
      "MUFL    float64\n",
      "MULL    float64\n",
      "LUFL    float64\n",
      "LULL    float64\n",
      "OT      float64\n",
      "dtype: object\n",
      "shape:  (69680, 7)\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes)\n",
    "print('shape: ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f9223c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['OT']\n",
    "features = data.drop(['OT'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16620e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['DATE'] = features.index.strftime('%Y%m%d%H').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c46cd5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2016-07-01 00:00:00', '2016-07-01 00:15:00',\n",
       "               '2016-07-01 00:30:00', '2016-07-01 00:45:00',\n",
       "               '2016-07-01 01:00:00', '2016-07-01 01:15:00',\n",
       "               '2016-07-01 01:30:00', '2016-07-01 01:45:00',\n",
       "               '2016-07-01 02:00:00', '2016-07-01 02:15:00',\n",
       "               ...\n",
       "               '2018-06-26 17:30:00', '2018-06-26 17:45:00',\n",
       "               '2018-06-26 18:00:00', '2018-06-26 18:15:00',\n",
       "               '2018-06-26 18:30:00', '2018-06-26 18:45:00',\n",
       "               '2018-06-26 19:00:00', '2018-06-26 19:15:00',\n",
       "               '2018-06-26 19:30:00', '2018-06-26 19:45:00'],\n",
       "              dtype='datetime64[ns]', name='date', length=69680, freq=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a84e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)                           \n",
    "    np.random.seed(seed)                        \n",
    "    torch.manual_seed(seed)                     \n",
    "    torch.cuda.manual_seed(seed)                \n",
    "    torch.cuda.manual_seed_all(seed)            \n",
    "    torch.backends.cudnn.deterministic = True   \n",
    "    torch.backends.cudnn.benchmark = False      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a94d6f",
   "metadata": {},
   "source": [
    "# Model Modification for Linear (Look-ahead Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af16069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Linear model with prediction-based augmentation (attach_pv)\n",
    "    \"\"\"\n",
    "    def __init__(self, configs):\n",
    "        super(Model, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.channels = configs.enc_in\n",
    "\n",
    "        \n",
    "        self.attach_pv = getattr(configs, \"attach_pv\", False)\n",
    "\n",
    "        \n",
    "        self.extra_len = self.pred_len // 3\n",
    "\n",
    "        \n",
    "        self.seq_len_aug = self.seq_len + (self.extra_len if self.attach_pv else 0)\n",
    "\n",
    "        self.individual = configs.individual\n",
    "\n",
    "        \n",
    "        if self.individual:\n",
    "            self.Linear = nn.ModuleList()\n",
    "            for i in range(self.channels):\n",
    "                self.Linear.append(nn.Linear(self.seq_len_aug, self.pred_len))\n",
    "        else:\n",
    "            self.Linear = nn.Linear(self.seq_len_aug, self.pred_len)\n",
    "\n",
    "\n",
    "    def forward(self, x, ground_truth=None):\n",
    "        \"\"\"\n",
    "        x: [B, L, C]\n",
    "        ground_truth: [B, L_gt, C] or None\n",
    "        \"\"\"\n",
    "        B, L, C = x.size()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.attach_pv and (ground_truth is not None):\n",
    "            \n",
    "            gt_part = ground_truth[:, :self.extra_len, :]  \n",
    "\n",
    "            \n",
    "            x = torch.cat([x, gt_part], dim=1)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.individual:\n",
    "            out = torch.zeros([B, self.pred_len, C], dtype=x.dtype).to(x.device)\n",
    "            for i in range(C):\n",
    "                out[:, :, i] = self.Linear[i](x[:, :, i])\n",
    "            return out\n",
    "\n",
    "        else:\n",
    "            \n",
    "            out = self.Linear(x.permute(0, 2, 1))\n",
    "            return out.permute(0, 2, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333d5d9",
   "metadata": {},
   "source": [
    "# Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e5814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sequences: torch.Size([34129, 336, 1])\n",
      "Train Labels:    torch.Size([34129, 96, 1])\n",
      "Val Sequences:   torch.Size([11425, 336, 1])\n",
      "Val Labels:      torch.Size([11425, 96, 1])\n",
      "Test Sequences:  torch.Size([11425, 336, 1])\n",
      "Test Labels:     torch.Size([11425, 96, 1])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "target = data['OT'].values.reshape(-1, 1)  \n",
    "\n",
    "\n",
    "seq_len = 336\n",
    "pred_len = 96\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_points = 12 * 30 * 24 * 4\n",
    "val_points   = 4  * 30 * 24 * 4\n",
    "test_points  = 4  * 30 * 24 * 4\n",
    "\n",
    "border1s = [\n",
    "    0,\n",
    "    train_points - seq_len,\n",
    "    train_points + val_points - seq_len\n",
    "]\n",
    "border2s = [\n",
    "    train_points,\n",
    "    train_points + val_points,\n",
    "    train_points + val_points + test_points\n",
    "]\n",
    "\n",
    "\n",
    "train = target[border1s[0]:border2s[0]]\n",
    "val   = target[border1s[1]:border2s[1]]\n",
    "test  = target[border1s[2]:border2s[2]]\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "val   = scaler.transform(val)\n",
    "test  = scaler.transform(test)\n",
    "\n",
    "\n",
    "def create_inout_sequences_univariate(data, seq_len, pred_len):\n",
    "    seqs = []\n",
    "    for i in range(len(data) - seq_len - pred_len + 1):\n",
    "        seq_x = data[i:i + seq_len]\n",
    "        seq_y = data[i + seq_len:i + seq_len + pred_len]\n",
    "        seqs.append((seq_x, seq_y))\n",
    "    return seqs\n",
    "\n",
    "train_data = create_inout_sequences_univariate(train, seq_len, pred_len)\n",
    "val_data   = create_inout_sequences_univariate(val,   seq_len, pred_len)\n",
    "test_data  = create_inout_sequences_univariate(test,  seq_len, pred_len)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_sequences = torch.tensor([x[0] for x in train_data]).float().to(device)  \n",
    "train_labels    = torch.tensor([x[1] for x in train_data]).float().to(device)\n",
    "\n",
    "val_sequences   = torch.tensor([x[0] for x in val_data]).float().to(device)\n",
    "val_labels      = torch.tensor([x[1] for x in val_data]).float().to(device)\n",
    "\n",
    "test_sequences  = torch.tensor([x[0] for x in test_data]).float().to(device)\n",
    "test_labels     = torch.tensor([x[1] for x in test_data]).float().to(device)\n",
    "\n",
    "\n",
    "print(\"Train Sequences:\", train_sequences.shape)\n",
    "print(\"Train Labels:   \", train_labels.shape)\n",
    "print(\"Val Sequences:  \", val_sequences.shape)\n",
    "print(\"Val Labels:     \", val_labels.shape)\n",
    "print(\"Test Sequences: \", test_sequences.shape)\n",
    "print(\"Test Labels:    \", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b58fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a94006",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(train_sequences, train_labels)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "val_dataset = TensorDataset(val_sequences, val_labels)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "test_dataset = TensorDataset(test_sequences, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96a50e",
   "metadata": {},
   "source": [
    "# 1st Model Training (Early Stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88ab994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18845fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating learning rate to 0.001\n",
      "Epoch 0 | Train Loss: 0.10962458412602 | Val Loss: 0.09320094824349767\n",
      "Validation loss decreased (inf --> 0.093201).  Saving model ...\n",
      "Updating learning rate to 0.0005\n",
      "Epoch 1 | Train Loss: 0.09465493611649252 | Val Loss: 0.08890527502930197\n",
      "Validation loss decreased (0.093201 --> 0.088905).  Saving model ...\n",
      "Updating learning rate to 0.00025\n",
      "Epoch 2 | Train Loss: 0.09293097740470413 | Val Loss: 0.08867514807491579\n",
      "Validation loss decreased (0.088905 --> 0.088675).  Saving model ...\n",
      "Updating learning rate to 0.000125\n",
      "Epoch 3 | Train Loss: 0.09186869214490517 | Val Loss: 0.08813603505278891\n",
      "Validation loss decreased (0.088675 --> 0.088136).  Saving model ...\n",
      "Updating learning rate to 6.25e-05\n",
      "Epoch 4 | Train Loss: 0.09118586270297478 | Val Loss: 0.08686588566546073\n",
      "Validation loss decreased (0.088136 --> 0.086866).  Saving model ...\n",
      "Updating learning rate to 3.125e-05\n",
      "Epoch 5 | Train Loss: 0.0908677066033034 | Val Loss: 0.086871200553974\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-05\n",
      "Epoch 6 | Train Loss: 0.09074033952153165 | Val Loss: 0.08673497963782566\n",
      "Validation loss decreased (0.086866 --> 0.086735).  Saving model ...\n",
      "Updating learning rate to 7.8125e-06\n",
      "Epoch 7 | Train Loss: 0.09067808874405313 | Val Loss: 0.08651525614095082\n",
      "Validation loss decreased (0.086735 --> 0.086515).  Saving model ...\n",
      "Updating learning rate to 3.90625e-06\n",
      "Epoch 8 | Train Loss: 0.09061364307231509 | Val Loss: 0.08648483088635449\n",
      "Validation loss decreased (0.086515 --> 0.086485).  Saving model ...\n",
      "Updating learning rate to 1.953125e-06\n",
      "Epoch 9 | Train Loss: 0.0906093692042164 | Val Loss: 0.08646370627977183\n",
      "Validation loss decreased (0.086485 --> 0.086464).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "\n",
    "seq_len = 336\n",
    "pred_len = 96  \n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual, learning_rate, lradj, patience, save_path, attach_pv):\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len  \n",
    "        self.enc_in = enc_in\n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv = attach_pv\n",
    "\n",
    "configs = Configs(seq_len=seq_len, pred_len=pred_len, enc_in=1, individual=False,\n",
    "                   learning_rate=0.0005, lradj='type1',  patience=3, save_path=\"./model_ETTm2\", attach_pv=False) \n",
    "\n",
    "\n",
    "\n",
    "model = Model(configs).to(device)\n",
    "loss_function = nn.MSELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=configs.learning_rate)\n",
    "\n",
    "if not os.path.exists(configs.save_path):\n",
    "    os.makedirs(configs.save_path)\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model, path):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, path):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), os.path.join(path, 'checkpoint_ES.pth'))\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    if args.lradj == 'type1':\n",
    "        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "    elif args.lradj == 'type2':\n",
    "        lr_adjust = {\n",
    "            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "            10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "        }\n",
    "    elif args.lradj == '3':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 10 else args.learning_rate*0.1}\n",
    "    elif args.lradj == '4':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 15 else args.learning_rate*0.1}\n",
    "    elif args.lradj == '5':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 25 else args.learning_rate*0.1}\n",
    "    elif args.lradj == '6':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 5 else args.learning_rate*0.1}  \n",
    "\n",
    "    if epoch in lr_adjust.keys():\n",
    "        lr = lr_adjust[epoch]\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        print(f'Updating learning rate to {lr}')\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, val_dataloader, optimizer, loss_function, epochs, pred_len, args):\n",
    "    early_stopping = EarlyStopping(patience=args.patience, verbose=True)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        \n",
    "        adjust_learning_rate(optimizer, epoch, args)\n",
    "        \n",
    "        for batch_sequences, batch_labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            output = model(batch_sequences)\n",
    "            \n",
    "            \n",
    "            \n",
    "            output = output[:, -pred_len:, :]  \n",
    "            batch_labels = batch_labels[:, -pred_len:, :]  \n",
    "            \n",
    "            \n",
    "            assert output.shape == batch_labels.shape, f\"Output shape {output.shape} and batch_labels shape {batch_labels.shape} must match\"\n",
    "            \n",
    "            loss = loss_function(output, batch_labels)  \n",
    "            \n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        \n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_batch_sequences, val_batch_labels in val_dataloader:\n",
    "                val_output = model(val_batch_sequences)\n",
    "                val_output = val_output[:, -args.pred_len:, :]\n",
    "                val_batch_labels = val_batch_labels[:, -args.pred_len:, :]\n",
    "                \n",
    "                val_loss += loss_function(val_output, val_batch_labels).item()\n",
    "        \n",
    "        val_loss /= len(val_dataloader)\n",
    "\n",
    "        \n",
    "        print(f'Epoch {epoch} | Train Loss: {total_loss / len(dataloader)} | Val Loss: {val_loss}')\n",
    "        \n",
    "        \n",
    "        early_stopping(val_loss, model, args.save_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered. Stopping training.\")\n",
    "            break\n",
    "\n",
    "\n",
    "train_model(model, train_dataloader, val_dataloader, optimizer, loss_function, epochs=10, pred_len=configs.pred_len, args=configs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c32056",
   "metadata": {},
   "source": [
    "# 1st Model Training (1 Epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b696a779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating learning rate to 0.001\n",
      "Epoch 0 | Train Loss: 0.11021939110649782 | Val Loss: 0.09497767913496048\n",
      "Model saved at epoch 1\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "seq_len = 336\n",
    "pred_len = 96  \n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual, learning_rate, lradj, patience, save_path, attach_pv):\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len  \n",
    "        self.enc_in = enc_in\n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv = attach_pv\n",
    "\n",
    "configs = Configs(seq_len=seq_len, pred_len=pred_len, enc_in=1, individual=False,\n",
    "                   learning_rate=0.0005, lradj='type1',  patience=3, save_path=\"./model_ETTm2\", attach_pv=False) \n",
    "\n",
    "\n",
    "model = Model(configs).to(device)\n",
    "loss_function = nn.MSELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=configs.learning_rate)\n",
    "\n",
    "if not os.path.exists(configs.save_path):\n",
    "    os.makedirs(configs.save_path)\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    if args.lradj == 'type1':\n",
    "        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "    elif args.lradj == 'type2':\n",
    "        lr_adjust = {\n",
    "            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "            10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "        }\n",
    "    elif args.lradj == '3':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 10 else args.learning_rate*0.1}\n",
    "    elif args.lradj == '4':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 15 else args.learning_rate*0.1}\n",
    "    elif args.lradj == '5':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 25 else args.learning_rate*0.1}\n",
    "    elif args.lradj == '6':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 5 else args.learning_rate*0.1}  \n",
    "\n",
    "    if epoch in lr_adjust.keys():\n",
    "        lr = lr_adjust[epoch]\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        print(f'Updating learning rate to {lr}')\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, val_dataloader, optimizer, loss_function, epochs, pred_len, args):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        if epoch == 1:\n",
    "            torch.save(model.state_dict(), os.path.join(args.save_path, 'checkpoint_1.pth'))\n",
    "            print(\"Model saved at epoch 1\")\n",
    "\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        \n",
    "        adjust_learning_rate(optimizer, epoch, args)\n",
    "        \n",
    "        for batch_sequences, batch_labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            output = model(batch_sequences)\n",
    "            \n",
    "            \n",
    "            \n",
    "            output = output[:, -pred_len:, :]  \n",
    "            batch_labels = batch_labels[:, -pred_len:, :]  \n",
    "            \n",
    "            \n",
    "            assert output.shape == batch_labels.shape, f\"Output shape {output.shape} and batch_labels shape {batch_labels.shape} must match\"\n",
    "            \n",
    "            loss = loss_function(output, batch_labels)  \n",
    "            \n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        \n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_batch_sequences, val_batch_labels in val_dataloader:\n",
    "                val_output = model(val_batch_sequences)\n",
    "                val_output = val_output[:, -args.pred_len:, :]\n",
    "                val_batch_labels = val_batch_labels[:, -args.pred_len:, :]\n",
    "                \n",
    "                val_loss += loss_function(val_output, val_batch_labels).item()\n",
    "        \n",
    "        val_loss /= len(val_dataloader)\n",
    "\n",
    "        \n",
    "        print(f'Epoch {epoch} | Train Loss: {total_loss / len(dataloader)} | Val Loss: {val_loss}')\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(args.save_path, f'checkpoint_{epochs}.pth'))\n",
    "    print(f\"Model saved at epoch {epochs}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "train_model(model, train_dataloader, val_dataloader, optimizer, loss_function, epochs=1, pred_len=configs.pred_len, args=configs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c20f7c5",
   "metadata": {},
   "source": [
    "# Perform Inference and Form Predicted Value (PV) Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c6e7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Predicting with model from epoch ES]\n",
      "Epoch ES | MSE: 0.06621406972408295 | MAE: 0.18940357863903046\n",
      "\n",
      "[Predicting with model from epoch 1]\n",
      "Epoch 1 | MSE: 0.08020953088998795 | MAE: 0.2136436551809311\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "\n",
    "\n",
    "checkpoint_epochs = ['ES', 1]\n",
    "\n",
    "\n",
    "test_1st_results = {}\n",
    "\n",
    "for ckpt_epoch in checkpoint_epochs:\n",
    "    print(f'\\n[Predicting with model from epoch {ckpt_epoch}]')\n",
    "\n",
    "    \n",
    "    model_path = os.path.join(configs.save_path, f'checkpoint_{ckpt_epoch}.pth')\n",
    "    \n",
    "    model = Model(configs).to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_sequence, batch_label in test_dataloader:\n",
    "            batch_sequence = batch_sequence.float().to(device)\n",
    "            batch_label = batch_label.float().to(device)\n",
    "\n",
    "            output = model(batch_sequence)\n",
    "            output = output[:, -configs.pred_len:, :]\n",
    "            batch_label = batch_label[:, -configs.pred_len:, :]\n",
    "\n",
    "            predictions.append(output.detach().cpu().numpy())\n",
    "            actuals.append(batch_label.detach().cpu().numpy())\n",
    "\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)  \n",
    "    actuals = np.concatenate(actuals, axis=0)\n",
    "\n",
    "    \n",
    "    predictions_flatten = predictions.flatten()\n",
    "    actuals_flatten = actuals.flatten()\n",
    "\n",
    "    \n",
    "    mse = mean_squared_error(actuals_flatten, predictions_flatten)\n",
    "    mae = mean_absolute_error(actuals_flatten, predictions_flatten)\n",
    "\n",
    "    print(f'Epoch {ckpt_epoch} | MSE: {mse} | MAE: {mae}')\n",
    "\n",
    "    \n",
    "    num_samples = len(predictions_flatten) // configs.pred_len\n",
    "    test_pv = torch.tensor(\n",
    "        predictions_flatten.reshape(num_samples, configs.pred_len, 1),\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    \n",
    "    test_1st_results[ckpt_epoch] = {\n",
    "        f'mse_test_E{ckpt_epoch}': mse,\n",
    "        f'mae_test_E{ckpt_epoch}': mae,\n",
    "        f'test_pv_E{ckpt_epoch}': test_pv\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "499483e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ES', 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1st_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45838c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Predicting with model from epoch ES]\n",
      "Epoch ES | MSE: 0.08658318966627121 | MAE: 0.20758093893527985\n",
      "\n",
      "[Predicting with model from epoch 1]\n",
      "Epoch 1 | MSE: 0.09512759745121002 | MAE: 0.22909186780452728\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "\n",
    "\n",
    "checkpoint_epochs = ['ES', 1]\n",
    "\n",
    "\n",
    "val_1st_results = {}\n",
    "\n",
    "for ckpt_epoch in checkpoint_epochs:\n",
    "    print(f'\\n[Predicting with model from epoch {ckpt_epoch}]')\n",
    "\n",
    "    \n",
    "    model_path = os.path.join(configs.save_path, f'checkpoint_{ckpt_epoch}.pth')\n",
    "    \n",
    "    model = Model(configs).to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_sequence, batch_label in val_dataloader:\n",
    "            batch_sequence = batch_sequence.float().to(device)\n",
    "            batch_label = batch_label.float().to(device)\n",
    "\n",
    "            output = model(batch_sequence)\n",
    "            output = output[:, -configs.pred_len:, :]\n",
    "            batch_label = batch_label[:, -configs.pred_len:, :]\n",
    "\n",
    "            predictions.append(output.detach().cpu().numpy())\n",
    "            actuals.append(batch_label.detach().cpu().numpy())\n",
    "\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)  \n",
    "    actuals = np.concatenate(actuals, axis=0)\n",
    "\n",
    "    \n",
    "    predictions_flatten = predictions.flatten()\n",
    "    actuals_flatten = actuals.flatten()\n",
    "\n",
    "    \n",
    "    mse = mean_squared_error(actuals_flatten, predictions_flatten)\n",
    "    mae = mean_absolute_error(actuals_flatten, predictions_flatten)\n",
    "\n",
    "    print(f'Epoch {ckpt_epoch} | MSE: {mse} | MAE: {mae}')\n",
    "\n",
    "    \n",
    "    num_samples = len(predictions_flatten) // configs.pred_len\n",
    "    val_pv = torch.tensor(\n",
    "        predictions_flatten.reshape(num_samples, configs.pred_len, 1),\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    \n",
    "    val_1st_results[ckpt_epoch] = {\n",
    "        f'mse_val_E{ckpt_epoch}': mse,\n",
    "        f'mae_val_E{ckpt_epoch}': mae,\n",
    "        f'val_pv_E{ckpt_epoch}': val_pv\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c6dc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Predicting with model from epoch ES]\n",
      "Epoch ES | MSE: 0.09059984236955643 | MAE: 0.21036852896213531\n",
      "\n",
      "[Predicting with model from epoch 1]\n",
      "Epoch 1 | MSE: 0.09867849946022034 | MAE: 0.22778195142745972\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "\n",
    "\n",
    "train_dataloader_infer = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "checkpoint_epochs = ['ES', 1]\n",
    "\n",
    "\n",
    "train_1st_results = {}\n",
    "\n",
    "for ckpt_epoch in checkpoint_epochs:\n",
    "    print(f'\\n[Predicting with model from epoch {ckpt_epoch}]')\n",
    "\n",
    "    \n",
    "    model_path = os.path.join(configs.save_path, f'checkpoint_{ckpt_epoch}.pth')\n",
    "    \n",
    "    model = Model(configs).to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_sequence, batch_label in train_dataloader_infer:\n",
    "            batch_sequence = batch_sequence.float().to(device)\n",
    "            batch_label = batch_label.float().to(device)\n",
    "\n",
    "            output = model(batch_sequence)\n",
    "            output = output[:, -configs.pred_len:, :]\n",
    "            batch_label = batch_label[:, -configs.pred_len:, :]\n",
    "\n",
    "            predictions.append(output.detach().cpu().numpy())\n",
    "            actuals.append(batch_label.detach().cpu().numpy())\n",
    "\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)  \n",
    "    actuals = np.concatenate(actuals, axis=0)\n",
    "\n",
    "    \n",
    "    predictions_flatten = predictions.flatten()\n",
    "    actuals_flatten = actuals.flatten()\n",
    "\n",
    "    \n",
    "    mse = mean_squared_error(actuals_flatten, predictions_flatten)\n",
    "    mae = mean_absolute_error(actuals_flatten, predictions_flatten)\n",
    "\n",
    "    print(f'Epoch {ckpt_epoch} | MSE: {mse} | MAE: {mae}')\n",
    "\n",
    "    \n",
    "    num_samples = len(predictions_flatten) // configs.pred_len\n",
    "    train_pv = torch.tensor(\n",
    "        predictions_flatten.reshape(num_samples, configs.pred_len, 1),\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    \n",
    "    train_1st_results[ckpt_epoch] = {\n",
    "        f'mse_train_E{ckpt_epoch}': mse,\n",
    "        f'mae_train_E{ckpt_epoch}': mae,\n",
    "        f'train_pv_E{ckpt_epoch}': train_pv\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7b146ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sequences shape:  torch.Size([34129, 336, 1])\n",
      "val_sequences shape:  torch.Size([11425, 336, 1])\n",
      "test_sequences shape:  torch.Size([11425, 336, 1])\n",
      "---------------------------------------------\n",
      "train_pv shape:  torch.Size([34129, 96, 1])\n",
      "val_pv shape:  torch.Size([11425, 96, 1])\n",
      "test_pv shape:  torch.Size([11425, 96, 1])\n",
      "---------------------------------------------\n",
      "train_labels shape:  torch.Size([34129, 96, 1])\n",
      "val_labels shape:  torch.Size([11425, 96, 1])\n",
      "test_labels shape:  torch.Size([11425, 96, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"train_sequences shape: \",train_sequences.shape)\n",
    "print(\"val_sequences shape: \",val_sequences.shape)\n",
    "print(\"test_sequences shape: \",test_sequences.shape)\n",
    "\n",
    "print('---------------------------------------------')\n",
    "\n",
    "print(\"train_pv shape: \",train_pv.shape)\n",
    "print(\"val_pv shape: \",val_pv.shape)\n",
    "print(\"test_pv shape: \",test_pv.shape)\n",
    "\n",
    "\n",
    "print('---------------------------------------------')\n",
    "\n",
    "print(\"train_labels shape: \",train_labels.shape)\n",
    "print(\"val_labels shape: \",val_labels.shape)\n",
    "print(\"test_labels shape: \",test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa07148b",
   "metadata": {},
   "source": [
    "# Segment Generation Function (sliding window-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d201aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_segments(predictions, labels, segment_length, stride=1):\n",
    "    \"\"\"\n",
    "    시퀀스에 슬라이딩 윈도우를 stride 간격으로 적용하여\n",
    "    (B, num_segments, segment_length, C) 형태로 반환합니다.\n",
    "\n",
    "    Args:\n",
    "        predictions: Tensor of shape (B, T, C)\n",
    "        labels: Tensor of shape (B, T, C)\n",
    "        segment_length: int, 각 세그먼트의 길이 (예: pred_len // 3)\n",
    "        stride: int, 슬라이딩 윈도우 stride 간격\n",
    "\n",
    "    Returns:\n",
    "        pred_segments: (B, num_segments, segment_length, C)\n",
    "        label_segments: (B, num_segments, segment_length, C)\n",
    "    \"\"\"\n",
    "    B, T, C = predictions.shape\n",
    "    num_segments = (T - segment_length) // stride + 1\n",
    "\n",
    "    pred_segments = []\n",
    "    label_segments = []\n",
    "\n",
    "    for i in range(0, T - segment_length + 1, stride):\n",
    "        pred_seg = predictions[:, i:i+segment_length, :]  \n",
    "        label_seg = labels[:, i:i+segment_length, :]      \n",
    "        pred_segments.append(pred_seg.unsqueeze(1))       \n",
    "        label_segments.append(label_seg.unsqueeze(1))\n",
    "\n",
    "    pred_segments = torch.cat(pred_segments, dim=1)       \n",
    "    label_segments = torch.cat(label_segments, dim=1)     \n",
    "\n",
    "    return pred_segments, label_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a08ae3",
   "metadata": {},
   "source": [
    "# Segmentation for PV Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74c7185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs.pred_len "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b357a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch ES] Train seg shape: torch.Size([34129, 65, 32, 1]), Val: torch.Size([11425, 65, 32, 1]), Test: torch.Size([11425, 65, 32, 1])\n",
      "[Epoch 1] Train seg shape: torch.Size([34129, 65, 32, 1]), Val: torch.Size([11425, 65, 32, 1]), Test: torch.Size([11425, 65, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "segment_len = configs.pred_len // 3\n",
    "stride = 1  \n",
    "\n",
    "train_segments_by_epoch = {}\n",
    "val_segments_by_epoch = {}\n",
    "test_segments_by_epoch = {}\n",
    "\n",
    "for epoch in checkpoint_epochs:\n",
    "    train_pv = train_1st_results[epoch][f'train_pv_E{epoch}']  \n",
    "    val_pv = val_1st_results[epoch][f'val_pv_E{epoch}']        \n",
    "    test_pv = test_1st_results[epoch][f'test_pv_E{epoch}']     \n",
    "\n",
    "    \n",
    "    train_pred_segments, train_label_segments = create_sliding_segments(train_pv, train_labels, segment_len,stride)\n",
    "    val_pred_segments, val_label_segments = create_sliding_segments(val_pv, val_labels, segment_len, stride)\n",
    "    test_pred_segments, test_label_segments = create_sliding_segments(test_pv, test_labels, segment_len, stride)\n",
    "\n",
    "    train_segments_by_epoch[epoch] = {\n",
    "        f'train_pred_segments_E{epoch}': train_pred_segments,  \n",
    "        f'train_label_segments_E{epoch}': train_label_segments\n",
    "    }\n",
    "\n",
    "    val_segments_by_epoch[epoch] = {\n",
    "        f'val_pred_segments_E{epoch}': val_pred_segments,\n",
    "        f'val_label_segments_E{epoch}': val_label_segments\n",
    "    }\n",
    "\n",
    "    test_segments_by_epoch[epoch] = {\n",
    "        f'test_pred_segments_E{epoch}': test_pred_segments,\n",
    "        f'test_label_segments_E{epoch}': test_label_segments\n",
    "    }\n",
    "\n",
    "    \n",
    "    print(f\"[Epoch {epoch}] Train seg shape: {train_pred_segments.shape}, Val: {val_pred_segments.shape}, Test: {test_pred_segments.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40799fae",
   "metadata": {},
   "source": [
    "## Save 1st Performance Metrics, PV, and Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73a22e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All dictionaries saved successfully in ./saved_results\n"
     ]
    }
   ],
   "source": [
    "save_dir = './1st_results_ETTm2'  \n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "torch.save(train_1st_results, os.path.join(save_dir, 'train_1st_results.pt'))\n",
    "torch.save(val_1st_results, os.path.join(save_dir, 'val_1st_results.pt'))\n",
    "torch.save(test_1st_results, os.path.join(save_dir, 'test_1st_results.pt'))\n",
    "\n",
    "\n",
    "torch.save(train_segments_by_epoch, os.path.join(save_dir, 'train_segments_by_epoch.pt'))\n",
    "torch.save(val_segments_by_epoch, os.path.join(save_dir, 'val_segments_by_epoch.pt'))\n",
    "torch.save(test_segments_by_epoch, os.path.join(save_dir, 'test_segments_by_epoch.pt'))\n",
    "\n",
    "print(\"✅ All dictionaries saved successfully in ./saved_results\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a661e719",
   "metadata": {},
   "source": [
    "# 2nd Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f79da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_segments_by_epoch = torch.load('./1st_results_ETTm2/train_segments_by_epoch.pt', weights_only=False)\n",
    "val_segments_by_epoch = torch.load('./1st_results_ETTm2/val_segments_by_epoch.pt', weights_only=False)\n",
    "test_segments_by_epoch = torch.load('./1st_results_ETTm2/test_segments_by_epoch.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd343cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ES', 1])\n",
      "dict_keys(['train_pred_segments_EES', 'train_label_segments_EES'])\n",
      "dict_keys(['train_pred_segments_E1', 'train_label_segments_E1'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_segments_by_epoch.keys())\n",
    "print(train_segments_by_epoch['ES'].keys())\n",
    "print(train_segments_by_epoch[1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ec62a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_pred_segments_ES = train_segments_by_epoch['ES']['train_pred_segments_EES']  \n",
    "train_label_segments_ES = train_segments_by_epoch['ES']['train_label_segments_EES']\n",
    "val_pred_segments_ES = val_segments_by_epoch['ES']['val_pred_segments_EES']  \n",
    "val_label_segments_ES = val_segments_by_epoch['ES']['val_label_segments_EES']\n",
    "test_pred_segments_ES = test_segments_by_epoch['ES']['test_pred_segments_EES']  \n",
    "test_label_segments_ES = test_segments_by_epoch['ES']['test_label_segments_EES']\n",
    "\n",
    "\n",
    "train_pred_segments_E1 = train_segments_by_epoch[1]['train_pred_segments_E1']  \n",
    "train_label_segments_E1 = train_segments_by_epoch[1]['train_label_segments_E1']\n",
    "val_pred_segments_E1 = val_segments_by_epoch[1]['val_pred_segments_E1']  \n",
    "val_label_segments_E1 = val_segments_by_epoch[1]['val_label_segments_E1']\n",
    "test_pred_segments_E1 = test_segments_by_epoch[1]['test_pred_segments_E1']  \n",
    "test_label_segments_E1 = test_segments_by_epoch[1]['test_label_segments_E1']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcab04b9",
   "metadata": {},
   "source": [
    "## ES->1E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0212d24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== Segment 0 ===========\n",
      "[Segment 0] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 0] Training Time = 2.43 sec\n",
      "[Segment 0] GPU Memory Start = 1467.87 MB\n",
      "[Segment 0] GPU Memory End   = 1468.10 MB\n",
      "[Segment 0] GPU Peak Memory  = 1469.22 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 1 ===========\n",
      "[Segment 1] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 1] Training Time = 4.58 sec\n",
      "[Segment 1] GPU Memory Start = 1468.10 MB\n",
      "[Segment 1] GPU Memory End   = 1468.24 MB\n",
      "[Segment 1] GPU Peak Memory  = 1469.36 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 2 ===========\n",
      "[Segment 2] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 2] Training Time = 4.60 sec\n",
      "[Segment 2] GPU Memory Start = 1468.24 MB\n",
      "[Segment 2] GPU Memory End   = 1468.38 MB\n",
      "[Segment 2] GPU Peak Memory  = 1469.49 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 3 ===========\n",
      "[Segment 3] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 3] Training Time = 2.98 sec\n",
      "[Segment 3] GPU Memory Start = 1468.38 MB\n",
      "[Segment 3] GPU Memory End   = 1468.51 MB\n",
      "[Segment 3] GPU Peak Memory  = 1469.63 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 4 ===========\n",
      "[Segment 4] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 4] Training Time = 2.34 sec\n",
      "[Segment 4] GPU Memory Start = 1468.51 MB\n",
      "[Segment 4] GPU Memory End   = 1468.65 MB\n",
      "[Segment 4] GPU Peak Memory  = 1469.76 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 5 ===========\n",
      "[Segment 5] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 5] Training Time = 3.68 sec\n",
      "[Segment 5] GPU Memory Start = 1468.65 MB\n",
      "[Segment 5] GPU Memory End   = 1468.78 MB\n",
      "[Segment 5] GPU Peak Memory  = 1469.90 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 6 ===========\n",
      "[Segment 6] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 6] Training Time = 4.55 sec\n",
      "[Segment 6] GPU Memory Start = 1468.78 MB\n",
      "[Segment 6] GPU Memory End   = 1468.92 MB\n",
      "[Segment 6] GPU Peak Memory  = 1470.03 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 7 ===========\n",
      "[Segment 7] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 7] Training Time = 2.33 sec\n",
      "[Segment 7] GPU Memory Start = 1468.92 MB\n",
      "[Segment 7] GPU Memory End   = 1469.05 MB\n",
      "[Segment 7] GPU Peak Memory  = 1470.17 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 8 ===========\n",
      "[Segment 8] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 8] Training Time = 4.12 sec\n",
      "[Segment 8] GPU Memory Start = 1469.05 MB\n",
      "[Segment 8] GPU Memory End   = 1469.19 MB\n",
      "[Segment 8] GPU Peak Memory  = 1470.30 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 9 ===========\n",
      "[Segment 9] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 9] Training Time = 3.25 sec\n",
      "[Segment 9] GPU Memory Start = 1468.10 MB\n",
      "[Segment 9] GPU Memory End   = 1468.24 MB\n",
      "[Segment 9] GPU Peak Memory  = 1469.36 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 10 ===========\n",
      "[Segment 10] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 10] Training Time = 4.44 sec\n",
      "[Segment 10] GPU Memory Start = 1468.24 MB\n",
      "[Segment 10] GPU Memory End   = 1468.38 MB\n",
      "[Segment 10] GPU Peak Memory  = 1469.49 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 11 ===========\n",
      "[Segment 11] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 11] Training Time = 4.55 sec\n",
      "[Segment 11] GPU Memory Start = 1468.38 MB\n",
      "[Segment 11] GPU Memory End   = 1468.51 MB\n",
      "[Segment 11] GPU Peak Memory  = 1469.63 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 12 ===========\n",
      "[Segment 12] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 12] Training Time = 4.78 sec\n",
      "[Segment 12] GPU Memory Start = 1468.51 MB\n",
      "[Segment 12] GPU Memory End   = 1468.65 MB\n",
      "[Segment 12] GPU Peak Memory  = 1469.76 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 13 ===========\n",
      "[Segment 13] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 13] Training Time = 4.69 sec\n",
      "[Segment 13] GPU Memory Start = 1468.65 MB\n",
      "[Segment 13] GPU Memory End   = 1468.78 MB\n",
      "[Segment 13] GPU Peak Memory  = 1469.90 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 14 ===========\n",
      "[Segment 14] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 14] Training Time = 4.84 sec\n",
      "[Segment 14] GPU Memory Start = 1468.78 MB\n",
      "[Segment 14] GPU Memory End   = 1468.92 MB\n",
      "[Segment 14] GPU Peak Memory  = 1470.03 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 15 ===========\n",
      "[Segment 15] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 15] Training Time = 3.92 sec\n",
      "[Segment 15] GPU Memory Start = 1468.92 MB\n",
      "[Segment 15] GPU Memory End   = 1469.05 MB\n",
      "[Segment 15] GPU Peak Memory  = 1470.17 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 16 ===========\n",
      "[Segment 16] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 16] Training Time = 4.69 sec\n",
      "[Segment 16] GPU Memory Start = 1469.05 MB\n",
      "[Segment 16] GPU Memory End   = 1469.19 MB\n",
      "[Segment 16] GPU Peak Memory  = 1470.30 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 17 ===========\n",
      "[Segment 17] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 17] Training Time = 4.77 sec\n",
      "[Segment 17] GPU Memory Start = 1469.19 MB\n",
      "[Segment 17] GPU Memory End   = 1469.32 MB\n",
      "[Segment 17] GPU Peak Memory  = 1470.44 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 18 ===========\n",
      "[Segment 18] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 18] Training Time = 4.92 sec\n",
      "[Segment 18] GPU Memory Start = 1469.32 MB\n",
      "[Segment 18] GPU Memory End   = 1469.46 MB\n",
      "[Segment 18] GPU Peak Memory  = 1470.57 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 19 ===========\n",
      "[Segment 19] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 19] Training Time = 4.77 sec\n",
      "[Segment 19] GPU Memory Start = 1468.10 MB\n",
      "[Segment 19] GPU Memory End   = 1468.24 MB\n",
      "[Segment 19] GPU Peak Memory  = 1469.36 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 20 ===========\n",
      "[Segment 20] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 20] Training Time = 4.78 sec\n",
      "[Segment 20] GPU Memory Start = 1468.24 MB\n",
      "[Segment 20] GPU Memory End   = 1468.38 MB\n",
      "[Segment 20] GPU Peak Memory  = 1469.49 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 21 ===========\n",
      "[Segment 21] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 21] Training Time = 4.25 sec\n",
      "[Segment 21] GPU Memory Start = 1468.38 MB\n",
      "[Segment 21] GPU Memory End   = 1468.51 MB\n",
      "[Segment 21] GPU Peak Memory  = 1469.63 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 22 ===========\n",
      "[Segment 22] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 22] Training Time = 4.82 sec\n",
      "[Segment 22] GPU Memory Start = 1468.51 MB\n",
      "[Segment 22] GPU Memory End   = 1468.65 MB\n",
      "[Segment 22] GPU Peak Memory  = 1469.76 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 23 ===========\n",
      "[Segment 23] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 23] Training Time = 4.87 sec\n",
      "[Segment 23] GPU Memory Start = 1468.65 MB\n",
      "[Segment 23] GPU Memory End   = 1468.78 MB\n",
      "[Segment 23] GPU Peak Memory  = 1469.90 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 24 ===========\n",
      "[Segment 24] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 24] Training Time = 4.69 sec\n",
      "[Segment 24] GPU Memory Start = 1468.78 MB\n",
      "[Segment 24] GPU Memory End   = 1468.92 MB\n",
      "[Segment 24] GPU Peak Memory  = 1470.03 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 25 ===========\n",
      "[Segment 25] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 25] Training Time = 4.95 sec\n",
      "[Segment 25] GPU Memory Start = 1468.92 MB\n",
      "[Segment 25] GPU Memory End   = 1469.05 MB\n",
      "[Segment 25] GPU Peak Memory  = 1470.17 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 26 ===========\n",
      "[Segment 26] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 26] Training Time = 4.38 sec\n",
      "[Segment 26] GPU Memory Start = 1469.05 MB\n",
      "[Segment 26] GPU Memory End   = 1469.19 MB\n",
      "[Segment 26] GPU Peak Memory  = 1470.30 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 27 ===========\n",
      "[Segment 27] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 27] Training Time = 4.96 sec\n",
      "[Segment 27] GPU Memory Start = 1469.19 MB\n",
      "[Segment 27] GPU Memory End   = 1469.32 MB\n",
      "[Segment 27] GPU Peak Memory  = 1470.44 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 28 ===========\n",
      "[Segment 28] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 28] Training Time = 4.09 sec\n",
      "[Segment 28] GPU Memory Start = 1469.32 MB\n",
      "[Segment 28] GPU Memory End   = 1469.46 MB\n",
      "[Segment 28] GPU Peak Memory  = 1470.57 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 29 ===========\n",
      "[Segment 29] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 29] Training Time = 4.86 sec\n",
      "[Segment 29] GPU Memory Start = 1468.10 MB\n",
      "[Segment 29] GPU Memory End   = 1468.24 MB\n",
      "[Segment 29] GPU Peak Memory  = 1469.36 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 30 ===========\n",
      "[Segment 30] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 30] Training Time = 4.88 sec\n",
      "[Segment 30] GPU Memory Start = 1468.24 MB\n",
      "[Segment 30] GPU Memory End   = 1468.38 MB\n",
      "[Segment 30] GPU Peak Memory  = 1469.49 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 31 ===========\n",
      "[Segment 31] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 31] Training Time = 4.91 sec\n",
      "[Segment 31] GPU Memory Start = 1468.38 MB\n",
      "[Segment 31] GPU Memory End   = 1468.51 MB\n",
      "[Segment 31] GPU Peak Memory  = 1469.63 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 32 ===========\n",
      "[Segment 32] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 32] Training Time = 4.72 sec\n",
      "[Segment 32] GPU Memory Start = 1468.51 MB\n",
      "[Segment 32] GPU Memory End   = 1468.65 MB\n",
      "[Segment 32] GPU Peak Memory  = 1469.76 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 33 ===========\n",
      "[Segment 33] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 33] Training Time = 4.59 sec\n",
      "[Segment 33] GPU Memory Start = 1468.65 MB\n",
      "[Segment 33] GPU Memory End   = 1468.78 MB\n",
      "[Segment 33] GPU Peak Memory  = 1469.90 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 34 ===========\n",
      "[Segment 34] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 34] Training Time = 4.70 sec\n",
      "[Segment 34] GPU Memory Start = 1468.78 MB\n",
      "[Segment 34] GPU Memory End   = 1468.92 MB\n",
      "[Segment 34] GPU Peak Memory  = 1470.03 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 35 ===========\n",
      "[Segment 35] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 35] Training Time = 3.61 sec\n",
      "[Segment 35] GPU Memory Start = 1468.92 MB\n",
      "[Segment 35] GPU Memory End   = 1469.05 MB\n",
      "[Segment 35] GPU Peak Memory  = 1470.17 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 36 ===========\n",
      "[Segment 36] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 36] Training Time = 2.67 sec\n",
      "[Segment 36] GPU Memory Start = 1469.05 MB\n",
      "[Segment 36] GPU Memory End   = 1469.19 MB\n",
      "[Segment 36] GPU Peak Memory  = 1470.30 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 37 ===========\n",
      "[Segment 37] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 37] Training Time = 4.73 sec\n",
      "[Segment 37] GPU Memory Start = 1469.19 MB\n",
      "[Segment 37] GPU Memory End   = 1469.32 MB\n",
      "[Segment 37] GPU Peak Memory  = 1470.44 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 38 ===========\n",
      "[Segment 38] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 38] Training Time = 4.89 sec\n",
      "[Segment 38] GPU Memory Start = 1469.32 MB\n",
      "[Segment 38] GPU Memory End   = 1469.46 MB\n",
      "[Segment 38] GPU Peak Memory  = 1470.57 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 39 ===========\n",
      "[Segment 39] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 39] Training Time = 4.81 sec\n",
      "[Segment 39] GPU Memory Start = 1468.10 MB\n",
      "[Segment 39] GPU Memory End   = 1468.24 MB\n",
      "[Segment 39] GPU Peak Memory  = 1469.36 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 40 ===========\n",
      "[Segment 40] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 40] Training Time = 4.49 sec\n",
      "[Segment 40] GPU Memory Start = 1468.24 MB\n",
      "[Segment 40] GPU Memory End   = 1468.38 MB\n",
      "[Segment 40] GPU Peak Memory  = 1469.49 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 41 ===========\n",
      "[Segment 41] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 41] Training Time = 4.86 sec\n",
      "[Segment 41] GPU Memory Start = 1468.38 MB\n",
      "[Segment 41] GPU Memory End   = 1468.51 MB\n",
      "[Segment 41] GPU Peak Memory  = 1469.63 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 42 ===========\n",
      "[Segment 42] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 42] Training Time = 4.29 sec\n",
      "[Segment 42] GPU Memory Start = 1468.51 MB\n",
      "[Segment 42] GPU Memory End   = 1468.65 MB\n",
      "[Segment 42] GPU Peak Memory  = 1469.76 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 43 ===========\n",
      "[Segment 43] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 43] Training Time = 4.47 sec\n",
      "[Segment 43] GPU Memory Start = 1468.65 MB\n",
      "[Segment 43] GPU Memory End   = 1468.78 MB\n",
      "[Segment 43] GPU Peak Memory  = 1469.90 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 44 ===========\n",
      "[Segment 44] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 44] Training Time = 4.88 sec\n",
      "[Segment 44] GPU Memory Start = 1468.78 MB\n",
      "[Segment 44] GPU Memory End   = 1468.92 MB\n",
      "[Segment 44] GPU Peak Memory  = 1470.03 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 45 ===========\n",
      "[Segment 45] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 45] Training Time = 2.69 sec\n",
      "[Segment 45] GPU Memory Start = 1468.92 MB\n",
      "[Segment 45] GPU Memory End   = 1469.05 MB\n",
      "[Segment 45] GPU Peak Memory  = 1470.17 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 46 ===========\n",
      "[Segment 46] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 46] Training Time = 4.85 sec\n",
      "[Segment 46] GPU Memory Start = 1469.05 MB\n",
      "[Segment 46] GPU Memory End   = 1469.19 MB\n",
      "[Segment 46] GPU Peak Memory  = 1470.30 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 47 ===========\n",
      "[Segment 47] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 47] Training Time = 4.83 sec\n",
      "[Segment 47] GPU Memory Start = 1469.19 MB\n",
      "[Segment 47] GPU Memory End   = 1469.32 MB\n",
      "[Segment 47] GPU Peak Memory  = 1470.44 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 48 ===========\n",
      "[Segment 48] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 48] Training Time = 5.11 sec\n",
      "[Segment 48] GPU Memory Start = 1469.32 MB\n",
      "[Segment 48] GPU Memory End   = 1468.10 MB\n",
      "[Segment 48] GPU Peak Memory  = 1469.46 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 49 ===========\n",
      "[Segment 49] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 49] Training Time = 4.58 sec\n",
      "[Segment 49] GPU Memory Start = 1468.10 MB\n",
      "[Segment 49] GPU Memory End   = 1468.24 MB\n",
      "[Segment 49] GPU Peak Memory  = 1469.36 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 50 ===========\n",
      "[Segment 50] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 50] Training Time = 4.77 sec\n",
      "[Segment 50] GPU Memory Start = 1468.24 MB\n",
      "[Segment 50] GPU Memory End   = 1468.38 MB\n",
      "[Segment 50] GPU Peak Memory  = 1469.49 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 51 ===========\n",
      "[Segment 51] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 51] Training Time = 4.94 sec\n",
      "[Segment 51] GPU Memory Start = 1468.38 MB\n",
      "[Segment 51] GPU Memory End   = 1468.51 MB\n",
      "[Segment 51] GPU Peak Memory  = 1469.63 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 52 ===========\n",
      "[Segment 52] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 52] Training Time = 4.82 sec\n",
      "[Segment 52] GPU Memory Start = 1468.51 MB\n",
      "[Segment 52] GPU Memory End   = 1468.65 MB\n",
      "[Segment 52] GPU Peak Memory  = 1469.76 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 53 ===========\n",
      "[Segment 53] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 53] Training Time = 4.99 sec\n",
      "[Segment 53] GPU Memory Start = 1468.65 MB\n",
      "[Segment 53] GPU Memory End   = 1468.78 MB\n",
      "[Segment 53] GPU Peak Memory  = 1469.90 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 54 ===========\n",
      "[Segment 54] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 54] Training Time = 3.33 sec\n",
      "[Segment 54] GPU Memory Start = 1468.78 MB\n",
      "[Segment 54] GPU Memory End   = 1468.92 MB\n",
      "[Segment 54] GPU Peak Memory  = 1470.03 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 55 ===========\n",
      "[Segment 55] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 55] Training Time = 4.65 sec\n",
      "[Segment 55] GPU Memory Start = 1468.92 MB\n",
      "[Segment 55] GPU Memory End   = 1469.05 MB\n",
      "[Segment 55] GPU Peak Memory  = 1470.17 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 56 ===========\n",
      "[Segment 56] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 56] Training Time = 4.84 sec\n",
      "[Segment 56] GPU Memory Start = 1469.05 MB\n",
      "[Segment 56] GPU Memory End   = 1469.19 MB\n",
      "[Segment 56] GPU Peak Memory  = 1470.30 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 57 ===========\n",
      "[Segment 57] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 57] Training Time = 4.79 sec\n",
      "[Segment 57] GPU Memory Start = 1469.19 MB\n",
      "[Segment 57] GPU Memory End   = 1469.32 MB\n",
      "[Segment 57] GPU Peak Memory  = 1470.44 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 58 ===========\n",
      "[Segment 58] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 58] Training Time = 2.45 sec\n",
      "[Segment 58] GPU Memory Start = 1469.32 MB\n",
      "[Segment 58] GPU Memory End   = 1468.10 MB\n",
      "[Segment 58] GPU Peak Memory  = 1469.34 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 59 ===========\n",
      "[Segment 59] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 59] Training Time = 4.71 sec\n",
      "[Segment 59] GPU Memory Start = 1468.10 MB\n",
      "[Segment 59] GPU Memory End   = 1468.24 MB\n",
      "[Segment 59] GPU Peak Memory  = 1469.36 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 60 ===========\n",
      "[Segment 60] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 60] Training Time = 4.61 sec\n",
      "[Segment 60] GPU Memory Start = 1468.24 MB\n",
      "[Segment 60] GPU Memory End   = 1468.38 MB\n",
      "[Segment 60] GPU Peak Memory  = 1469.49 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 61 ===========\n",
      "[Segment 61] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 61] Training Time = 4.83 sec\n",
      "[Segment 61] GPU Memory Start = 1468.38 MB\n",
      "[Segment 61] GPU Memory End   = 1468.51 MB\n",
      "[Segment 61] GPU Peak Memory  = 1469.63 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 62 ===========\n",
      "[Segment 62] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 62] Training Time = 3.93 sec\n",
      "[Segment 62] GPU Memory Start = 1468.51 MB\n",
      "[Segment 62] GPU Memory End   = 1468.65 MB\n",
      "[Segment 62] GPU Peak Memory  = 1469.76 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 63 ===========\n",
      "[Segment 63] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 63] Training Time = 4.42 sec\n",
      "[Segment 63] GPU Memory Start = 1468.65 MB\n",
      "[Segment 63] GPU Memory End   = 1468.78 MB\n",
      "[Segment 63] GPU Peak Memory  = 1469.90 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 64 ===========\n",
      "[Segment 64] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 64] Training Time = 4.86 sec\n",
      "[Segment 64] GPU Memory Start = 1468.78 MB\n",
      "[Segment 64] GPU Memory End   = 1468.92 MB\n",
      "[Segment 64] GPU Peak Memory  = 1470.03 MB\n",
      "\n",
      "============= Done =============\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "\n",
    "epo = 'ES'\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual,\n",
    "                 learning_rate, lradj, patience,\n",
    "                 save_path, attach_pv):\n",
    "        self.seq_len  = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in   = enc_in          \n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv    = attach_pv\n",
    "\n",
    "\n",
    "\n",
    "base_cfg = Configs(\n",
    "    seq_len          = 336 ,\n",
    "    pred_len         = 96,\n",
    "    enc_in           = 1,\n",
    "    individual       = True,\n",
    "    learning_rate    = 0.001,\n",
    "    lradj            = 'type1',\n",
    "    patience         = 3,\n",
    "    save_path        = f\"./model2_ETTm2_E{epo}_1E\",\n",
    "    attach_pv  = True,\n",
    ")\n",
    "Path(base_cfg.save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "for seg in range(len(train_pred_segments_ES[0])):\n",
    "    print(f\"\\n=========== Segment {seg} ===========\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    mem_start = torch.cuda.memory_allocated(device)\n",
    "\n",
    "    \n",
    "    tr_pv = train_pred_segments_ES[:, seg, :, :]   \n",
    "    va_pv = val_pred_segments_ES[:,  seg, :, :]\n",
    "\n",
    "    tr_ds = TensorDataset(train_sequences, train_labels, tr_pv)\n",
    "    va_ds = TensorDataset(val_sequences,   val_labels,   va_pv)\n",
    "    tr_dl = DataLoader(tr_ds, batch_size=32, shuffle=True)\n",
    "    va_dl = DataLoader(va_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "    \n",
    "    model = Model(base_cfg).to(device)\n",
    "    C     = model.channels                                    \n",
    "\n",
    "    opts = []\n",
    "    for c in range(C):\n",
    "        params = list(model.Linear[c].parameters())\n",
    "        opts.append(optim.Adam(params, lr=base_cfg.learning_rate))\n",
    "        path = Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{c}\"\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    active = set(range(C))            \n",
    "\n",
    "    \n",
    "    for epoch in range(1, 2):\n",
    "        if not active: break          \n",
    "\n",
    "        \n",
    "        model.train()\n",
    "        for c in active:                              \n",
    "            if base_cfg.lradj=='type1':\n",
    "                lr = base_cfg.learning_rate * 0.5**((epoch-1)//1)\n",
    "                for g in opts[c].param_groups: g['lr'] = lr\n",
    "\n",
    "        printed_tensor_info = False  \n",
    "\n",
    "        for xb, yb, pv in tr_dl:\n",
    "            xb, yb, pv = xb.float().to(device), yb.float().to(device), pv.float().to(device)\n",
    "\n",
    "            if not printed_tensor_info:\n",
    "                \n",
    "                xb_size = xb.numel() * xb.element_size() / 1024**2\n",
    "                yb_size = yb.numel() * yb.element_size() / 1024**2\n",
    "                pv_size = pv.numel() * pv.element_size() / 1024**2\n",
    "\n",
    "                \n",
    "                \n",
    "                num_batches = len(tr_dl)\n",
    "\n",
    "                \n",
    "                total_xb_MB = num_batches * xb_size\n",
    "                total_yb_MB = num_batches * yb_size\n",
    "                total_pv_MB = num_batches * pv_size\n",
    "                \n",
    "\n",
    "\n",
    "                print(f\"[Segment {seg}] Batch Size Info:\")\n",
    "                print(f\"  xb per batch = {xb_size:.4f} MB, total = {total_xb_MB:.4f} MB\")\n",
    "                print(f\"  yb per batch = {yb_size:.4f} MB, total = {total_yb_MB:.4f} MB\")\n",
    "                print(f\"  pv per batch = {pv_size:.4f} MB, total = {total_pv_MB:.4f} MB\")\n",
    "\n",
    "                printed_tensor_info = True\n",
    "\n",
    "\n",
    "            out = model(xb, pv)                       \n",
    "\n",
    "            loss_list = []\n",
    "            for c in active:\n",
    "                pred = out[:, -base_cfg.pred_len:, c]\n",
    "                tgt  = yb[:, -base_cfg.pred_len:, c]\n",
    "                loss_list.append(loss_fn(pred, tgt))\n",
    "\n",
    "            total = torch.stack(loss_list).sum()\n",
    "            for opt in opts:\n",
    "                if opt: opt.zero_grad()\n",
    "            total.backward()\n",
    "            for c in active:\n",
    "                opts[c].step()\n",
    "        \n",
    "    elapsed = time.time() - start_time\n",
    "    mem_end = torch.cuda.memory_allocated(device)\n",
    "    peak_mem = torch.cuda.max_memory_allocated(device)\n",
    "\n",
    "\n",
    "    print(f\"[Segment {seg}] Training Time = {elapsed:.2f} sec\")\n",
    "    print(f\"[Segment {seg}] GPU Memory Start = {mem_start/1024**2:.2f} MB\")\n",
    "    print(f\"[Segment {seg}] GPU Memory End   = {mem_end/1024**2:.2f} MB\")\n",
    "    print(f\"[Segment {seg}] GPU Peak Memory  = {peak_mem/1024**2:.2f} MB\")\n",
    "\n",
    "    print(f\"\\n============= Done =============\")\n",
    "\n",
    "    \n",
    "    torch.save(model.state_dict(),\n",
    "                Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{c}\" / \"checkpoint.pth\")\n",
    "    del model, opts; torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c21e3",
   "metadata": {},
   "source": [
    "## 1E->1E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9b5d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== Segment 0 ===========\n",
      "[Segment 0] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 0] Training Time = 4.94 sec\n",
      "[Segment 0] GPU Memory Start = 1468.10 MB\n",
      "[Segment 0] GPU Memory End   = 1468.10 MB\n",
      "[Segment 0] GPU Peak Memory  = 1469.34 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 1 ===========\n",
      "[Segment 1] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 1] Training Time = 4.98 sec\n",
      "[Segment 1] GPU Memory Start = 1468.10 MB\n",
      "[Segment 1] GPU Memory End   = 1468.24 MB\n",
      "[Segment 1] GPU Peak Memory  = 1469.36 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 2 ===========\n",
      "[Segment 2] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 2] Training Time = 4.84 sec\n",
      "[Segment 2] GPU Memory Start = 1468.24 MB\n",
      "[Segment 2] GPU Memory End   = 1468.38 MB\n",
      "[Segment 2] GPU Peak Memory  = 1469.49 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 3 ===========\n",
      "[Segment 3] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 3] Training Time = 4.76 sec\n",
      "[Segment 3] GPU Memory Start = 1468.38 MB\n",
      "[Segment 3] GPU Memory End   = 1468.51 MB\n",
      "[Segment 3] GPU Peak Memory  = 1469.63 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 4 ===========\n",
      "[Segment 4] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 4] Training Time = 2.46 sec\n",
      "[Segment 4] GPU Memory Start = 1468.51 MB\n",
      "[Segment 4] GPU Memory End   = 1468.65 MB\n",
      "[Segment 4] GPU Peak Memory  = 1469.76 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 5 ===========\n",
      "[Segment 5] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 5] Training Time = 4.43 sec\n",
      "[Segment 5] GPU Memory Start = 1468.65 MB\n",
      "[Segment 5] GPU Memory End   = 1468.78 MB\n",
      "[Segment 5] GPU Peak Memory  = 1469.90 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 6 ===========\n",
      "[Segment 6] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 6] Training Time = 4.56 sec\n",
      "[Segment 6] GPU Memory Start = 1468.78 MB\n",
      "[Segment 6] GPU Memory End   = 1468.10 MB\n",
      "[Segment 6] GPU Peak Memory  = 1469.34 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 7 ===========\n",
      "[Segment 7] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 7] Training Time = 4.45 sec\n",
      "[Segment 7] GPU Memory Start = 1468.10 MB\n",
      "[Segment 7] GPU Memory End   = 1468.24 MB\n",
      "[Segment 7] GPU Peak Memory  = 1469.36 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 8 ===========\n",
      "[Segment 8] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 8] Training Time = 4.79 sec\n",
      "[Segment 8] GPU Memory Start = 1468.24 MB\n",
      "[Segment 8] GPU Memory End   = 1468.38 MB\n",
      "[Segment 8] GPU Peak Memory  = 1469.49 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 9 ===========\n",
      "[Segment 9] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 9] Training Time = 4.77 sec\n",
      "[Segment 9] GPU Memory Start = 1468.38 MB\n",
      "[Segment 9] GPU Memory End   = 1468.51 MB\n",
      "[Segment 9] GPU Peak Memory  = 1469.63 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 10 ===========\n",
      "[Segment 10] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 10] Training Time = 4.86 sec\n",
      "[Segment 10] GPU Memory Start = 1468.51 MB\n",
      "[Segment 10] GPU Memory End   = 1468.65 MB\n",
      "[Segment 10] GPU Peak Memory  = 1469.76 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 11 ===========\n",
      "[Segment 11] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 11] Training Time = 4.93 sec\n",
      "[Segment 11] GPU Memory Start = 1468.65 MB\n",
      "[Segment 11] GPU Memory End   = 1468.78 MB\n",
      "[Segment 11] GPU Peak Memory  = 1469.90 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 12 ===========\n",
      "[Segment 12] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 12] Training Time = 4.76 sec\n",
      "[Segment 12] GPU Memory Start = 1468.78 MB\n",
      "[Segment 12] GPU Memory End   = 1468.92 MB\n",
      "[Segment 12] GPU Peak Memory  = 1470.03 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 13 ===========\n",
      "[Segment 13] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 13] Training Time = 4.73 sec\n",
      "[Segment 13] GPU Memory Start = 1468.92 MB\n",
      "[Segment 13] GPU Memory End   = 1469.05 MB\n",
      "[Segment 13] GPU Peak Memory  = 1470.17 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 14 ===========\n",
      "[Segment 14] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 14] Training Time = 4.94 sec\n",
      "[Segment 14] GPU Memory Start = 1469.05 MB\n",
      "[Segment 14] GPU Memory End   = 1469.19 MB\n",
      "[Segment 14] GPU Peak Memory  = 1470.30 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 15 ===========\n",
      "[Segment 15] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 15] Training Time = 4.80 sec\n",
      "[Segment 15] GPU Memory Start = 1469.19 MB\n",
      "[Segment 15] GPU Memory End   = 1469.32 MB\n",
      "[Segment 15] GPU Peak Memory  = 1470.44 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 16 ===========\n",
      "[Segment 16] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 16] Training Time = 4.70 sec\n",
      "[Segment 16] GPU Memory Start = 1469.32 MB\n",
      "[Segment 16] GPU Memory End   = 1468.10 MB\n",
      "[Segment 16] GPU Peak Memory  = 1469.34 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 17 ===========\n",
      "[Segment 17] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 17] Training Time = 4.79 sec\n",
      "[Segment 17] GPU Memory Start = 1468.10 MB\n",
      "[Segment 17] GPU Memory End   = 1468.24 MB\n",
      "[Segment 17] GPU Peak Memory  = 1469.36 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 18 ===========\n",
      "[Segment 18] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 18] Training Time = 2.47 sec\n",
      "[Segment 18] GPU Memory Start = 1468.24 MB\n",
      "[Segment 18] GPU Memory End   = 1468.38 MB\n",
      "[Segment 18] GPU Peak Memory  = 1469.49 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 19 ===========\n",
      "[Segment 19] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 19] Training Time = 2.46 sec\n",
      "[Segment 19] GPU Memory Start = 1468.38 MB\n",
      "[Segment 19] GPU Memory End   = 1468.51 MB\n",
      "[Segment 19] GPU Peak Memory  = 1469.63 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 20 ===========\n",
      "[Segment 20] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 20] Training Time = 4.72 sec\n",
      "[Segment 20] GPU Memory Start = 1468.51 MB\n",
      "[Segment 20] GPU Memory End   = 1468.65 MB\n",
      "[Segment 20] GPU Peak Memory  = 1469.76 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 21 ===========\n",
      "[Segment 21] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 21] Training Time = 4.71 sec\n",
      "[Segment 21] GPU Memory Start = 1468.65 MB\n",
      "[Segment 21] GPU Memory End   = 1468.78 MB\n",
      "[Segment 21] GPU Peak Memory  = 1469.90 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 22 ===========\n",
      "[Segment 22] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 22] Training Time = 4.53 sec\n",
      "[Segment 22] GPU Memory Start = 1468.78 MB\n",
      "[Segment 22] GPU Memory End   = 1468.92 MB\n",
      "[Segment 22] GPU Peak Memory  = 1470.03 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 23 ===========\n",
      "[Segment 23] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 23] Training Time = 4.75 sec\n",
      "[Segment 23] GPU Memory Start = 1468.92 MB\n",
      "[Segment 23] GPU Memory End   = 1469.05 MB\n",
      "[Segment 23] GPU Peak Memory  = 1470.17 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 24 ===========\n",
      "[Segment 24] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 24] Training Time = 4.47 sec\n",
      "[Segment 24] GPU Memory Start = 1469.05 MB\n",
      "[Segment 24] GPU Memory End   = 1469.19 MB\n",
      "[Segment 24] GPU Peak Memory  = 1470.30 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 25 ===========\n",
      "[Segment 25] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 25] Training Time = 4.86 sec\n",
      "[Segment 25] GPU Memory Start = 1469.19 MB\n",
      "[Segment 25] GPU Memory End   = 1469.32 MB\n",
      "[Segment 25] GPU Peak Memory  = 1470.44 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 26 ===========\n",
      "[Segment 26] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 26] Training Time = 4.81 sec\n",
      "[Segment 26] GPU Memory Start = 1469.32 MB\n",
      "[Segment 26] GPU Memory End   = 1468.10 MB\n",
      "[Segment 26] GPU Peak Memory  = 1469.34 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 27 ===========\n",
      "[Segment 27] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 27] Training Time = 4.91 sec\n",
      "[Segment 27] GPU Memory Start = 1468.10 MB\n",
      "[Segment 27] GPU Memory End   = 1468.24 MB\n",
      "[Segment 27] GPU Peak Memory  = 1469.36 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 28 ===========\n",
      "[Segment 28] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 28] Training Time = 4.77 sec\n",
      "[Segment 28] GPU Memory Start = 1468.24 MB\n",
      "[Segment 28] GPU Memory End   = 1468.38 MB\n",
      "[Segment 28] GPU Peak Memory  = 1469.49 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 29 ===========\n",
      "[Segment 29] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 29] Training Time = 3.64 sec\n",
      "[Segment 29] GPU Memory Start = 1468.38 MB\n",
      "[Segment 29] GPU Memory End   = 1468.51 MB\n",
      "[Segment 29] GPU Peak Memory  = 1469.63 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 30 ===========\n",
      "[Segment 30] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 30] Training Time = 3.38 sec\n",
      "[Segment 30] GPU Memory Start = 1468.51 MB\n",
      "[Segment 30] GPU Memory End   = 1468.65 MB\n",
      "[Segment 30] GPU Peak Memory  = 1469.76 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 31 ===========\n",
      "[Segment 31] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 31] Training Time = 4.87 sec\n",
      "[Segment 31] GPU Memory Start = 1468.65 MB\n",
      "[Segment 31] GPU Memory End   = 1468.78 MB\n",
      "[Segment 31] GPU Peak Memory  = 1469.90 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 32 ===========\n",
      "[Segment 32] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 32] Training Time = 4.83 sec\n",
      "[Segment 32] GPU Memory Start = 1468.78 MB\n",
      "[Segment 32] GPU Memory End   = 1468.92 MB\n",
      "[Segment 32] GPU Peak Memory  = 1470.03 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 33 ===========\n",
      "[Segment 33] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 33] Training Time = 4.79 sec\n",
      "[Segment 33] GPU Memory Start = 1468.92 MB\n",
      "[Segment 33] GPU Memory End   = 1469.05 MB\n",
      "[Segment 33] GPU Peak Memory  = 1470.17 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 34 ===========\n",
      "[Segment 34] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 34] Training Time = 4.77 sec\n",
      "[Segment 34] GPU Memory Start = 1469.05 MB\n",
      "[Segment 34] GPU Memory End   = 1469.19 MB\n",
      "[Segment 34] GPU Peak Memory  = 1470.30 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 35 ===========\n",
      "[Segment 35] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 35] Training Time = 3.54 sec\n",
      "[Segment 35] GPU Memory Start = 1469.19 MB\n",
      "[Segment 35] GPU Memory End   = 1469.32 MB\n",
      "[Segment 35] GPU Peak Memory  = 1470.44 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 36 ===========\n",
      "[Segment 36] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 36] Training Time = 5.32 sec\n",
      "[Segment 36] GPU Memory Start = 1469.32 MB\n",
      "[Segment 36] GPU Memory End   = 1468.10 MB\n",
      "[Segment 36] GPU Peak Memory  = 1469.34 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 37 ===========\n",
      "[Segment 37] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 37] Training Time = 3.82 sec\n",
      "[Segment 37] GPU Memory Start = 1468.10 MB\n",
      "[Segment 37] GPU Memory End   = 1468.24 MB\n",
      "[Segment 37] GPU Peak Memory  = 1469.36 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 38 ===========\n",
      "[Segment 38] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 38] Training Time = 5.00 sec\n",
      "[Segment 38] GPU Memory Start = 1468.24 MB\n",
      "[Segment 38] GPU Memory End   = 1468.38 MB\n",
      "[Segment 38] GPU Peak Memory  = 1469.49 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 39 ===========\n",
      "[Segment 39] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 39] Training Time = 4.93 sec\n",
      "[Segment 39] GPU Memory Start = 1468.38 MB\n",
      "[Segment 39] GPU Memory End   = 1468.51 MB\n",
      "[Segment 39] GPU Peak Memory  = 1469.63 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 40 ===========\n",
      "[Segment 40] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 40] Training Time = 2.80 sec\n",
      "[Segment 40] GPU Memory Start = 1468.51 MB\n",
      "[Segment 40] GPU Memory End   = 1468.10 MB\n",
      "[Segment 40] GPU Peak Memory  = 1469.34 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 41 ===========\n",
      "[Segment 41] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 41] Training Time = 4.37 sec\n",
      "[Segment 41] GPU Memory Start = 1468.10 MB\n",
      "[Segment 41] GPU Memory End   = 1468.24 MB\n",
      "[Segment 41] GPU Peak Memory  = 1469.36 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 42 ===========\n",
      "[Segment 42] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 42] Training Time = 2.40 sec\n",
      "[Segment 42] GPU Memory Start = 1468.24 MB\n",
      "[Segment 42] GPU Memory End   = 1468.38 MB\n",
      "[Segment 42] GPU Peak Memory  = 1469.49 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 43 ===========\n",
      "[Segment 43] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 43] Training Time = 4.80 sec\n",
      "[Segment 43] GPU Memory Start = 1468.38 MB\n",
      "[Segment 43] GPU Memory End   = 1468.51 MB\n",
      "[Segment 43] GPU Peak Memory  = 1469.63 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 44 ===========\n",
      "[Segment 44] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 44] Training Time = 4.82 sec\n",
      "[Segment 44] GPU Memory Start = 1468.51 MB\n",
      "[Segment 44] GPU Memory End   = 1468.65 MB\n",
      "[Segment 44] GPU Peak Memory  = 1469.76 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 45 ===========\n",
      "[Segment 45] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 45] Training Time = 2.39 sec\n",
      "[Segment 45] GPU Memory Start = 1468.65 MB\n",
      "[Segment 45] GPU Memory End   = 1468.78 MB\n",
      "[Segment 45] GPU Peak Memory  = 1469.90 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 46 ===========\n",
      "[Segment 46] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 46] Training Time = 4.75 sec\n",
      "[Segment 46] GPU Memory Start = 1468.78 MB\n",
      "[Segment 46] GPU Memory End   = 1468.92 MB\n",
      "[Segment 46] GPU Peak Memory  = 1470.03 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 47 ===========\n",
      "[Segment 47] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 47] Training Time = 4.77 sec\n",
      "[Segment 47] GPU Memory Start = 1468.92 MB\n",
      "[Segment 47] GPU Memory End   = 1469.05 MB\n",
      "[Segment 47] GPU Peak Memory  = 1470.17 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 48 ===========\n",
      "[Segment 48] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 48] Training Time = 3.75 sec\n",
      "[Segment 48] GPU Memory Start = 1469.05 MB\n",
      "[Segment 48] GPU Memory End   = 1469.19 MB\n",
      "[Segment 48] GPU Peak Memory  = 1470.30 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 49 ===========\n",
      "[Segment 49] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 49] Training Time = 4.92 sec\n",
      "[Segment 49] GPU Memory Start = 1468.10 MB\n",
      "[Segment 49] GPU Memory End   = 1468.24 MB\n",
      "[Segment 49] GPU Peak Memory  = 1469.36 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 50 ===========\n",
      "[Segment 50] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 50] Training Time = 4.80 sec\n",
      "[Segment 50] GPU Memory Start = 1468.24 MB\n",
      "[Segment 50] GPU Memory End   = 1468.38 MB\n",
      "[Segment 50] GPU Peak Memory  = 1469.49 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 51 ===========\n",
      "[Segment 51] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 51] Training Time = 4.55 sec\n",
      "[Segment 51] GPU Memory Start = 1468.38 MB\n",
      "[Segment 51] GPU Memory End   = 1468.51 MB\n",
      "[Segment 51] GPU Peak Memory  = 1469.63 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 52 ===========\n",
      "[Segment 52] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 52] Training Time = 4.01 sec\n",
      "[Segment 52] GPU Memory Start = 1468.51 MB\n",
      "[Segment 52] GPU Memory End   = 1468.65 MB\n",
      "[Segment 52] GPU Peak Memory  = 1469.76 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 53 ===========\n",
      "[Segment 53] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 53] Training Time = 2.46 sec\n",
      "[Segment 53] GPU Memory Start = 1468.65 MB\n",
      "[Segment 53] GPU Memory End   = 1468.78 MB\n",
      "[Segment 53] GPU Peak Memory  = 1469.90 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 54 ===========\n",
      "[Segment 54] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 54] Training Time = 4.51 sec\n",
      "[Segment 54] GPU Memory Start = 1468.78 MB\n",
      "[Segment 54] GPU Memory End   = 1468.92 MB\n",
      "[Segment 54] GPU Peak Memory  = 1470.03 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 55 ===========\n",
      "[Segment 55] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 55] Training Time = 3.99 sec\n",
      "[Segment 55] GPU Memory Start = 1468.92 MB\n",
      "[Segment 55] GPU Memory End   = 1469.05 MB\n",
      "[Segment 55] GPU Peak Memory  = 1470.17 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 56 ===========\n",
      "[Segment 56] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 56] Training Time = 3.25 sec\n",
      "[Segment 56] GPU Memory Start = 1469.05 MB\n",
      "[Segment 56] GPU Memory End   = 1469.19 MB\n",
      "[Segment 56] GPU Peak Memory  = 1470.30 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 57 ===========\n",
      "[Segment 57] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 57] Training Time = 4.60 sec\n",
      "[Segment 57] GPU Memory Start = 1469.19 MB\n",
      "[Segment 57] GPU Memory End   = 1469.32 MB\n",
      "[Segment 57] GPU Peak Memory  = 1470.44 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 58 ===========\n",
      "[Segment 58] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 58] Training Time = 4.75 sec\n",
      "[Segment 58] GPU Memory Start = 1469.32 MB\n",
      "[Segment 58] GPU Memory End   = 1469.46 MB\n",
      "[Segment 58] GPU Peak Memory  = 1470.57 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 59 ===========\n",
      "[Segment 59] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 59] Training Time = 4.84 sec\n",
      "[Segment 59] GPU Memory Start = 1468.10 MB\n",
      "[Segment 59] GPU Memory End   = 1468.24 MB\n",
      "[Segment 59] GPU Peak Memory  = 1469.36 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 60 ===========\n",
      "[Segment 60] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 60] Training Time = 4.10 sec\n",
      "[Segment 60] GPU Memory Start = 1468.24 MB\n",
      "[Segment 60] GPU Memory End   = 1468.38 MB\n",
      "[Segment 60] GPU Peak Memory  = 1469.49 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 61 ===========\n",
      "[Segment 61] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 61] Training Time = 4.41 sec\n",
      "[Segment 61] GPU Memory Start = 1468.38 MB\n",
      "[Segment 61] GPU Memory End   = 1468.51 MB\n",
      "[Segment 61] GPU Peak Memory  = 1469.63 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 62 ===========\n",
      "[Segment 62] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 62] Training Time = 4.52 sec\n",
      "[Segment 62] GPU Memory Start = 1468.51 MB\n",
      "[Segment 62] GPU Memory End   = 1468.65 MB\n",
      "[Segment 62] GPU Peak Memory  = 1469.76 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 63 ===========\n",
      "[Segment 63] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 63] Training Time = 3.60 sec\n",
      "[Segment 63] GPU Memory Start = 1468.65 MB\n",
      "[Segment 63] GPU Memory End   = 1468.78 MB\n",
      "[Segment 63] GPU Peak Memory  = 1469.90 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 64 ===========\n",
      "[Segment 64] Batch Size Info:\n",
      "  xb per batch = 0.0410 MB, total = 43.7637 MB\n",
      "  yb per batch = 0.0117 MB, total = 12.5039 MB\n",
      "  pv per batch = 0.0039 MB, total = 4.1680 MB\n",
      "[Segment 64] Training Time = 4.65 sec\n",
      "[Segment 64] GPU Memory Start = 1468.78 MB\n",
      "[Segment 64] GPU Memory End   = 1468.92 MB\n",
      "[Segment 64] GPU Peak Memory  = 1470.03 MB\n",
      "\n",
      "============= Done =============\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "epo = 1\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual,\n",
    "                 learning_rate, lradj, patience,\n",
    "                 save_path, attach_pv):\n",
    "        self.seq_len  = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in   = enc_in          \n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv    = attach_pv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "base_cfg = Configs(\n",
    "    seq_len          = 336 ,\n",
    "    pred_len         = 96,\n",
    "    enc_in           = 1,\n",
    "    individual       = True,\n",
    "    learning_rate    = 0.001,\n",
    "    lradj            = 'type1',\n",
    "    patience         = 3,\n",
    "    save_path        = f\"./model2_ETTm2_E{epo}_1E/\",\n",
    "    attach_pv  = True,\n",
    "\n",
    ")\n",
    "Path(base_cfg.save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "for seg in range(len(train_pred_segments_E1[0])):\n",
    "    print(f\"\\n=========== Segment {seg} ===========\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    mem_start = torch.cuda.memory_allocated(device)\n",
    "\n",
    "    \n",
    "    tr_pv = train_pred_segments_E1[:, seg, :, :]   \n",
    "    va_pv = val_pred_segments_E1[:,  seg, :, :]\n",
    "\n",
    "    tr_ds = TensorDataset(train_sequences, train_labels, tr_pv)\n",
    "    va_ds = TensorDataset(val_sequences,   val_labels,   va_pv)\n",
    "    tr_dl = DataLoader(tr_ds, batch_size=32, shuffle=True)\n",
    "    va_dl = DataLoader(va_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "    \n",
    "    model = Model(base_cfg).to(device)\n",
    "    C     = model.channels                                    \n",
    "\n",
    "    opts = []\n",
    "    for c in range(C):\n",
    "        params = list(model.Linear[c].parameters())\n",
    "        opts.append(optim.Adam(params, lr=base_cfg.learning_rate))\n",
    "        path = Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{c}\"\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    active = set(range(C))            \n",
    "\n",
    "    \n",
    "    for epoch in range(1, 2):\n",
    "        if not active: break          \n",
    "\n",
    "        \n",
    "        model.train()\n",
    "        for c in active:                              \n",
    "            if base_cfg.lradj=='type1':\n",
    "                lr = base_cfg.learning_rate * 0.5**((epoch-1)//1)\n",
    "                for g in opts[c].param_groups: g['lr'] = lr\n",
    "\n",
    "        printed_tensor_info = False\n",
    "        \n",
    "        for xb, yb, pv in tr_dl:\n",
    "            xb, yb, pv = xb.float().to(device), yb.float().to(device), pv.float().to(device)\n",
    "\n",
    "            if not printed_tensor_info:\n",
    "                \n",
    "                xb_size = xb.numel() * xb.element_size() / 1024**2\n",
    "                yb_size = yb.numel() * yb.element_size() / 1024**2\n",
    "                pv_size = pv.numel() * pv.element_size() / 1024**2\n",
    "\n",
    "                \n",
    "                \n",
    "                num_batches = len(tr_dl)\n",
    "\n",
    "                \n",
    "                total_xb_MB = num_batches * xb_size\n",
    "                total_yb_MB = num_batches * yb_size\n",
    "                total_pv_MB = num_batches * pv_size\n",
    "                \n",
    "\n",
    "\n",
    "                print(f\"[Segment {seg}] Batch Size Info:\")\n",
    "                print(f\"  xb per batch = {xb_size:.4f} MB, total = {total_xb_MB:.4f} MB\")\n",
    "                print(f\"  yb per batch = {yb_size:.4f} MB, total = {total_yb_MB:.4f} MB\")\n",
    "                print(f\"  pv per batch = {pv_size:.4f} MB, total = {total_pv_MB:.4f} MB\")\n",
    "\n",
    "                printed_tensor_info = True\n",
    "\n",
    "\n",
    "\n",
    "            out = model(xb, pv)                       \n",
    "\n",
    "            loss_list = []\n",
    "            for c in active:\n",
    "                pred = out[:, -base_cfg.pred_len:, c]\n",
    "                tgt  = yb[:, -base_cfg.pred_len:, c]\n",
    "                loss_list.append(loss_fn(pred, tgt))\n",
    "\n",
    "            total = torch.stack(loss_list).sum()\n",
    "            for opt in opts:\n",
    "                if opt: opt.zero_grad()\n",
    "            total.backward()\n",
    "            for c in active:\n",
    "                opts[c].step()\n",
    "\n",
    "        \n",
    "    elapsed = time.time() - start_time\n",
    "    mem_end = torch.cuda.memory_allocated(device)\n",
    "    peak_mem = torch.cuda.max_memory_allocated(device)\n",
    "\n",
    "\n",
    "    print(f\"[Segment {seg}] Training Time = {elapsed:.2f} sec\")\n",
    "    print(f\"[Segment {seg}] GPU Memory Start = {mem_start/1024**2:.2f} MB\")\n",
    "    print(f\"[Segment {seg}] GPU Memory End   = {mem_end/1024**2:.2f} MB\")\n",
    "    print(f\"[Segment {seg}] GPU Peak Memory  = {peak_mem/1024**2:.2f} MB\")\n",
    "\n",
    "    print(f\"\\n============= Done =============\")\n",
    "\n",
    "    \n",
    "    torch.save(model.state_dict(),\n",
    "                Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{c}\" / \"checkpoint.pth\")\n",
    "    del model, opts; torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d10eb2",
   "metadata": {},
   "source": [
    "# 2nd Inference for Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab71a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_segments_by_epoch = torch.load('./1st_results_ETTm2/train_segments_by_epoch.pt', weights_only=False)\n",
    "val_segments_by_epoch = torch.load('./1st_results_ETTm2/val_segments_by_epoch.pt', weights_only=False)\n",
    "test_segments_by_epoch = torch.load('./1st_results_ETTm2/test_segments_by_epoch.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0832a715",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_segments_ES = train_segments_by_epoch['ES']['train_pred_segments_EES']  \n",
    "train_label_segments_ES = train_segments_by_epoch['ES']['train_label_segments_EES']\n",
    "val_pred_segments_ES = val_segments_by_epoch['ES']['val_pred_segments_EES']  \n",
    "val_label_segments_ES = val_segments_by_epoch['ES']['val_label_segments_EES']\n",
    "test_pred_segments_ES = test_segments_by_epoch['ES']['test_pred_segments_EES']  \n",
    "test_label_segments_ES = test_segments_by_epoch['ES']['test_label_segments_EES']\n",
    "\n",
    "\n",
    "train_pred_segments_E1 = train_segments_by_epoch[1]['train_pred_segments_E1']  \n",
    "train_label_segments_E1 = train_segments_by_epoch[1]['train_label_segments_E1']\n",
    "val_pred_segments_E1 = val_segments_by_epoch[1]['val_pred_segments_E1']  \n",
    "val_label_segments_E1 = val_segments_by_epoch[1]['val_label_segments_E1']\n",
    "test_pred_segments_E1 = test_segments_by_epoch[1]['test_pred_segments_E1']  \n",
    "test_label_segments_E1 = test_segments_by_epoch[1]['test_label_segments_E1']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad54bf8",
   "metadata": {},
   "source": [
    "## ES->1E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0774a87d",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaacb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual,\n",
    "                 learning_rate, lradj, patience,\n",
    "                 save_path, attach_pv):\n",
    "        self.seq_len  = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in   = enc_in          \n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv    = attach_pv\n",
    "\n",
    "\n",
    "\n",
    "base_cfg = Configs(\n",
    "    pred_len         = 96,\n",
    "    seq_len          = 336 ,\n",
    "    enc_in           = 1,\n",
    "    individual       = True,\n",
    "    learning_rate    = 0.001,\n",
    "    lradj            = 'type1',\n",
    "    patience         = 3,\n",
    "    save_path        = \"./model2_ETTm2_EES_1E\",\n",
    "    attach_pv  = True,\n",
    "\n",
    ")\n",
    "Path(base_cfg.save_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a1c3ea",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4a9334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "―――― Inference  |  Segment 0 ――――\n",
      "  seg0-ch0  MSE:0.0902695283293724  MAE:0.22102338075637817\n",
      "▶ seg0  mean  MSE:0.0902695283293724  MAE:0.22102338075637817\n",
      "\n",
      "―――― Inference  |  Segment 1 ――――\n",
      "  seg1-ch0  MSE:0.09316027164459229  MAE:0.21731077134609222\n",
      "▶ seg1  mean  MSE:0.09316027164459229  MAE:0.21731077134609222\n",
      "\n",
      "―――― Inference  |  Segment 2 ――――\n",
      "  seg2-ch0  MSE:0.09303690493106842  MAE:0.2266368567943573\n",
      "▶ seg2  mean  MSE:0.09303690493106842  MAE:0.2266368567943573\n",
      "\n",
      "―――― Inference  |  Segment 3 ――――\n",
      "  seg3-ch0  MSE:0.0923643633723259  MAE:0.22212018072605133\n",
      "▶ seg3  mean  MSE:0.0923643633723259  MAE:0.22212018072605133\n",
      "\n",
      "―――― Inference  |  Segment 4 ――――\n",
      "  seg4-ch0  MSE:0.08830766379833221  MAE:0.20912109315395355\n",
      "▶ seg4  mean  MSE:0.08830766379833221  MAE:0.20912109315395355\n",
      "\n",
      "―――― Inference  |  Segment 5 ――――\n",
      "  seg5-ch0  MSE:0.09767402708530426  MAE:0.22402524948120117\n",
      "▶ seg5  mean  MSE:0.09767402708530426  MAE:0.22402524948120117\n",
      "\n",
      "―――― Inference  |  Segment 6 ――――\n",
      "  seg6-ch0  MSE:0.08828707039356232  MAE:0.21461817622184753\n",
      "▶ seg6  mean  MSE:0.08828707039356232  MAE:0.21461817622184753\n",
      "\n",
      "―――― Inference  |  Segment 7 ――――\n",
      "  seg7-ch0  MSE:0.10121720284223557  MAE:0.23598302900791168\n",
      "▶ seg7  mean  MSE:0.10121720284223557  MAE:0.23598302900791168\n",
      "\n",
      "―――― Inference  |  Segment 8 ――――\n",
      "  seg8-ch0  MSE:0.08874587714672089  MAE:0.2162027209997177\n",
      "▶ seg8  mean  MSE:0.08874587714672089  MAE:0.2162027209997177\n",
      "\n",
      "―――― Inference  |  Segment 9 ――――\n",
      "  seg9-ch0  MSE:0.09319287538528442  MAE:0.22581282258033752\n",
      "▶ seg9  mean  MSE:0.09319287538528442  MAE:0.22581282258033752\n",
      "\n",
      "―――― Inference  |  Segment 10 ――――\n",
      "  seg10-ch0  MSE:0.089107446372509  MAE:0.21427899599075317\n",
      "▶ seg10  mean  MSE:0.089107446372509  MAE:0.21427899599075317\n",
      "\n",
      "―――― Inference  |  Segment 11 ――――\n",
      "  seg11-ch0  MSE:0.08839896321296692  MAE:0.21640822291374207\n",
      "▶ seg11  mean  MSE:0.08839896321296692  MAE:0.21640822291374207\n",
      "\n",
      "―――― Inference  |  Segment 12 ――――\n",
      "  seg12-ch0  MSE:0.0876704677939415  MAE:0.21234269440174103\n",
      "▶ seg12  mean  MSE:0.0876704677939415  MAE:0.21234269440174103\n",
      "\n",
      "―――― Inference  |  Segment 13 ――――\n",
      "  seg13-ch0  MSE:0.0905846655368805  MAE:0.21028552949428558\n",
      "▶ seg13  mean  MSE:0.0905846655368805  MAE:0.21028552949428558\n",
      "\n",
      "―――― Inference  |  Segment 14 ――――\n",
      "  seg14-ch0  MSE:0.11794564127922058  MAE:0.25018832087516785\n",
      "▶ seg14  mean  MSE:0.11794564127922058  MAE:0.25018832087516785\n",
      "\n",
      "―――― Inference  |  Segment 15 ――――\n",
      "  seg15-ch0  MSE:0.09481775015592575  MAE:0.21596521139144897\n",
      "▶ seg15  mean  MSE:0.09481775015592575  MAE:0.21596521139144897\n",
      "\n",
      "―――― Inference  |  Segment 16 ――――\n",
      "  seg16-ch0  MSE:0.09800978004932404  MAE:0.21889150142669678\n",
      "▶ seg16  mean  MSE:0.09800978004932404  MAE:0.21889150142669678\n",
      "\n",
      "―――― Inference  |  Segment 17 ――――\n",
      "  seg17-ch0  MSE:0.08855468779802322  MAE:0.21030457317829132\n",
      "▶ seg17  mean  MSE:0.08855468779802322  MAE:0.21030457317829132\n",
      "\n",
      "―――― Inference  |  Segment 18 ――――\n",
      "  seg18-ch0  MSE:0.09124262630939484  MAE:0.21137912571430206\n",
      "▶ seg18  mean  MSE:0.09124262630939484  MAE:0.21137912571430206\n",
      "\n",
      "―――― Inference  |  Segment 19 ――――\n",
      "  seg19-ch0  MSE:0.0884689912199974  MAE:0.20715369284152985\n",
      "▶ seg19  mean  MSE:0.0884689912199974  MAE:0.20715369284152985\n",
      "\n",
      "―――― Inference  |  Segment 20 ――――\n",
      "  seg20-ch0  MSE:0.08758723735809326  MAE:0.21308791637420654\n",
      "▶ seg20  mean  MSE:0.08758723735809326  MAE:0.21308791637420654\n",
      "\n",
      "―――― Inference  |  Segment 21 ――――\n",
      "  seg21-ch0  MSE:0.09216920286417007  MAE:0.22223185002803802\n",
      "▶ seg21  mean  MSE:0.09216920286417007  MAE:0.22223185002803802\n",
      "\n",
      "―――― Inference  |  Segment 22 ――――\n",
      "  seg22-ch0  MSE:0.08936537802219391  MAE:0.21036876738071442\n",
      "▶ seg22  mean  MSE:0.08936537802219391  MAE:0.21036876738071442\n",
      "\n",
      "―――― Inference  |  Segment 23 ――――\n",
      "  seg23-ch0  MSE:0.10295146703720093  MAE:0.24210552871227264\n",
      "▶ seg23  mean  MSE:0.10295146703720093  MAE:0.24210552871227264\n",
      "\n",
      "―――― Inference  |  Segment 24 ――――\n",
      "  seg24-ch0  MSE:0.09234251081943512  MAE:0.2275719791650772\n",
      "▶ seg24  mean  MSE:0.09234251081943512  MAE:0.2275719791650772\n",
      "\n",
      "―――― Inference  |  Segment 25 ――――\n",
      "  seg25-ch0  MSE:0.08868800848722458  MAE:0.21204061806201935\n",
      "▶ seg25  mean  MSE:0.08868800848722458  MAE:0.21204061806201935\n",
      "\n",
      "―――― Inference  |  Segment 26 ――――\n",
      "  seg26-ch0  MSE:0.09224651008844376  MAE:0.221684068441391\n",
      "▶ seg26  mean  MSE:0.09224651008844376  MAE:0.221684068441391\n",
      "\n",
      "―――― Inference  |  Segment 27 ――――\n",
      "  seg27-ch0  MSE:0.08885619044303894  MAE:0.2121242880821228\n",
      "▶ seg27  mean  MSE:0.08885619044303894  MAE:0.2121242880821228\n",
      "\n",
      "―――― Inference  |  Segment 28 ――――\n",
      "  seg28-ch0  MSE:0.09379703551530838  MAE:0.22288160026073456\n",
      "▶ seg28  mean  MSE:0.09379703551530838  MAE:0.22288160026073456\n",
      "\n",
      "―――― Inference  |  Segment 29 ――――\n",
      "  seg29-ch0  MSE:0.09417066723108292  MAE:0.21196229755878448\n",
      "▶ seg29  mean  MSE:0.09417066723108292  MAE:0.21196229755878448\n",
      "\n",
      "―――― Inference  |  Segment 30 ――――\n",
      "  seg30-ch0  MSE:0.09247830510139465  MAE:0.2105562537908554\n",
      "▶ seg30  mean  MSE:0.09247830510139465  MAE:0.2105562537908554\n",
      "\n",
      "―――― Inference  |  Segment 31 ――――\n",
      "  seg31-ch0  MSE:0.09026747196912766  MAE:0.21205446124076843\n",
      "▶ seg31  mean  MSE:0.09026747196912766  MAE:0.21205446124076843\n",
      "\n",
      "―――― Inference  |  Segment 32 ――――\n",
      "  seg32-ch0  MSE:0.095985546708107  MAE:0.231227844953537\n",
      "▶ seg32  mean  MSE:0.095985546708107  MAE:0.231227844953537\n",
      "\n",
      "―――― Inference  |  Segment 33 ――――\n",
      "  seg33-ch0  MSE:0.09510386735200882  MAE:0.22470222413539886\n",
      "▶ seg33  mean  MSE:0.09510386735200882  MAE:0.22470222413539886\n",
      "\n",
      "―――― Inference  |  Segment 34 ――――\n",
      "  seg34-ch0  MSE:0.09501280635595322  MAE:0.2187134325504303\n",
      "▶ seg34  mean  MSE:0.09501280635595322  MAE:0.2187134325504303\n",
      "\n",
      "―――― Inference  |  Segment 35 ――――\n",
      "  seg35-ch0  MSE:0.09724597632884979  MAE:0.2199222892522812\n",
      "▶ seg35  mean  MSE:0.09724597632884979  MAE:0.2199222892522812\n",
      "\n",
      "―――― Inference  |  Segment 36 ――――\n",
      "  seg36-ch0  MSE:0.09564883261919022  MAE:0.22445325553417206\n",
      "▶ seg36  mean  MSE:0.09564883261919022  MAE:0.22445325553417206\n",
      "\n",
      "―――― Inference  |  Segment 37 ――――\n",
      "  seg37-ch0  MSE:0.10569871962070465  MAE:0.24271035194396973\n",
      "▶ seg37  mean  MSE:0.10569871962070465  MAE:0.24271035194396973\n",
      "\n",
      "―――― Inference  |  Segment 38 ――――\n",
      "  seg38-ch0  MSE:0.0950416624546051  MAE:0.21509800851345062\n",
      "▶ seg38  mean  MSE:0.0950416624546051  MAE:0.21509800851345062\n",
      "\n",
      "―――― Inference  |  Segment 39 ――――\n",
      "  seg39-ch0  MSE:0.09281578660011292  MAE:0.21680016815662384\n",
      "▶ seg39  mean  MSE:0.09281578660011292  MAE:0.21680016815662384\n",
      "\n",
      "―――― Inference  |  Segment 40 ――――\n",
      "  seg40-ch0  MSE:0.09135954082012177  MAE:0.21659612655639648\n",
      "▶ seg40  mean  MSE:0.09135954082012177  MAE:0.21659612655639648\n",
      "\n",
      "―――― Inference  |  Segment 41 ――――\n",
      "  seg41-ch0  MSE:0.0907292515039444  MAE:0.2207706719636917\n",
      "▶ seg41  mean  MSE:0.0907292515039444  MAE:0.2207706719636917\n",
      "\n",
      "―――― Inference  |  Segment 42 ――――\n",
      "  seg42-ch0  MSE:0.09147018939256668  MAE:0.21795959770679474\n",
      "▶ seg42  mean  MSE:0.09147018939256668  MAE:0.21795959770679474\n",
      "\n",
      "―――― Inference  |  Segment 43 ――――\n",
      "  seg43-ch0  MSE:0.09127530455589294  MAE:0.22160238027572632\n",
      "▶ seg43  mean  MSE:0.09127530455589294  MAE:0.22160238027572632\n",
      "\n",
      "―――― Inference  |  Segment 44 ――――\n",
      "  seg44-ch0  MSE:0.09186716377735138  MAE:0.21380658447742462\n",
      "▶ seg44  mean  MSE:0.09186716377735138  MAE:0.21380658447742462\n",
      "\n",
      "―――― Inference  |  Segment 45 ――――\n",
      "  seg45-ch0  MSE:0.09184905141592026  MAE:0.2130766361951828\n",
      "▶ seg45  mean  MSE:0.09184905141592026  MAE:0.2130766361951828\n",
      "\n",
      "―――― Inference  |  Segment 46 ――――\n",
      "  seg46-ch0  MSE:0.09107464551925659  MAE:0.22257350385189056\n",
      "▶ seg46  mean  MSE:0.09107464551925659  MAE:0.22257350385189056\n",
      "\n",
      "―――― Inference  |  Segment 47 ――――\n",
      "  seg47-ch0  MSE:0.09398394078016281  MAE:0.22916601598262787\n",
      "▶ seg47  mean  MSE:0.09398394078016281  MAE:0.22916601598262787\n",
      "\n",
      "―――― Inference  |  Segment 48 ――――\n",
      "  seg48-ch0  MSE:0.0957346186041832  MAE:0.21553044021129608\n",
      "▶ seg48  mean  MSE:0.0957346186041832  MAE:0.21553044021129608\n",
      "\n",
      "―――― Inference  |  Segment 49 ――――\n",
      "  seg49-ch0  MSE:0.09301885962486267  MAE:0.22499659657478333\n",
      "▶ seg49  mean  MSE:0.09301885962486267  MAE:0.22499659657478333\n",
      "\n",
      "―――― Inference  |  Segment 50 ――――\n",
      "  seg50-ch0  MSE:0.0903465673327446  MAE:0.21439608931541443\n",
      "▶ seg50  mean  MSE:0.0903465673327446  MAE:0.21439608931541443\n",
      "\n",
      "―――― Inference  |  Segment 51 ――――\n",
      "  seg51-ch0  MSE:0.08902623504400253  MAE:0.21519309282302856\n",
      "▶ seg51  mean  MSE:0.08902623504400253  MAE:0.21519309282302856\n",
      "\n",
      "―――― Inference  |  Segment 52 ――――\n",
      "  seg52-ch0  MSE:0.10393095016479492  MAE:0.24827036261558533\n",
      "▶ seg52  mean  MSE:0.10393095016479492  MAE:0.24827036261558533\n",
      "\n",
      "―――― Inference  |  Segment 53 ――――\n",
      "  seg53-ch0  MSE:0.09046144783496857  MAE:0.2201334685087204\n",
      "▶ seg53  mean  MSE:0.09046144783496857  MAE:0.2201334685087204\n",
      "\n",
      "―――― Inference  |  Segment 54 ――――\n",
      "  seg54-ch0  MSE:0.09451886266469955  MAE:0.2171686291694641\n",
      "▶ seg54  mean  MSE:0.09451886266469955  MAE:0.2171686291694641\n",
      "\n",
      "―――― Inference  |  Segment 55 ――――\n",
      "  seg55-ch0  MSE:0.10726277530193329  MAE:0.22934940457344055\n",
      "▶ seg55  mean  MSE:0.10726277530193329  MAE:0.22934940457344055\n",
      "\n",
      "―――― Inference  |  Segment 56 ――――\n",
      "  seg56-ch0  MSE:0.09011147916316986  MAE:0.21008466184139252\n",
      "▶ seg56  mean  MSE:0.09011147916316986  MAE:0.21008466184139252\n",
      "\n",
      "―――― Inference  |  Segment 57 ――――\n",
      "  seg57-ch0  MSE:0.09109140187501907  MAE:0.21926258504390717\n",
      "▶ seg57  mean  MSE:0.09109140187501907  MAE:0.21926258504390717\n",
      "\n",
      "―――― Inference  |  Segment 58 ――――\n",
      "  seg58-ch0  MSE:0.09604708105325699  MAE:0.23348988592624664\n",
      "▶ seg58  mean  MSE:0.09604708105325699  MAE:0.23348988592624664\n",
      "\n",
      "―――― Inference  |  Segment 59 ――――\n",
      "  seg59-ch0  MSE:0.09720195829868317  MAE:0.22136159241199493\n",
      "▶ seg59  mean  MSE:0.09720195829868317  MAE:0.22136159241199493\n",
      "\n",
      "―――― Inference  |  Segment 60 ――――\n",
      "  seg60-ch0  MSE:0.09450094401836395  MAE:0.2304275631904602\n",
      "▶ seg60  mean  MSE:0.09450094401836395  MAE:0.2304275631904602\n",
      "\n",
      "―――― Inference  |  Segment 61 ――――\n",
      "  seg61-ch0  MSE:0.09296664595603943  MAE:0.21921682357788086\n",
      "▶ seg61  mean  MSE:0.09296664595603943  MAE:0.21921682357788086\n",
      "\n",
      "―――― Inference  |  Segment 62 ――――\n",
      "  seg62-ch0  MSE:0.09052230417728424  MAE:0.2110707312822342\n",
      "▶ seg62  mean  MSE:0.09052230417728424  MAE:0.2110707312822342\n",
      "\n",
      "―――― Inference  |  Segment 63 ――――\n",
      "  seg63-ch0  MSE:0.09010863304138184  MAE:0.2135852873325348\n",
      "▶ seg63  mean  MSE:0.09010863304138184  MAE:0.2135852873325348\n",
      "\n",
      "―――― Inference  |  Segment 64 ――――\n",
      "  seg64-ch0  MSE:0.09463661164045334  MAE:0.22808969020843506\n",
      "▶ seg64  mean  MSE:0.09463661164045334  MAE:0.22808969020843506\n",
      "\n",
      "seg10 ch0 MSE : 0.08910745\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import r2_score\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "C        = 1                                \n",
    "P        = base_cfg.pred_len                \n",
    "seg_cnt  = 65\n",
    "batch_sz = 32\n",
    "\n",
    "results2_ETTm2_ES_val_1E = {}  \n",
    "\n",
    "for seg in range(seg_cnt):\n",
    "    print(f\"\\n―――― Inference  |  Segment {seg} ――――\")\n",
    "\n",
    "    \n",
    "    pv = val_pred_segments_ES[:, seg, :, :]         \n",
    "    ds = TensorDataset(val_sequences, val_labels, pv) \n",
    "    dl = DataLoader(ds, batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "    \n",
    "    pred_ch, true_ch, metrics = [], [], {}\n",
    "\n",
    "    \n",
    "    for ch in range(C):\n",
    "        ckpt = Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{ch}\" / \"checkpoint.pth\"\n",
    "        if not ckpt.exists():\n",
    "            print(f\"[Warn] seg{seg}-ch{ch} ckpt 없음 → skip\");  continue\n",
    "\n",
    "        \n",
    "        model = Model(base_cfg).to(device)\n",
    "        model.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        preds, trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, pv_batch in dl:                 \n",
    "                xb  = xb.float().to(device)\n",
    "                yb  = yb.float()      \n",
    "                pv_ = pv_batch.float().to(device)\n",
    "\n",
    "                out = model(xb, pv_)                     \n",
    "                preds.append(out[:, -P:, ch].cpu())\n",
    "                trues.append(yb[:, -P:, ch])\n",
    "\n",
    "        preds = torch.cat(preds, 0)     \n",
    "        trues = torch.cat(trues, 0)\n",
    "        pred_ch.append(preds)\n",
    "        true_ch.append(trues)\n",
    "\n",
    "        \n",
    "        p, t = preds.reshape(-1).cpu().numpy(), trues.reshape(-1).cpu().numpy()\n",
    "        mse  = np.mean((p - t)**2)\n",
    "        mae  = np.mean(np.abs(p - t))\n",
    "        metrics[ch] = (mse, mae)\n",
    "\n",
    "        print(f\"  seg{seg}-ch{ch}  MSE:{mse}  MAE:{mae}\")\n",
    "\n",
    "        del model; torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "    pred_all = torch.stack(pred_ch,  dim=2)   \n",
    "    true_all = torch.stack(true_ch,  dim=2)\n",
    "\n",
    "    \n",
    "    mse_avg = np.mean([m for m,_ in metrics.values()])\n",
    "    mae_avg = np.mean([a for _,a in metrics.values()])\n",
    "    print(f\"▶ seg{seg}  mean  MSE:{mse_avg}  MAE:{mae_avg}\")\n",
    "\n",
    "    \n",
    "    results2_ETTm2_ES_val_1E[seg] = {\n",
    "        \"pred2_ES_val_1E\"    : pred_all,   \n",
    "        \"true2_ES_val_1E\"    : true_all,   \n",
    "        \"metrics2_ES_val_1E\" : metrics     \n",
    "    }\n",
    "\n",
    "\n",
    "seg10_ch0_mse = results2_ETTm2_ES_val_1E[10][\"metrics2_ES_val_1E\"][0][0]\n",
    "print(\"\\nseg10 ch0 MSE :\", seg10_ch0_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb123635",
   "metadata": {},
   "source": [
    "## 1E->1E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82bc55d",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f00efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual,\n",
    "                 learning_rate, lradj, patience,\n",
    "                 save_path, attach_pv):\n",
    "        self.seq_len  = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in   = enc_in          \n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv    = attach_pv\n",
    "\n",
    "\n",
    "\n",
    "base_cfg = Configs(\n",
    "    pred_len         = 96,\n",
    "    seq_len          = 336,\n",
    "    enc_in           = 1,\n",
    "    individual       = True,\n",
    "    learning_rate    = 0.001,\n",
    "    lradj            = 'type1',\n",
    "    patience         = 3,\n",
    "    save_path        = \"./model2_ETTm2_E1_1E\",\n",
    "    attach_pv  = True,\n",
    "\n",
    ")\n",
    "Path(base_cfg.save_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df00ecaf",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e772f93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "―――― Inference  |  Segment 0 ――――\n",
      "  seg0-ch0  MSE:0.08885124325752258  MAE:0.21342304348945618\n",
      "▶ seg0  mean  MSE:0.08885124325752258  MAE:0.21342304348945618\n",
      "\n",
      "―――― Inference  |  Segment 1 ――――\n",
      "  seg1-ch0  MSE:0.09177860617637634  MAE:0.21592341363430023\n",
      "▶ seg1  mean  MSE:0.09177860617637634  MAE:0.21592341363430023\n",
      "\n",
      "―――― Inference  |  Segment 2 ――――\n",
      "  seg2-ch0  MSE:0.09008163958787918  MAE:0.2155316025018692\n",
      "▶ seg2  mean  MSE:0.09008163958787918  MAE:0.2155316025018692\n",
      "\n",
      "―――― Inference  |  Segment 3 ――――\n",
      "  seg3-ch0  MSE:0.08868439495563507  MAE:0.21066777408123016\n",
      "▶ seg3  mean  MSE:0.08868439495563507  MAE:0.21066777408123016\n",
      "\n",
      "―――― Inference  |  Segment 4 ――――\n",
      "  seg4-ch0  MSE:0.09777917712926865  MAE:0.2193797081708908\n",
      "▶ seg4  mean  MSE:0.09777917712926865  MAE:0.2193797081708908\n",
      "\n",
      "―――― Inference  |  Segment 5 ――――\n",
      "  seg5-ch0  MSE:0.09608153998851776  MAE:0.23183612525463104\n",
      "▶ seg5  mean  MSE:0.09608153998851776  MAE:0.23183612525463104\n",
      "\n",
      "―――― Inference  |  Segment 6 ――――\n",
      "  seg6-ch0  MSE:0.09090610593557358  MAE:0.2144462615251541\n",
      "▶ seg6  mean  MSE:0.09090610593557358  MAE:0.2144462615251541\n",
      "\n",
      "―――― Inference  |  Segment 7 ――――\n",
      "  seg7-ch0  MSE:0.0929541140794754  MAE:0.21461589634418488\n",
      "▶ seg7  mean  MSE:0.0929541140794754  MAE:0.21461589634418488\n",
      "\n",
      "―――― Inference  |  Segment 8 ――――\n",
      "  seg8-ch0  MSE:0.09045857191085815  MAE:0.21476095914840698\n",
      "▶ seg8  mean  MSE:0.09045857191085815  MAE:0.21476095914840698\n",
      "\n",
      "―――― Inference  |  Segment 9 ――――\n",
      "  seg9-ch0  MSE:0.09112868458032608  MAE:0.21682237088680267\n",
      "▶ seg9  mean  MSE:0.09112868458032608  MAE:0.21682237088680267\n",
      "\n",
      "―――― Inference  |  Segment 10 ――――\n",
      "  seg10-ch0  MSE:0.08871441334486008  MAE:0.21035444736480713\n",
      "▶ seg10  mean  MSE:0.08871441334486008  MAE:0.21035444736480713\n",
      "\n",
      "―――― Inference  |  Segment 11 ――――\n",
      "  seg11-ch0  MSE:0.09300972521305084  MAE:0.225260391831398\n",
      "▶ seg11  mean  MSE:0.09300972521305084  MAE:0.225260391831398\n",
      "\n",
      "―――― Inference  |  Segment 12 ――――\n",
      "  seg12-ch0  MSE:0.09118521958589554  MAE:0.2134539783000946\n",
      "▶ seg12  mean  MSE:0.09118521958589554  MAE:0.2134539783000946\n",
      "\n",
      "―――― Inference  |  Segment 13 ――――\n",
      "  seg13-ch0  MSE:0.09572446346282959  MAE:0.23123596608638763\n",
      "▶ seg13  mean  MSE:0.09572446346282959  MAE:0.23123596608638763\n",
      "\n",
      "―――― Inference  |  Segment 14 ――――\n",
      "  seg14-ch0  MSE:0.0909980908036232  MAE:0.21173611283302307\n",
      "▶ seg14  mean  MSE:0.0909980908036232  MAE:0.21173611283302307\n",
      "\n",
      "―――― Inference  |  Segment 15 ――――\n",
      "  seg15-ch0  MSE:0.08880012482404709  MAE:0.2121104747056961\n",
      "▶ seg15  mean  MSE:0.08880012482404709  MAE:0.2121104747056961\n",
      "\n",
      "―――― Inference  |  Segment 16 ――――\n",
      "  seg16-ch0  MSE:0.09769245982170105  MAE:0.22278599441051483\n",
      "▶ seg16  mean  MSE:0.09769245982170105  MAE:0.22278599441051483\n",
      "\n",
      "―――― Inference  |  Segment 17 ――――\n",
      "  seg17-ch0  MSE:0.09062841534614563  MAE:0.21560944616794586\n",
      "▶ seg17  mean  MSE:0.09062841534614563  MAE:0.21560944616794586\n",
      "\n",
      "―――― Inference  |  Segment 18 ――――\n",
      "  seg18-ch0  MSE:0.09618408977985382  MAE:0.22565171122550964\n",
      "▶ seg18  mean  MSE:0.09618408977985382  MAE:0.22565171122550964\n",
      "\n",
      "―――― Inference  |  Segment 19 ――――\n",
      "  seg19-ch0  MSE:0.09018293768167496  MAE:0.2144903689622879\n",
      "▶ seg19  mean  MSE:0.09018293768167496  MAE:0.2144903689622879\n",
      "\n",
      "―――― Inference  |  Segment 20 ――――\n",
      "  seg20-ch0  MSE:0.09065234661102295  MAE:0.21958056092262268\n",
      "▶ seg20  mean  MSE:0.09065234661102295  MAE:0.21958056092262268\n",
      "\n",
      "―――― Inference  |  Segment 21 ――――\n",
      "  seg21-ch0  MSE:0.10147693753242493  MAE:0.2367081195116043\n",
      "▶ seg21  mean  MSE:0.10147693753242493  MAE:0.2367081195116043\n",
      "\n",
      "―――― Inference  |  Segment 22 ――――\n",
      "  seg22-ch0  MSE:0.09346959739923477  MAE:0.22248242795467377\n",
      "▶ seg22  mean  MSE:0.09346959739923477  MAE:0.22248242795467377\n",
      "\n",
      "―――― Inference  |  Segment 23 ――――\n",
      "  seg23-ch0  MSE:0.1020994633436203  MAE:0.2267988920211792\n",
      "▶ seg23  mean  MSE:0.1020994633436203  MAE:0.2267988920211792\n",
      "\n",
      "―――― Inference  |  Segment 24 ――――\n",
      "  seg24-ch0  MSE:0.10126244276762009  MAE:0.2229042798280716\n",
      "▶ seg24  mean  MSE:0.10126244276762009  MAE:0.2229042798280716\n",
      "\n",
      "―――― Inference  |  Segment 25 ――――\n",
      "  seg25-ch0  MSE:0.08986883610486984  MAE:0.2144578993320465\n",
      "▶ seg25  mean  MSE:0.08986883610486984  MAE:0.2144578993320465\n",
      "\n",
      "―――― Inference  |  Segment 26 ――――\n",
      "  seg26-ch0  MSE:0.09574707597494125  MAE:0.21812383830547333\n",
      "▶ seg26  mean  MSE:0.09574707597494125  MAE:0.21812383830547333\n",
      "\n",
      "―――― Inference  |  Segment 27 ――――\n",
      "  seg27-ch0  MSE:0.10453832149505615  MAE:0.22905737161636353\n",
      "▶ seg27  mean  MSE:0.10453832149505615  MAE:0.22905737161636353\n",
      "\n",
      "―――― Inference  |  Segment 28 ――――\n",
      "  seg28-ch0  MSE:0.09685497730970383  MAE:0.2310781329870224\n",
      "▶ seg28  mean  MSE:0.09685497730970383  MAE:0.2310781329870224\n",
      "\n",
      "―――― Inference  |  Segment 29 ――――\n",
      "  seg29-ch0  MSE:0.09280011057853699  MAE:0.22219829261302948\n",
      "▶ seg29  mean  MSE:0.09280011057853699  MAE:0.22219829261302948\n",
      "\n",
      "―――― Inference  |  Segment 30 ――――\n",
      "  seg30-ch0  MSE:0.08913195878267288  MAE:0.2135235220193863\n",
      "▶ seg30  mean  MSE:0.08913195878267288  MAE:0.2135235220193863\n",
      "\n",
      "―――― Inference  |  Segment 31 ――――\n",
      "  seg31-ch0  MSE:0.10248099267482758  MAE:0.2401016652584076\n",
      "▶ seg31  mean  MSE:0.10248099267482758  MAE:0.2401016652584076\n",
      "\n",
      "―――― Inference  |  Segment 32 ――――\n",
      "  seg32-ch0  MSE:0.09737031906843185  MAE:0.2204795926809311\n",
      "▶ seg32  mean  MSE:0.09737031906843185  MAE:0.2204795926809311\n",
      "\n",
      "―――― Inference  |  Segment 33 ――――\n",
      "  seg33-ch0  MSE:0.09416788071393967  MAE:0.2209419459104538\n",
      "▶ seg33  mean  MSE:0.09416788071393967  MAE:0.2209419459104538\n",
      "\n",
      "―――― Inference  |  Segment 34 ――――\n",
      "  seg34-ch0  MSE:0.0901724249124527  MAE:0.21669910848140717\n",
      "▶ seg34  mean  MSE:0.0901724249124527  MAE:0.21669910848140717\n",
      "\n",
      "―――― Inference  |  Segment 35 ――――\n",
      "  seg35-ch0  MSE:0.09022026509046555  MAE:0.21699638664722443\n",
      "▶ seg35  mean  MSE:0.09022026509046555  MAE:0.21699638664722443\n",
      "\n",
      "―――― Inference  |  Segment 36 ――――\n",
      "  seg36-ch0  MSE:0.09097319096326828  MAE:0.21615740656852722\n",
      "▶ seg36  mean  MSE:0.09097319096326828  MAE:0.21615740656852722\n",
      "\n",
      "―――― Inference  |  Segment 37 ――――\n",
      "  seg37-ch0  MSE:0.09445519000291824  MAE:0.22588588297367096\n",
      "▶ seg37  mean  MSE:0.09445519000291824  MAE:0.22588588297367096\n",
      "\n",
      "―――― Inference  |  Segment 38 ――――\n",
      "  seg38-ch0  MSE:0.09269428253173828  MAE:0.219124436378479\n",
      "▶ seg38  mean  MSE:0.09269428253173828  MAE:0.219124436378479\n",
      "\n",
      "―――― Inference  |  Segment 39 ――――\n",
      "  seg39-ch0  MSE:0.09753841906785965  MAE:0.21754290163516998\n",
      "▶ seg39  mean  MSE:0.09753841906785965  MAE:0.21754290163516998\n",
      "\n",
      "―――― Inference  |  Segment 40 ――――\n",
      "  seg40-ch0  MSE:0.09419649839401245  MAE:0.2252829223871231\n",
      "▶ seg40  mean  MSE:0.09419649839401245  MAE:0.2252829223871231\n",
      "\n",
      "―――― Inference  |  Segment 41 ――――\n",
      "  seg41-ch0  MSE:0.1006382405757904  MAE:0.23696760833263397\n",
      "▶ seg41  mean  MSE:0.1006382405757904  MAE:0.23696760833263397\n",
      "\n",
      "―――― Inference  |  Segment 42 ――――\n",
      "  seg42-ch0  MSE:0.09276088327169418  MAE:0.21830342710018158\n",
      "▶ seg42  mean  MSE:0.09276088327169418  MAE:0.21830342710018158\n",
      "\n",
      "―――― Inference  |  Segment 43 ――――\n",
      "  seg43-ch0  MSE:0.10394752025604248  MAE:0.2257453352212906\n",
      "▶ seg43  mean  MSE:0.10394752025604248  MAE:0.2257453352212906\n",
      "\n",
      "―――― Inference  |  Segment 44 ――――\n",
      "  seg44-ch0  MSE:0.1134858950972557  MAE:0.24362324178218842\n",
      "▶ seg44  mean  MSE:0.1134858950972557  MAE:0.24362324178218842\n",
      "\n",
      "―――― Inference  |  Segment 45 ――――\n",
      "  seg45-ch0  MSE:0.09469635039567947  MAE:0.23043756186962128\n",
      "▶ seg45  mean  MSE:0.09469635039567947  MAE:0.23043756186962128\n",
      "\n",
      "―――― Inference  |  Segment 46 ――――\n",
      "  seg46-ch0  MSE:0.09299399703741074  MAE:0.22506791353225708\n",
      "▶ seg46  mean  MSE:0.09299399703741074  MAE:0.22506791353225708\n",
      "\n",
      "―――― Inference  |  Segment 47 ――――\n",
      "  seg47-ch0  MSE:0.0924784317612648  MAE:0.2201063185930252\n",
      "▶ seg47  mean  MSE:0.0924784317612648  MAE:0.2201063185930252\n",
      "\n",
      "―――― Inference  |  Segment 48 ――――\n",
      "  seg48-ch0  MSE:0.09059835970401764  MAE:0.2171367108821869\n",
      "▶ seg48  mean  MSE:0.09059835970401764  MAE:0.2171367108821869\n",
      "\n",
      "―――― Inference  |  Segment 49 ――――\n",
      "  seg49-ch0  MSE:0.09257093071937561  MAE:0.22275476157665253\n",
      "▶ seg49  mean  MSE:0.09257093071937561  MAE:0.22275476157665253\n",
      "\n",
      "―――― Inference  |  Segment 50 ――――\n",
      "  seg50-ch0  MSE:0.09148142486810684  MAE:0.22132715582847595\n",
      "▶ seg50  mean  MSE:0.09148142486810684  MAE:0.22132715582847595\n",
      "\n",
      "―――― Inference  |  Segment 51 ――――\n",
      "  seg51-ch0  MSE:0.09714767336845398  MAE:0.23023128509521484\n",
      "▶ seg51  mean  MSE:0.09714767336845398  MAE:0.23023128509521484\n",
      "\n",
      "―――― Inference  |  Segment 52 ――――\n",
      "  seg52-ch0  MSE:0.09145662188529968  MAE:0.2201942652463913\n",
      "▶ seg52  mean  MSE:0.09145662188529968  MAE:0.2201942652463913\n",
      "\n",
      "―――― Inference  |  Segment 53 ――――\n",
      "  seg53-ch0  MSE:0.09099200367927551  MAE:0.21164509654045105\n",
      "▶ seg53  mean  MSE:0.09099200367927551  MAE:0.21164509654045105\n",
      "\n",
      "―――― Inference  |  Segment 54 ――――\n",
      "  seg54-ch0  MSE:0.09058381617069244  MAE:0.21104134619235992\n",
      "▶ seg54  mean  MSE:0.09058381617069244  MAE:0.21104134619235992\n",
      "\n",
      "―――― Inference  |  Segment 55 ――――\n",
      "  seg55-ch0  MSE:0.09345045685768127  MAE:0.22269967198371887\n",
      "▶ seg55  mean  MSE:0.09345045685768127  MAE:0.22269967198371887\n",
      "\n",
      "―――― Inference  |  Segment 56 ――――\n",
      "  seg56-ch0  MSE:0.0954098179936409  MAE:0.2201177030801773\n",
      "▶ seg56  mean  MSE:0.0954098179936409  MAE:0.2201177030801773\n",
      "\n",
      "―――― Inference  |  Segment 57 ――――\n",
      "  seg57-ch0  MSE:0.09999049454927444  MAE:0.24334874749183655\n",
      "▶ seg57  mean  MSE:0.09999049454927444  MAE:0.24334874749183655\n",
      "\n",
      "―――― Inference  |  Segment 58 ――――\n",
      "  seg58-ch0  MSE:0.09098956733942032  MAE:0.2123950868844986\n",
      "▶ seg58  mean  MSE:0.09098956733942032  MAE:0.2123950868844986\n",
      "\n",
      "―――― Inference  |  Segment 59 ――――\n",
      "  seg59-ch0  MSE:0.09072858840227127  MAE:0.214629128575325\n",
      "▶ seg59  mean  MSE:0.09072858840227127  MAE:0.214629128575325\n",
      "\n",
      "―――― Inference  |  Segment 60 ――――\n",
      "  seg60-ch0  MSE:0.08991257101297379  MAE:0.21550026535987854\n",
      "▶ seg60  mean  MSE:0.08991257101297379  MAE:0.21550026535987854\n",
      "\n",
      "―――― Inference  |  Segment 61 ――――\n",
      "  seg61-ch0  MSE:0.09249847382307053  MAE:0.21247664093971252\n",
      "▶ seg61  mean  MSE:0.09249847382307053  MAE:0.21247664093971252\n",
      "\n",
      "―――― Inference  |  Segment 62 ――――\n",
      "  seg62-ch0  MSE:0.09139008074998856  MAE:0.21417687833309174\n",
      "▶ seg62  mean  MSE:0.09139008074998856  MAE:0.21417687833309174\n",
      "\n",
      "―――― Inference  |  Segment 63 ――――\n",
      "  seg63-ch0  MSE:0.09232848882675171  MAE:0.22303958237171173\n",
      "▶ seg63  mean  MSE:0.09232848882675171  MAE:0.22303958237171173\n",
      "\n",
      "―――― Inference  |  Segment 64 ――――\n",
      "  seg64-ch0  MSE:0.10110189020633698  MAE:0.2234519124031067\n",
      "▶ seg64  mean  MSE:0.10110189020633698  MAE:0.2234519124031067\n",
      "\n",
      "seg10 ch0 MSE : 0.08871441\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import r2_score\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "C        = 1                                \n",
    "P        = base_cfg.pred_len                \n",
    "seg_cnt  = 65\n",
    "batch_sz = 32\n",
    "\n",
    "results2_ETTm2_E1_val_1E = {}  \n",
    "\n",
    "for seg in range(seg_cnt):\n",
    "    print(f\"\\n―――― Inference  |  Segment {seg} ――――\")\n",
    "\n",
    "    \n",
    "    pv = val_pred_segments_E1[:, seg, :, :]         \n",
    "    ds = TensorDataset(val_sequences, val_labels, pv) \n",
    "    dl = DataLoader(ds, batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "    \n",
    "    pred_ch, true_ch, metrics = [], [], {}\n",
    "\n",
    "    \n",
    "    for ch in range(C):\n",
    "        ckpt = Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{ch}\" / \"checkpoint.pth\"\n",
    "        if not ckpt.exists():\n",
    "            print(f\"[Warn] seg{seg}-ch{ch} ckpt 없음 → skip\");  continue\n",
    "\n",
    "        \n",
    "        model = Model(base_cfg).to(device)\n",
    "        model.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        preds, trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, pv_batch in dl:                 \n",
    "                xb  = xb.float().to(device)\n",
    "                yb  = yb.float()        \n",
    "                pv_ = pv_batch.float().to(device)\n",
    "\n",
    "                out = model(xb, pv_)                     \n",
    "                preds.append(out[:, -P:, ch].cpu())\n",
    "                trues.append(yb[:, -P:, ch])\n",
    "\n",
    "        preds = torch.cat(preds, 0)     \n",
    "        trues = torch.cat(trues, 0)\n",
    "        pred_ch.append(preds)\n",
    "        true_ch.append(trues)\n",
    "\n",
    "        \n",
    "        p, t = preds.reshape(-1).cpu().numpy(), trues.reshape(-1).cpu().numpy()\n",
    "        mse  = np.mean((p - t)**2)\n",
    "        mae  = np.mean(np.abs(p - t))\n",
    "        metrics[ch] = (mse, mae)\n",
    "\n",
    "        print(f\"  seg{seg}-ch{ch}  MSE:{mse}  MAE:{mae}\")\n",
    "\n",
    "        del model; torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "    pred_all = torch.stack(pred_ch,  dim=2)   \n",
    "    true_all = torch.stack(true_ch,  dim=2)\n",
    "\n",
    "    \n",
    "    mse_avg = np.mean([m for m,_ in metrics.values()])\n",
    "    mae_avg = np.mean([a for _,a in metrics.values()])\n",
    "    print(f\"▶ seg{seg}  mean  MSE:{mse_avg}  MAE:{mae_avg}\")\n",
    "\n",
    "    \n",
    "    results2_ETTm2_E1_val_1E[seg] = {\n",
    "        \"pred2_E1_val_1E\"    : pred_all,   \n",
    "        \"true2_E1_val_1E\"    : true_all,   \n",
    "        \"metrics2_E1_val_1E\" : metrics     \n",
    "    }\n",
    "\n",
    "\n",
    "seg10_ch0_mse = results2_ETTm2_E1_val_1E[10][\"metrics2_E1_val_1E\"][0][0]\n",
    "print(\"\\nseg10 ch0 MSE :\", seg10_ch0_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686c6fe9",
   "metadata": {},
   "source": [
    "# 2nd Inference for Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ada563",
   "metadata": {},
   "source": [
    "## ES->1E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1511a5",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb1e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "\n",
    "pred_len = 96\n",
    "seq_len = 336 \n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual,\n",
    "                 learning_rate, lradj, patience,\n",
    "                 save_path, attach_pv):\n",
    "        self.seq_len  = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in   = enc_in          \n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv    = attach_pv\n",
    "\n",
    "\n",
    "base_cfg = Configs(\n",
    "    pred_len         = 96,\n",
    "    seq_len          = 336 ,\n",
    "    enc_in           = 1,\n",
    "    individual       = True,\n",
    "    learning_rate    = 0.001,\n",
    "    lradj            = 'type1',\n",
    "    patience         = 3,\n",
    "    save_path        = \"./model2_ETTm2_EES_1E\",\n",
    "    attach_pv  = True,\n",
    ")\n",
    "Path(base_cfg.save_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2364b90",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e612632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "―――― Inference  |  Segment 0 ――――\n",
      "  seg0-ch0  MSE:0.07553787529468536  MAE:0.2044474482536316\n",
      "▶ seg0  mean  MSE:0.07553787529468536  MAE:0.2044474482536316\n",
      "\n",
      "―――― Inference  |  Segment 1 ――――\n",
      "  seg1-ch0  MSE:0.0722019225358963  MAE:0.19953452050685883\n",
      "▶ seg1  mean  MSE:0.0722019225358963  MAE:0.19953452050685883\n",
      "\n",
      "―――― Inference  |  Segment 2 ――――\n",
      "  seg2-ch0  MSE:0.08134885132312775  MAE:0.21134522557258606\n",
      "▶ seg2  mean  MSE:0.08134885132312775  MAE:0.21134522557258606\n",
      "\n",
      "―――― Inference  |  Segment 3 ――――\n",
      "  seg3-ch0  MSE:0.07780439406633377  MAE:0.2073831409215927\n",
      "▶ seg3  mean  MSE:0.07780439406633377  MAE:0.2073831409215927\n",
      "\n",
      "―――― Inference  |  Segment 4 ――――\n",
      "  seg4-ch0  MSE:0.06749197095632553  MAE:0.19139336049556732\n",
      "▶ seg4  mean  MSE:0.06749197095632553  MAE:0.19139336049556732\n",
      "\n",
      "―――― Inference  |  Segment 5 ――――\n",
      "  seg5-ch0  MSE:0.0778064876794815  MAE:0.21087466180324554\n",
      "▶ seg5  mean  MSE:0.0778064876794815  MAE:0.21087466180324554\n",
      "\n",
      "―――― Inference  |  Segment 6 ――――\n",
      "  seg6-ch0  MSE:0.0702066570520401  MAE:0.19848278164863586\n",
      "▶ seg6  mean  MSE:0.0702066570520401  MAE:0.19848278164863586\n",
      "\n",
      "―――― Inference  |  Segment 7 ――――\n",
      "  seg7-ch0  MSE:0.08997052162885666  MAE:0.2230915129184723\n",
      "▶ seg7  mean  MSE:0.08997052162885666  MAE:0.2230915129184723\n",
      "\n",
      "―――― Inference  |  Segment 8 ――――\n",
      "  seg8-ch0  MSE:0.07087226212024689  MAE:0.19960688054561615\n",
      "▶ seg8  mean  MSE:0.07087226212024689  MAE:0.19960688054561615\n",
      "\n",
      "―――― Inference  |  Segment 9 ――――\n",
      "  seg9-ch0  MSE:0.08037497848272324  MAE:0.21319188177585602\n",
      "▶ seg9  mean  MSE:0.08037497848272324  MAE:0.21319188177585602\n",
      "\n",
      "―――― Inference  |  Segment 10 ――――\n",
      "  seg10-ch0  MSE:0.06965446472167969  MAE:0.20011067390441895\n",
      "▶ seg10  mean  MSE:0.06965446472167969  MAE:0.20011067390441895\n",
      "\n",
      "―――― Inference  |  Segment 11 ――――\n",
      "  seg11-ch0  MSE:0.07412076741456985  MAE:0.20343942940235138\n",
      "▶ seg11  mean  MSE:0.07412076741456985  MAE:0.20343942940235138\n",
      "\n",
      "―――― Inference  |  Segment 12 ――――\n",
      "  seg12-ch0  MSE:0.07165765017271042  MAE:0.19745326042175293\n",
      "▶ seg12  mean  MSE:0.07165765017271042  MAE:0.19745326042175293\n",
      "\n",
      "―――― Inference  |  Segment 13 ――――\n",
      "  seg13-ch0  MSE:0.06892861425876617  MAE:0.19374603033065796\n",
      "▶ seg13  mean  MSE:0.06892861425876617  MAE:0.19374603033065796\n",
      "\n",
      "―――― Inference  |  Segment 14 ――――\n",
      "  seg14-ch0  MSE:0.10125426203012466  MAE:0.24041418731212616\n",
      "▶ seg14  mean  MSE:0.10125426203012466  MAE:0.24041418731212616\n",
      "\n",
      "―――― Inference  |  Segment 15 ――――\n",
      "  seg15-ch0  MSE:0.0732644721865654  MAE:0.2029491662979126\n",
      "▶ seg15  mean  MSE:0.0732644721865654  MAE:0.2029491662979126\n",
      "\n",
      "―――― Inference  |  Segment 16 ――――\n",
      "  seg16-ch0  MSE:0.07693111151456833  MAE:0.20669180154800415\n",
      "▶ seg16  mean  MSE:0.07693111151456833  MAE:0.20669180154800415\n",
      "\n",
      "―――― Inference  |  Segment 17 ――――\n",
      "  seg17-ch0  MSE:0.06829410046339035  MAE:0.1942969709634781\n",
      "▶ seg17  mean  MSE:0.06829410046339035  MAE:0.1942969709634781\n",
      "\n",
      "―――― Inference  |  Segment 18 ――――\n",
      "  seg18-ch0  MSE:0.06992873549461365  MAE:0.1964888870716095\n",
      "▶ seg18  mean  MSE:0.06992873549461365  MAE:0.1964888870716095\n",
      "\n",
      "―――― Inference  |  Segment 19 ――――\n",
      "  seg19-ch0  MSE:0.06692542880773544  MAE:0.1923440843820572\n",
      "▶ seg19  mean  MSE:0.06692542880773544  MAE:0.1923440843820572\n",
      "\n",
      "―――― Inference  |  Segment 20 ――――\n",
      "  seg20-ch0  MSE:0.06949292123317719  MAE:0.1963285356760025\n",
      "▶ seg20  mean  MSE:0.06949292123317719  MAE:0.1963285356760025\n",
      "\n",
      "―――― Inference  |  Segment 21 ――――\n",
      "  seg21-ch0  MSE:0.074863500893116  MAE:0.2036578208208084\n",
      "▶ seg21  mean  MSE:0.074863500893116  MAE:0.2036578208208084\n",
      "\n",
      "―――― Inference  |  Segment 22 ――――\n",
      "  seg22-ch0  MSE:0.06893941015005112  MAE:0.19357997179031372\n",
      "▶ seg22  mean  MSE:0.06893941015005112  MAE:0.19357997179031372\n",
      "\n",
      "―――― Inference  |  Segment 23 ――――\n",
      "  seg23-ch0  MSE:0.09988260269165039  MAE:0.23705701529979706\n",
      "▶ seg23  mean  MSE:0.09988260269165039  MAE:0.23705701529979706\n",
      "\n",
      "―――― Inference  |  Segment 24 ――――\n",
      "  seg24-ch0  MSE:0.07833970338106155  MAE:0.21262472867965698\n",
      "▶ seg24  mean  MSE:0.07833970338106155  MAE:0.21262472867965698\n",
      "\n",
      "―――― Inference  |  Segment 25 ――――\n",
      "  seg25-ch0  MSE:0.06851179897785187  MAE:0.19466111063957214\n",
      "▶ seg25  mean  MSE:0.06851179897785187  MAE:0.19466111063957214\n",
      "\n",
      "―――― Inference  |  Segment 26 ――――\n",
      "  seg26-ch0  MSE:0.07473542541265488  MAE:0.20544932782649994\n",
      "▶ seg26  mean  MSE:0.07473542541265488  MAE:0.20544932782649994\n",
      "\n",
      "―――― Inference  |  Segment 27 ――――\n",
      "  seg27-ch0  MSE:0.0683131217956543  MAE:0.19387748837471008\n",
      "▶ seg27  mean  MSE:0.0683131217956543  MAE:0.19387748837471008\n",
      "\n",
      "―――― Inference  |  Segment 28 ――――\n",
      "  seg28-ch0  MSE:0.07625254988670349  MAE:0.20535501837730408\n",
      "▶ seg28  mean  MSE:0.07625254988670349  MAE:0.20535501837730408\n",
      "\n",
      "―――― Inference  |  Segment 29 ――――\n",
      "  seg29-ch0  MSE:0.07065097987651825  MAE:0.19723862409591675\n",
      "▶ seg29  mean  MSE:0.07065097987651825  MAE:0.19723862409591675\n",
      "\n",
      "―――― Inference  |  Segment 30 ――――\n",
      "  seg30-ch0  MSE:0.06930600106716156  MAE:0.1953529417514801\n",
      "▶ seg30  mean  MSE:0.06930600106716156  MAE:0.1953529417514801\n",
      "\n",
      "―――― Inference  |  Segment 31 ――――\n",
      "  seg31-ch0  MSE:0.06859057396650314  MAE:0.1936921924352646\n",
      "▶ seg31  mean  MSE:0.06859057396650314  MAE:0.1936921924352646\n",
      "\n",
      "―――― Inference  |  Segment 32 ――――\n",
      "  seg32-ch0  MSE:0.08181450515985489  MAE:0.213919997215271\n",
      "▶ seg32  mean  MSE:0.08181450515985489  MAE:0.213919997215271\n",
      "\n",
      "―――― Inference  |  Segment 33 ――――\n",
      "  seg33-ch0  MSE:0.0807638019323349  MAE:0.21077580749988556\n",
      "▶ seg33  mean  MSE:0.0807638019323349  MAE:0.21077580749988556\n",
      "\n",
      "―――― Inference  |  Segment 34 ――――\n",
      "  seg34-ch0  MSE:0.07345784455537796  MAE:0.20564022660255432\n",
      "▶ seg34  mean  MSE:0.07345784455537796  MAE:0.20564022660255432\n",
      "\n",
      "―――― Inference  |  Segment 35 ――――\n",
      "  seg35-ch0  MSE:0.07373573631048203  MAE:0.20144300162792206\n",
      "▶ seg35  mean  MSE:0.07373573631048203  MAE:0.20144300162792206\n",
      "\n",
      "―――― Inference  |  Segment 36 ――――\n",
      "  seg36-ch0  MSE:0.07891617715358734  MAE:0.20797717571258545\n",
      "▶ seg36  mean  MSE:0.07891617715358734  MAE:0.20797717571258545\n",
      "\n",
      "―――― Inference  |  Segment 37 ――――\n",
      "  seg37-ch0  MSE:0.09884435683488846  MAE:0.23424828052520752\n",
      "▶ seg37  mean  MSE:0.09884435683488846  MAE:0.23424828052520752\n",
      "\n",
      "―――― Inference  |  Segment 38 ――――\n",
      "  seg38-ch0  MSE:0.07253897935152054  MAE:0.2015119194984436\n",
      "▶ seg38  mean  MSE:0.07253897935152054  MAE:0.2015119194984436\n",
      "\n",
      "―――― Inference  |  Segment 39 ――――\n",
      "  seg39-ch0  MSE:0.07079965621232986  MAE:0.20061077177524567\n",
      "▶ seg39  mean  MSE:0.07079965621232986  MAE:0.20061077177524567\n",
      "\n",
      "―――― Inference  |  Segment 40 ――――\n",
      "  seg40-ch0  MSE:0.07304498553276062  MAE:0.2003219574689865\n",
      "▶ seg40  mean  MSE:0.07304498553276062  MAE:0.2003219574689865\n",
      "\n",
      "―――― Inference  |  Segment 41 ――――\n",
      "  seg41-ch0  MSE:0.07417170703411102  MAE:0.20338015258312225\n",
      "▶ seg41  mean  MSE:0.07417170703411102  MAE:0.20338015258312225\n",
      "\n",
      "―――― Inference  |  Segment 42 ――――\n",
      "  seg42-ch0  MSE:0.07227380573749542  MAE:0.19996578991413116\n",
      "▶ seg42  mean  MSE:0.07227380573749542  MAE:0.19996578991413116\n",
      "\n",
      "―――― Inference  |  Segment 43 ――――\n",
      "  seg43-ch0  MSE:0.07375454902648926  MAE:0.20397937297821045\n",
      "▶ seg43  mean  MSE:0.07375454902648926  MAE:0.20397937297821045\n",
      "\n",
      "―――― Inference  |  Segment 44 ――――\n",
      "  seg44-ch0  MSE:0.07094541937112808  MAE:0.1987048238515854\n",
      "▶ seg44  mean  MSE:0.07094541937112808  MAE:0.1987048238515854\n",
      "\n",
      "―――― Inference  |  Segment 45 ――――\n",
      "  seg45-ch0  MSE:0.06846415251493454  MAE:0.1964285522699356\n",
      "▶ seg45  mean  MSE:0.06846415251493454  MAE:0.1964285522699356\n",
      "\n",
      "―――― Inference  |  Segment 46 ――――\n",
      "  seg46-ch0  MSE:0.07647135853767395  MAE:0.20747792720794678\n",
      "▶ seg46  mean  MSE:0.07647135853767395  MAE:0.20747792720794678\n",
      "\n",
      "―――― Inference  |  Segment 47 ――――\n",
      "  seg47-ch0  MSE:0.07827194780111313  MAE:0.2106158286333084\n",
      "▶ seg47  mean  MSE:0.07827194780111313  MAE:0.2106158286333084\n",
      "\n",
      "―――― Inference  |  Segment 48 ――――\n",
      "  seg48-ch0  MSE:0.07265955209732056  MAE:0.20124000310897827\n",
      "▶ seg48  mean  MSE:0.07265955209732056  MAE:0.20124000310897827\n",
      "\n",
      "―――― Inference  |  Segment 49 ――――\n",
      "  seg49-ch0  MSE:0.08017615228891373  MAE:0.21140062808990479\n",
      "▶ seg49  mean  MSE:0.08017615228891373  MAE:0.21140062808990479\n",
      "\n",
      "―――― Inference  |  Segment 50 ――――\n",
      "  seg50-ch0  MSE:0.06979172676801682  MAE:0.19733469188213348\n",
      "▶ seg50  mean  MSE:0.06979172676801682  MAE:0.19733469188213348\n",
      "\n",
      "―――― Inference  |  Segment 51 ――――\n",
      "  seg51-ch0  MSE:0.07048024982213974  MAE:0.19766640663146973\n",
      "▶ seg51  mean  MSE:0.07048024982213974  MAE:0.19766640663146973\n",
      "\n",
      "―――― Inference  |  Segment 52 ――――\n",
      "  seg52-ch0  MSE:0.09845107048749924  MAE:0.24204735457897186\n",
      "▶ seg52  mean  MSE:0.09845107048749924  MAE:0.24204735457897186\n",
      "\n",
      "―――― Inference  |  Segment 53 ――――\n",
      "  seg53-ch0  MSE:0.07463983446359634  MAE:0.20489022135734558\n",
      "▶ seg53  mean  MSE:0.07463983446359634  MAE:0.20489022135734558\n",
      "\n",
      "―――― Inference  |  Segment 54 ――――\n",
      "  seg54-ch0  MSE:0.07228431850671768  MAE:0.20137152075767517\n",
      "▶ seg54  mean  MSE:0.07228431850671768  MAE:0.20137152075767517\n",
      "\n",
      "―――― Inference  |  Segment 55 ――――\n",
      "  seg55-ch0  MSE:0.08219380676746368  MAE:0.21506501734256744\n",
      "▶ seg55  mean  MSE:0.08219380676746368  MAE:0.21506501734256744\n",
      "\n",
      "―――― Inference  |  Segment 56 ――――\n",
      "  seg56-ch0  MSE:0.06769786030054092  MAE:0.19243831932544708\n",
      "▶ seg56  mean  MSE:0.06769786030054092  MAE:0.19243831932544708\n",
      "\n",
      "―――― Inference  |  Segment 57 ――――\n",
      "  seg57-ch0  MSE:0.07615675032138824  MAE:0.2051491141319275\n",
      "▶ seg57  mean  MSE:0.07615675032138824  MAE:0.2051491141319275\n",
      "\n",
      "―――― Inference  |  Segment 58 ――――\n",
      "  seg58-ch0  MSE:0.08645612001419067  MAE:0.22335824370384216\n",
      "▶ seg58  mean  MSE:0.08645612001419067  MAE:0.22335824370384216\n",
      "\n",
      "―――― Inference  |  Segment 59 ――――\n",
      "  seg59-ch0  MSE:0.07628851383924484  MAE:0.2082960307598114\n",
      "▶ seg59  mean  MSE:0.07628851383924484  MAE:0.2082960307598114\n",
      "\n",
      "―――― Inference  |  Segment 60 ――――\n",
      "  seg60-ch0  MSE:0.0820813775062561  MAE:0.21743936836719513\n",
      "▶ seg60  mean  MSE:0.0820813775062561  MAE:0.21743936836719513\n",
      "\n",
      "―――― Inference  |  Segment 61 ――――\n",
      "  seg61-ch0  MSE:0.07173069566488266  MAE:0.20276325941085815\n",
      "▶ seg61  mean  MSE:0.07173069566488266  MAE:0.20276325941085815\n",
      "\n",
      "―――― Inference  |  Segment 62 ――――\n",
      "  seg62-ch0  MSE:0.06941387802362442  MAE:0.19734454154968262\n",
      "▶ seg62  mean  MSE:0.06941387802362442  MAE:0.19734454154968262\n",
      "\n",
      "―――― Inference  |  Segment 63 ――――\n",
      "  seg63-ch0  MSE:0.07020743936300278  MAE:0.1987963616847992\n",
      "▶ seg63  mean  MSE:0.07020743936300278  MAE:0.1987963616847992\n",
      "\n",
      "―――― Inference  |  Segment 64 ――――\n",
      "  seg64-ch0  MSE:0.07941613346338272  MAE:0.2103652060031891\n",
      "▶ seg64  mean  MSE:0.07941613346338272  MAE:0.2103652060031891\n",
      "\n",
      "seg10 ch0 MSE : 0.069654465\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import r2_score\n",
    "from pathlib import Path\n",
    "\n",
    "C        = 1                                \n",
    "P        = base_cfg.pred_len                \n",
    "seg_cnt  = 65\n",
    "batch_sz = 32\n",
    "\n",
    "results2_ETTm2_ES_test_1E = {}  \n",
    "\n",
    "for seg in range(seg_cnt):\n",
    "    print(f\"\\n―――― Inference  |  Segment {seg} ――――\")\n",
    "\n",
    "    \n",
    "    pv = test_pred_segments_ES[:, seg, :, :]         \n",
    "    ds = TensorDataset(test_sequences, test_labels, pv) \n",
    "    dl = DataLoader(ds, batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "    \n",
    "    pred_ch, true_ch, metrics = [], [], {}\n",
    "\n",
    "    \n",
    "    for ch in range(C):\n",
    "        ckpt = Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{ch}\" / \"checkpoint.pth\"\n",
    "        if not ckpt.exists():\n",
    "            print(f\"[Warn] seg{seg}-ch{ch} ckpt 없음 → skip\");  continue\n",
    "\n",
    "        \n",
    "        model = Model(base_cfg).to(device)\n",
    "        model.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        preds, trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, pv_batch in dl:                 \n",
    "                xb  = xb.float().to(device)\n",
    "                yb  = yb.float()        \n",
    "                pv_ = pv_batch.float().to(device)\n",
    "\n",
    "                out = model(xb, pv_)                     \n",
    "                preds.append(out[:, -P:, ch].cpu())\n",
    "                trues.append(yb[:, -P:, ch])\n",
    "\n",
    "        preds = torch.cat(preds, 0)     \n",
    "        trues = torch.cat(trues, 0)\n",
    "        pred_ch.append(preds)\n",
    "        true_ch.append(trues)\n",
    "\n",
    "        \n",
    "        p, t = preds.reshape(-1).cpu().numpy(), trues.reshape(-1).cpu().numpy()\n",
    "        mse  = np.mean((p - t)**2)\n",
    "        mae  = np.mean(np.abs(p - t))\n",
    "        metrics[ch] = (mse, mae)\n",
    "\n",
    "        print(f\"  seg{seg}-ch{ch}  MSE:{mse}  MAE:{mae}\")\n",
    "\n",
    "        del model; torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "    pred_all = torch.stack(pred_ch,  dim=2)   \n",
    "    true_all = torch.stack(true_ch,  dim=2)\n",
    "\n",
    "    \n",
    "    mse_avg = np.mean([m for m,_ in metrics.values()])\n",
    "    mae_avg = np.mean([a for _,a in metrics.values()])\n",
    "    print(f\"▶ seg{seg}  mean  MSE:{mse_avg}  MAE:{mae_avg}\")\n",
    "\n",
    "    \n",
    "    results2_ETTm2_ES_test_1E[seg] = {\n",
    "        \"pred2_ES_test_1E\"    : pred_all,   \n",
    "        \"true2_ES_test_1E\"    : true_all,   \n",
    "        \"metrics2_ES_test_1E\" : metrics     \n",
    "    }\n",
    "\n",
    "\n",
    "seg10_ch0_mse = results2_ETTm2_ES_test_1E[10][\"metrics2_ES_test_1E\"][0][0]\n",
    "print(\"\\nseg10 ch0 MSE :\", seg10_ch0_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eee5de",
   "metadata": {},
   "source": [
    "## 1E->1E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd7612",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b5562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "\n",
    "pred_len = 96\n",
    "seq_len = 336\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual,\n",
    "                 learning_rate, lradj, patience,\n",
    "                 save_path, attach_pv):\n",
    "        self.seq_len  = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in   = enc_in          \n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv    = attach_pv\n",
    "\n",
    "\n",
    "\n",
    "base_cfg = Configs(\n",
    "    pred_len         = 96,\n",
    "    seq_len          = 336 ,\n",
    "    enc_in           = 1,\n",
    "    individual       = True,\n",
    "    learning_rate    = 0.001,\n",
    "    lradj            = 'type1',\n",
    "    patience         = 3,\n",
    "    save_path        = \"./model2_ETTm2_E1_1E\",\n",
    "    attach_pv  = True,\n",
    ")\n",
    "Path(base_cfg.save_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e45662",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3f16a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "―――― Inference  |  Segment 0 ――――\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  seg0-ch0  MSE:0.07115178555250168  MAE:0.1977097988128662\n",
      "▶ seg0  mean  MSE:0.07115178555250168  MAE:0.1977097988128662\n",
      "\n",
      "―――― Inference  |  Segment 1 ――――\n",
      "  seg1-ch0  MSE:0.07011184096336365  MAE:0.19701342284679413\n",
      "▶ seg1  mean  MSE:0.07011184096336365  MAE:0.19701342284679413\n",
      "\n",
      "―――― Inference  |  Segment 2 ――――\n",
      "  seg2-ch0  MSE:0.07117436826229095  MAE:0.1994733363389969\n",
      "▶ seg2  mean  MSE:0.07117436826229095  MAE:0.1994733363389969\n",
      "\n",
      "―――― Inference  |  Segment 3 ――――\n",
      "  seg3-ch0  MSE:0.06700856238603592  MAE:0.19191287457942963\n",
      "▶ seg3  mean  MSE:0.06700856238603592  MAE:0.19191287457942963\n",
      "\n",
      "―――― Inference  |  Segment 4 ――――\n",
      "  seg4-ch0  MSE:0.07513946294784546  MAE:0.2051100879907608\n",
      "▶ seg4  mean  MSE:0.07513946294784546  MAE:0.2051100879907608\n",
      "\n",
      "―――― Inference  |  Segment 5 ――――\n",
      "  seg5-ch0  MSE:0.0838283896446228  MAE:0.21797211468219757\n",
      "▶ seg5  mean  MSE:0.0838283896446228  MAE:0.21797211468219757\n",
      "\n",
      "―――― Inference  |  Segment 6 ――――\n",
      "  seg6-ch0  MSE:0.06986470520496368  MAE:0.19794106483459473\n",
      "▶ seg6  mean  MSE:0.06986470520496368  MAE:0.19794106483459473\n",
      "\n",
      "―――― Inference  |  Segment 7 ――――\n",
      "  seg7-ch0  MSE:0.07121114432811737  MAE:0.19837623834609985\n",
      "▶ seg7  mean  MSE:0.07121114432811737  MAE:0.19837623834609985\n",
      "\n",
      "―――― Inference  |  Segment 8 ――――\n",
      "  seg8-ch0  MSE:0.06997516751289368  MAE:0.19641755521297455\n",
      "▶ seg8  mean  MSE:0.06997516751289368  MAE:0.19641755521297455\n",
      "\n",
      "―――― Inference  |  Segment 9 ――――\n",
      "  seg9-ch0  MSE:0.07103132456541061  MAE:0.1996232122182846\n",
      "▶ seg9  mean  MSE:0.07103132456541061  MAE:0.1996232122182846\n",
      "\n",
      "―――― Inference  |  Segment 10 ――――\n",
      "  seg10-ch0  MSE:0.06806167960166931  MAE:0.1926247626543045\n",
      "▶ seg10  mean  MSE:0.06806167960166931  MAE:0.1926247626543045\n",
      "\n",
      "―――― Inference  |  Segment 11 ――――\n",
      "  seg11-ch0  MSE:0.076664499938488  MAE:0.20697233080863953\n",
      "▶ seg11  mean  MSE:0.076664499938488  MAE:0.20697233080863953\n",
      "\n",
      "―――― Inference  |  Segment 12 ――――\n",
      "  seg12-ch0  MSE:0.0707225650548935  MAE:0.20044593513011932\n",
      "▶ seg12  mean  MSE:0.0707225650548935  MAE:0.20044593513011932\n",
      "\n",
      "―――― Inference  |  Segment 13 ――――\n",
      "  seg13-ch0  MSE:0.08319017291069031  MAE:0.21623803675174713\n",
      "▶ seg13  mean  MSE:0.08319017291069031  MAE:0.21623803675174713\n",
      "\n",
      "―――― Inference  |  Segment 14 ――――\n",
      "  seg14-ch0  MSE:0.0686974748969078  MAE:0.19515100121498108\n",
      "▶ seg14  mean  MSE:0.0686974748969078  MAE:0.19515100121498108\n",
      "\n",
      "―――― Inference  |  Segment 15 ――――\n",
      "  seg15-ch0  MSE:0.06755515933036804  MAE:0.1933649480342865\n",
      "▶ seg15  mean  MSE:0.06755515933036804  MAE:0.1933649480342865\n",
      "\n",
      "―――― Inference  |  Segment 16 ――――\n",
      "  seg16-ch0  MSE:0.07351521402597427  MAE:0.20479735732078552\n",
      "▶ seg16  mean  MSE:0.07351521402597427  MAE:0.20479735732078552\n",
      "\n",
      "―――― Inference  |  Segment 17 ――――\n",
      "  seg17-ch0  MSE:0.07018058001995087  MAE:0.19682857394218445\n",
      "▶ seg17  mean  MSE:0.07018058001995087  MAE:0.19682857394218445\n",
      "\n",
      "―――― Inference  |  Segment 18 ――――\n",
      "  seg18-ch0  MSE:0.07768934220075607  MAE:0.2098718285560608\n",
      "▶ seg18  mean  MSE:0.07768934220075607  MAE:0.2098718285560608\n",
      "\n",
      "―――― Inference  |  Segment 19 ――――\n",
      "  seg19-ch0  MSE:0.07015874981880188  MAE:0.19727572798728943\n",
      "▶ seg19  mean  MSE:0.07015874981880188  MAE:0.19727572798728943\n",
      "\n",
      "―――― Inference  |  Segment 20 ――――\n",
      "  seg20-ch0  MSE:0.07597850263118744  MAE:0.20526181161403656\n",
      "▶ seg20  mean  MSE:0.07597850263118744  MAE:0.20526181161403656\n",
      "\n",
      "―――― Inference  |  Segment 21 ――――\n",
      "  seg21-ch0  MSE:0.08493316173553467  MAE:0.22353346645832062\n",
      "▶ seg21  mean  MSE:0.08493316173553467  MAE:0.22353346645832062\n",
      "\n",
      "―――― Inference  |  Segment 22 ――――\n",
      "  seg22-ch0  MSE:0.07599741220474243  MAE:0.20405057072639465\n",
      "▶ seg22  mean  MSE:0.07599741220474243  MAE:0.20405057072639465\n",
      "\n",
      "―――― Inference  |  Segment 23 ――――\n",
      "  seg23-ch0  MSE:0.08218147605657578  MAE:0.21650724112987518\n",
      "▶ seg23  mean  MSE:0.08218147605657578  MAE:0.21650724112987518\n",
      "\n",
      "―――― Inference  |  Segment 24 ――――\n",
      "  seg24-ch0  MSE:0.07614085078239441  MAE:0.20817865431308746\n",
      "▶ seg24  mean  MSE:0.07614085078239441  MAE:0.20817865431308746\n",
      "\n",
      "―――― Inference  |  Segment 25 ――――\n",
      "  seg25-ch0  MSE:0.07024624198675156  MAE:0.19657617807388306\n",
      "▶ seg25  mean  MSE:0.07024624198675156  MAE:0.19657617807388306\n",
      "\n",
      "―――― Inference  |  Segment 26 ――――\n",
      "  seg26-ch0  MSE:0.07449120283126831  MAE:0.2036912441253662\n",
      "▶ seg26  mean  MSE:0.07449120283126831  MAE:0.2036912441253662\n",
      "\n",
      "―――― Inference  |  Segment 27 ――――\n",
      "  seg27-ch0  MSE:0.08328159153461456  MAE:0.21798570454120636\n",
      "▶ seg27  mean  MSE:0.08328159153461456  MAE:0.21798570454120636\n",
      "\n",
      "―――― Inference  |  Segment 28 ――――\n",
      "  seg28-ch0  MSE:0.0834355428814888  MAE:0.2153617888689041\n",
      "▶ seg28  mean  MSE:0.0834355428814888  MAE:0.2153617888689041\n",
      "\n",
      "―――― Inference  |  Segment 29 ――――\n",
      "  seg29-ch0  MSE:0.07288440316915512  MAE:0.2017529457807541\n",
      "▶ seg29  mean  MSE:0.07288440316915512  MAE:0.2017529457807541\n",
      "\n",
      "―――― Inference  |  Segment 30 ――――\n",
      "  seg30-ch0  MSE:0.06863348186016083  MAE:0.19437982141971588\n",
      "▶ seg30  mean  MSE:0.06863348186016083  MAE:0.19437982141971588\n",
      "\n",
      "―――― Inference  |  Segment 31 ――――\n",
      "  seg31-ch0  MSE:0.09361135959625244  MAE:0.22905664145946503\n",
      "▶ seg31  mean  MSE:0.09361135959625244  MAE:0.22905664145946503\n",
      "\n",
      "―――― Inference  |  Segment 32 ――――\n",
      "  seg32-ch0  MSE:0.07417749613523483  MAE:0.20288853347301483\n",
      "▶ seg32  mean  MSE:0.07417749613523483  MAE:0.20288853347301483\n",
      "\n",
      "―――― Inference  |  Segment 33 ――――\n",
      "  seg33-ch0  MSE:0.07522813975811005  MAE:0.20774754881858826\n",
      "▶ seg33  mean  MSE:0.07522813975811005  MAE:0.20774754881858826\n",
      "\n",
      "―――― Inference  |  Segment 34 ――――\n",
      "  seg34-ch0  MSE:0.0715043693780899  MAE:0.19971425831317902\n",
      "▶ seg34  mean  MSE:0.0715043693780899  MAE:0.19971425831317902\n",
      "\n",
      "―――― Inference  |  Segment 35 ――――\n",
      "  seg35-ch0  MSE:0.07382797449827194  MAE:0.20213031768798828\n",
      "▶ seg35  mean  MSE:0.07382797449827194  MAE:0.20213031768798828\n",
      "\n",
      "―――― Inference  |  Segment 36 ――――\n",
      "  seg36-ch0  MSE:0.07061270624399185  MAE:0.19725200533866882\n",
      "▶ seg36  mean  MSE:0.07061270624399185  MAE:0.19725200533866882\n",
      "\n",
      "―――― Inference  |  Segment 37 ――――\n",
      "  seg37-ch0  MSE:0.07446183264255524  MAE:0.2071370929479599\n",
      "▶ seg37  mean  MSE:0.07446183264255524  MAE:0.2071370929479599\n",
      "\n",
      "―――― Inference  |  Segment 38 ――――\n",
      "  seg38-ch0  MSE:0.0730312168598175  MAE:0.20054766535758972\n",
      "▶ seg38  mean  MSE:0.0730312168598175  MAE:0.20054766535758972\n",
      "\n",
      "―――― Inference  |  Segment 39 ――――\n",
      "  seg39-ch0  MSE:0.07306133955717087  MAE:0.20163583755493164\n",
      "▶ seg39  mean  MSE:0.07306133955717087  MAE:0.20163583755493164\n",
      "\n",
      "―――― Inference  |  Segment 40 ――――\n",
      "  seg40-ch0  MSE:0.07529334723949432  MAE:0.20469696819782257\n",
      "▶ seg40  mean  MSE:0.07529334723949432  MAE:0.20469696819782257\n",
      "\n",
      "―――― Inference  |  Segment 41 ――――\n",
      "  seg41-ch0  MSE:0.08868661522865295  MAE:0.22182871401309967\n",
      "▶ seg41  mean  MSE:0.08868661522865295  MAE:0.22182871401309967\n",
      "\n",
      "―――― Inference  |  Segment 42 ――――\n",
      "  seg42-ch0  MSE:0.07556827366352081  MAE:0.20381076633930206\n",
      "▶ seg42  mean  MSE:0.07556827366352081  MAE:0.20381076633930206\n",
      "\n",
      "―――― Inference  |  Segment 43 ――――\n",
      "  seg43-ch0  MSE:0.08245408535003662  MAE:0.21464326977729797\n",
      "▶ seg43  mean  MSE:0.08245408535003662  MAE:0.21464326977729797\n",
      "\n",
      "―――― Inference  |  Segment 44 ――――\n",
      "  seg44-ch0  MSE:0.09196598827838898  MAE:0.23050810396671295\n",
      "▶ seg44  mean  MSE:0.09196598827838898  MAE:0.23050810396671295\n",
      "\n",
      "―――― Inference  |  Segment 45 ――――\n",
      "  seg45-ch0  MSE:0.08268770575523376  MAE:0.22056201100349426\n",
      "▶ seg45  mean  MSE:0.08268770575523376  MAE:0.22056201100349426\n",
      "\n",
      "―――― Inference  |  Segment 46 ――――\n",
      "  seg46-ch0  MSE:0.07804441452026367  MAE:0.20801468193531036\n",
      "▶ seg46  mean  MSE:0.07804441452026367  MAE:0.20801468193531036\n",
      "\n",
      "―――― Inference  |  Segment 47 ――――\n",
      "  seg47-ch0  MSE:0.07391771674156189  MAE:0.20311525464057922\n",
      "▶ seg47  mean  MSE:0.07391771674156189  MAE:0.20311525464057922\n",
      "\n",
      "―――― Inference  |  Segment 48 ――――\n",
      "  seg48-ch0  MSE:0.0711974948644638  MAE:0.19877870380878448\n",
      "▶ seg48  mean  MSE:0.0711974948644638  MAE:0.19877870380878448\n",
      "\n",
      "―――― Inference  |  Segment 49 ――――\n",
      "  seg49-ch0  MSE:0.07774662226438522  MAE:0.20744332671165466\n",
      "▶ seg49  mean  MSE:0.07774662226438522  MAE:0.20744332671165466\n",
      "\n",
      "―――― Inference  |  Segment 50 ――――\n",
      "  seg50-ch0  MSE:0.07511480897665024  MAE:0.20373333990573883\n",
      "▶ seg50  mean  MSE:0.07511480897665024  MAE:0.20373333990573883\n",
      "\n",
      "―――― Inference  |  Segment 51 ――――\n",
      "  seg51-ch0  MSE:0.07869232445955276  MAE:0.2096521556377411\n",
      "▶ seg51  mean  MSE:0.07869232445955276  MAE:0.2096521556377411\n",
      "\n",
      "―――― Inference  |  Segment 52 ――――\n",
      "  seg52-ch0  MSE:0.07353667914867401  MAE:0.20269358158111572\n",
      "▶ seg52  mean  MSE:0.07353667914867401  MAE:0.20269358158111572\n",
      "\n",
      "―――― Inference  |  Segment 53 ――――\n",
      "  seg53-ch0  MSE:0.07002955675125122  MAE:0.19813117384910583\n",
      "▶ seg53  mean  MSE:0.07002955675125122  MAE:0.19813117384910583\n",
      "\n",
      "―――― Inference  |  Segment 54 ――――\n",
      "  seg54-ch0  MSE:0.06824854016304016  MAE:0.19532348215579987\n",
      "▶ seg54  mean  MSE:0.06824854016304016  MAE:0.19532348215579987\n",
      "\n",
      "―――― Inference  |  Segment 55 ――――\n",
      "  seg55-ch0  MSE:0.07658589631319046  MAE:0.20648804306983948\n",
      "▶ seg55  mean  MSE:0.07658589631319046  MAE:0.20648804306983948\n",
      "\n",
      "―――― Inference  |  Segment 56 ――――\n",
      "  seg56-ch0  MSE:0.07436871528625488  MAE:0.20488710701465607\n",
      "▶ seg56  mean  MSE:0.07436871528625488  MAE:0.20488710701465607\n",
      "\n",
      "―――― Inference  |  Segment 57 ――――\n",
      "  seg57-ch0  MSE:0.09146998077630997  MAE:0.23204675316810608\n",
      "▶ seg57  mean  MSE:0.09146998077630997  MAE:0.23204675316810608\n",
      "\n",
      "―――― Inference  |  Segment 58 ――――\n",
      "  seg58-ch0  MSE:0.06874538213014603  MAE:0.1958872377872467\n",
      "▶ seg58  mean  MSE:0.06874538213014603  MAE:0.1958872377872467\n",
      "\n",
      "―――― Inference  |  Segment 59 ――――\n",
      "  seg59-ch0  MSE:0.07028120756149292  MAE:0.19933485984802246\n",
      "▶ seg59  mean  MSE:0.07028120756149292  MAE:0.19933485984802246\n",
      "\n",
      "―――― Inference  |  Segment 60 ――――\n",
      "  seg60-ch0  MSE:0.07042469084262848  MAE:0.19849862158298492\n",
      "▶ seg60  mean  MSE:0.07042469084262848  MAE:0.19849862158298492\n",
      "\n",
      "―――― Inference  |  Segment 61 ――――\n",
      "  seg61-ch0  MSE:0.06942647695541382  MAE:0.19644217193126678\n",
      "▶ seg61  mean  MSE:0.06942647695541382  MAE:0.19644217193126678\n",
      "\n",
      "―――― Inference  |  Segment 62 ――――\n",
      "  seg62-ch0  MSE:0.06999065726995468  MAE:0.1958814412355423\n",
      "▶ seg62  mean  MSE:0.06999065726995468  MAE:0.1958814412355423\n",
      "\n",
      "―――― Inference  |  Segment 63 ――――\n",
      "  seg63-ch0  MSE:0.07558750361204147  MAE:0.2064417153596878\n",
      "▶ seg63  mean  MSE:0.07558750361204147  MAE:0.2064417153596878\n",
      "\n",
      "―――― Inference  |  Segment 64 ――――\n",
      "  seg64-ch0  MSE:0.07747890055179596  MAE:0.2092932164669037\n",
      "▶ seg64  mean  MSE:0.07747890055179596  MAE:0.2092932164669037\n",
      "\n",
      "seg10 ch0 MSE : 0.06806168\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import r2_score\n",
    "from pathlib import Path\n",
    "\n",
    "C        = 1                                \n",
    "P        = base_cfg.pred_len                \n",
    "seg_cnt  = 65\n",
    "batch_sz = 32\n",
    "\n",
    "results2_ETTm2_E1_test_1E = {}  \n",
    "\n",
    "for seg in range(seg_cnt):\n",
    "    print(f\"\\n―――― Inference  |  Segment {seg} ――――\")\n",
    "\n",
    "    \n",
    "    pv = test_pred_segments_E1[:, seg, :, :]         \n",
    "    ds = TensorDataset(test_sequences, test_labels, pv) \n",
    "    dl = DataLoader(ds, batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "    \n",
    "    pred_ch, true_ch, metrics = [], [], {}\n",
    "\n",
    "    \n",
    "    for ch in range(C):\n",
    "        ckpt = Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{ch}\" / \"checkpoint.pth\"\n",
    "        if not ckpt.exists():\n",
    "            print(f\"[Warn] seg{seg}-ch{ch} ckpt 없음 → skip\");  continue\n",
    "\n",
    "        \n",
    "        model = Model(base_cfg).to(device)\n",
    "        model.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        preds, trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, pv_batch in dl:                 \n",
    "                xb  = xb.float().to(device)\n",
    "                yb  = yb.float()        \n",
    "                pv_ = pv_batch.float().to(device)\n",
    "\n",
    "                out = model(xb, pv_)                     \n",
    "                preds.append(out[:, -P:, ch].cpu())\n",
    "                trues.append(yb[:, -P:, ch])\n",
    "\n",
    "        preds = torch.cat(preds, 0)     \n",
    "        trues = torch.cat(trues, 0)\n",
    "        pred_ch.append(preds)\n",
    "        true_ch.append(trues)\n",
    "\n",
    "        \n",
    "        p, t = preds.reshape(-1).cpu().numpy(), trues.reshape(-1).cpu().numpy()\n",
    "        mse  = np.mean((p - t)**2)\n",
    "        mae  = np.mean(np.abs(p - t))\n",
    "        metrics[ch] = (mse, mae)\n",
    "\n",
    "        print(f\"  seg{seg}-ch{ch}  MSE:{mse}  MAE:{mae}\")\n",
    "\n",
    "        del model; torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "    pred_all = torch.stack(pred_ch,  dim=2)   \n",
    "    true_all = torch.stack(true_ch,  dim=2)\n",
    "\n",
    "    \n",
    "    mse_avg = np.mean([m for m,_ in metrics.values()])\n",
    "    mae_avg = np.mean([a for _,a in metrics.values()])\n",
    "    print(f\"▶ seg{seg}  mean  MSE:{mse_avg}  MAE:{mae_avg}\")\n",
    "\n",
    "    \n",
    "    results2_ETTm2_E1_test_1E[seg] = {\n",
    "        \"pred2_E1_test_1E\"    : pred_all,   \n",
    "        \"true2_E1_test_1E\"    : true_all,   \n",
    "        \"metrics2_E1_test_1E\" : metrics     \n",
    "    }\n",
    "\n",
    "\n",
    "seg10_ch0_mse = results2_ETTm2_E1_test_1E[10][\"metrics2_E1_test_1E\"][0][0]\n",
    "print(\"\\nseg10 ch0 MSE :\", seg10_ch0_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64f70d6",
   "metadata": {},
   "source": [
    "# Rank Models (by 2nd validation performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f5fb163",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1_ETTm2_train = torch.load(\"./1st_results_ETTm2/train_1st_results.pt\")\n",
    "results1_ETTm2_val = torch.load(\"./1st_results_ETTm2/val_1st_results.pt\")\n",
    "results1_ETTm2_test = torch.load(\"./1st_results_ETTm2/test_1st_results.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc12945d",
   "metadata": {},
   "source": [
    "### ES->1E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fab26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Train-set  Per-Channel  Top-N  MSE\n",
      "\n",
      "=== Channel 0 ===\n",
      "Vanilla MSE : 0.095128\n",
      "\n",
      "  Top  1 | seg 20 | MSE 0.087587 (+0.007540)\n",
      "  Top  2 | seg 12 | MSE 0.087670 (+0.007457)\n",
      "  Top  3 | seg 06 | MSE 0.088287 (+0.006841)\n",
      "  Top  4 | seg 04 | MSE 0.088308 (+0.006820)\n",
      "  Top  5 | seg 11 | MSE 0.088399 (+0.006729)\n",
      "  Top  6 | seg 19 | MSE 0.088469 (+0.006659)\n",
      "  Top  7 | seg 17 | MSE 0.088555 (+0.006573)\n",
      "  Top  8 | seg 25 | MSE 0.088688 (+0.006440)\n",
      "  Top  9 | seg 08 | MSE 0.088746 (+0.006382)\n",
      "  Top 10 | seg 27 | MSE 0.088856 (+0.006271)\n",
      "  Top 11 | seg 51 | MSE 0.089026 (+0.006101)\n",
      "  Top 12 | seg 10 | MSE 0.089107 (+0.006020)\n",
      "  Top 13 | seg 22 | MSE 0.089365 (+0.005762)\n",
      "  Top 14 | seg 63 | MSE 0.090109 (+0.005019)\n",
      "  Top 15 | seg 56 | MSE 0.090111 (+0.005016)\n",
      "  Top 16 | seg 31 | MSE 0.090267 (+0.004860)\n",
      "  Top 17 | seg 00 | MSE 0.090270 (+0.004858)\n",
      "  Top 18 | seg 50 | MSE 0.090347 (+0.004781)\n",
      "  Top 19 | seg 53 | MSE 0.090461 (+0.004666)\n",
      "  Top 20 | seg 62 | MSE 0.090522 (+0.004605)\n",
      "  Top 21 | seg 13 | MSE 0.090585 (+0.004543)\n",
      "  Top 22 | seg 41 | MSE 0.090729 (+0.004398)\n",
      "  Top 23 | seg 46 | MSE 0.091075 (+0.004053)\n",
      "  Top 24 | seg 57 | MSE 0.091091 (+0.004036)\n",
      "  Top 25 | seg 18 | MSE 0.091243 (+0.003885)\n",
      "  Top 26 | seg 43 | MSE 0.091275 (+0.003852)\n",
      "  Top 27 | seg 40 | MSE 0.091360 (+0.003768)\n",
      "  Top 28 | seg 42 | MSE 0.091470 (+0.003657)\n",
      "  Top 29 | seg 45 | MSE 0.091849 (+0.003279)\n",
      "  Top 30 | seg 44 | MSE 0.091867 (+0.003260)\n",
      "  Top 31 | seg 21 | MSE 0.092169 (+0.002958)\n",
      "  Top 32 | seg 26 | MSE 0.092247 (+0.002881)\n",
      "  Top 33 | seg 24 | MSE 0.092343 (+0.002785)\n",
      "  Top 34 | seg 03 | MSE 0.092364 (+0.002763)\n",
      "  Top 35 | seg 30 | MSE 0.092478 (+0.002649)\n",
      "  Top 36 | seg 39 | MSE 0.092816 (+0.002312)\n",
      "  Top 37 | seg 61 | MSE 0.092967 (+0.002161)\n",
      "  Top 38 | seg 49 | MSE 0.093019 (+0.002109)\n",
      "  Top 39 | seg 02 | MSE 0.093037 (+0.002091)\n",
      "  Top 40 | seg 01 | MSE 0.093160 (+0.001967)\n",
      "  Top 41 | seg 09 | MSE 0.093193 (+0.001935)\n",
      "  Top 42 | seg 28 | MSE 0.093797 (+0.001331)\n",
      "  Top 43 | seg 47 | MSE 0.093984 (+0.001144)\n",
      "  Top 44 | seg 29 | MSE 0.094171 (+0.000957)\n",
      "  Top 45 | seg 60 | MSE 0.094501 (+0.000627)\n",
      "  Top 46 | seg 54 | MSE 0.094519 (+0.000609)\n",
      "  Top 47 | seg 64 | MSE 0.094637 (+0.000491)\n",
      "  Top 48 | seg 15 | MSE 0.094818 (+0.000310)\n",
      "  Top 49 | seg 34 | MSE 0.095013 (+0.000115)\n",
      "  Top 50 | seg 38 | MSE 0.095042 (+0.000086)\n",
      "  Top 51 | seg 33 | MSE 0.095104 (+0.000024)\n",
      "  Top 52 | seg 36 | MSE 0.095649 (-0.000521)\n",
      "  Top 53 | seg 48 | MSE 0.095735 (-0.000607)\n",
      "  Top 54 | seg 32 | MSE 0.095986 (-0.000858)\n",
      "  Top 55 | seg 58 | MSE 0.096047 (-0.000919)\n",
      "  Top 56 | seg 59 | MSE 0.097202 (-0.002074)\n",
      "  Top 57 | seg 35 | MSE 0.097246 (-0.002118)\n",
      "  Top 58 | seg 05 | MSE 0.097674 (-0.002546)\n",
      "  Top 59 | seg 16 | MSE 0.098010 (-0.002882)\n",
      "  Top 60 | seg 07 | MSE 0.101217 (-0.006090)\n",
      "  Top 61 | seg 23 | MSE 0.102951 (-0.007824)\n",
      "  Top 62 | seg 52 | MSE 0.103931 (-0.008803)\n",
      "  Top 63 | seg 37 | MSE 0.105699 (-0.010571)\n",
      "  Top 64 | seg 55 | MSE 0.107263 (-0.012135)\n",
      "  Top 65 | seg 14 | MSE 0.117946 (-0.022818)\n",
      "\n",
      "Saved top segment indices per channel:\n",
      "Channel 0: [20, 12, 6, 4, 11, 19, 17, 25, 8, 27, 51, 10, 22, 63, 56, 31, 0, 50, 53, 62, 13, 41, 46, 57, 18, 43, 40, 42, 45, 44, 21, 26, 24, 3, 30, 39, 61, 49, 2, 1, 9, 28, 47, 29, 60, 54, 64, 15, 34, 38, 33, 36, 48, 32, 58, 59, 35, 5, 16, 7, 23, 52, 37, 55, 14]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TOP_N       = 65\n",
    "SEG_CNT     = 65\n",
    "CH_CNT      = 1\n",
    "metric_idx  = 0          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mse_table = np.full((SEG_CNT, CH_CNT), np.inf)\n",
    "\n",
    "for seg in range(SEG_CNT):\n",
    "    if seg not in results2_ETTm2_ES_val_1E:\n",
    "        continue\n",
    "    for ch in range(CH_CNT):\n",
    "        if ch in results2_ETTm2_ES_val_1E[seg][\"metrics2_ES_val_1E\"]:\n",
    "            mse_table[seg, ch] = results2_ETTm2_ES_val_1E[seg][\"metrics2_ES_val_1E\"][ch][metric_idx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n▶ Train-set  Per-Channel  Top-N  MSE\\n\")\n",
    "top_seg_idx_ES_val_1E = {}                       \n",
    "\n",
    "for ch in range(CH_CNT):\n",
    "    print(f\"=== Channel {ch} ===\")\n",
    "    v_mse = results1_ETTm2_val[1]['mse_val_E1']\n",
    "    print(f\"Vanilla MSE : {v_mse:.6f}\\n\")\n",
    "\n",
    "    \n",
    "    pairs = [(seg, mse_table[seg, ch]) for seg in range(SEG_CNT)\n",
    "             if np.isfinite(mse_table[seg, ch])]\n",
    "    top   = sorted(pairs, key=lambda x: x[1])[:TOP_N]\n",
    "\n",
    "    \n",
    "    top_seg_idx_ES_val_1E[ch] = [seg for seg, _ in top]   \n",
    "\n",
    "    \n",
    "    for rank, (seg_id, mse_val) in enumerate(top, 1):\n",
    "        delta = v_mse - mse_val\n",
    "        sign  = \"+\" if delta > 0 else \"-\"\n",
    "        print(f\"  Top {rank:2d} | seg {seg_id:02d} | MSE {mse_val:.6f} \"\n",
    "              f\"({sign}{abs(delta):.6f})\")\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Saved top segment indices per channel:\")\n",
    "for ch, seg_list in top_seg_idx_ES_val_1E.items():\n",
    "    print(f\"Channel {ch}: {seg_list}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c555306f",
   "metadata": {},
   "source": [
    "### 1E->1E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8348f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Train-set  Per-Channel  Top-N  MSE\n",
      "\n",
      "=== Channel 0 ===\n",
      "Vanilla MSE : 0.095128\n",
      "\n",
      "  Top  1 | seg 03 | MSE 0.088684 (+0.006443)\n",
      "  Top  2 | seg 10 | MSE 0.088714 (+0.006413)\n",
      "  Top  3 | seg 15 | MSE 0.088800 (+0.006327)\n",
      "  Top  4 | seg 00 | MSE 0.088851 (+0.006276)\n",
      "  Top  5 | seg 30 | MSE 0.089132 (+0.005996)\n",
      "  Top  6 | seg 25 | MSE 0.089869 (+0.005259)\n",
      "  Top  7 | seg 60 | MSE 0.089913 (+0.005215)\n",
      "  Top  8 | seg 02 | MSE 0.090082 (+0.005046)\n",
      "  Top  9 | seg 34 | MSE 0.090172 (+0.004955)\n",
      "  Top 10 | seg 19 | MSE 0.090183 (+0.004945)\n",
      "  Top 11 | seg 35 | MSE 0.090220 (+0.004907)\n",
      "  Top 12 | seg 08 | MSE 0.090459 (+0.004669)\n",
      "  Top 13 | seg 54 | MSE 0.090584 (+0.004544)\n",
      "  Top 14 | seg 48 | MSE 0.090598 (+0.004529)\n",
      "  Top 15 | seg 17 | MSE 0.090628 (+0.004499)\n",
      "  Top 16 | seg 20 | MSE 0.090652 (+0.004475)\n",
      "  Top 17 | seg 59 | MSE 0.090729 (+0.004399)\n",
      "  Top 18 | seg 06 | MSE 0.090906 (+0.004221)\n",
      "  Top 19 | seg 36 | MSE 0.090973 (+0.004154)\n",
      "  Top 20 | seg 58 | MSE 0.090990 (+0.004138)\n",
      "  Top 21 | seg 53 | MSE 0.090992 (+0.004136)\n",
      "  Top 22 | seg 14 | MSE 0.090998 (+0.004130)\n",
      "  Top 23 | seg 09 | MSE 0.091129 (+0.003999)\n",
      "  Top 24 | seg 12 | MSE 0.091185 (+0.003942)\n",
      "  Top 25 | seg 62 | MSE 0.091390 (+0.003738)\n",
      "  Top 26 | seg 52 | MSE 0.091457 (+0.003671)\n",
      "  Top 27 | seg 50 | MSE 0.091481 (+0.003646)\n",
      "  Top 28 | seg 01 | MSE 0.091779 (+0.003349)\n",
      "  Top 29 | seg 63 | MSE 0.092328 (+0.002799)\n",
      "  Top 30 | seg 47 | MSE 0.092478 (+0.002649)\n",
      "  Top 31 | seg 61 | MSE 0.092498 (+0.002629)\n",
      "  Top 32 | seg 49 | MSE 0.092571 (+0.002557)\n",
      "  Top 33 | seg 38 | MSE 0.092694 (+0.002433)\n",
      "  Top 34 | seg 42 | MSE 0.092761 (+0.002367)\n",
      "  Top 35 | seg 29 | MSE 0.092800 (+0.002327)\n",
      "  Top 36 | seg 07 | MSE 0.092954 (+0.002173)\n",
      "  Top 37 | seg 46 | MSE 0.092994 (+0.002134)\n",
      "  Top 38 | seg 11 | MSE 0.093010 (+0.002118)\n",
      "  Top 39 | seg 55 | MSE 0.093450 (+0.001677)\n",
      "  Top 40 | seg 22 | MSE 0.093470 (+0.001658)\n",
      "  Top 41 | seg 33 | MSE 0.094168 (+0.000960)\n",
      "  Top 42 | seg 40 | MSE 0.094196 (+0.000931)\n",
      "  Top 43 | seg 37 | MSE 0.094455 (+0.000672)\n",
      "  Top 44 | seg 45 | MSE 0.094696 (+0.000431)\n",
      "  Top 45 | seg 56 | MSE 0.095410 (-0.000282)\n",
      "  Top 46 | seg 13 | MSE 0.095724 (-0.000597)\n",
      "  Top 47 | seg 26 | MSE 0.095747 (-0.000619)\n",
      "  Top 48 | seg 05 | MSE 0.096082 (-0.000954)\n",
      "  Top 49 | seg 18 | MSE 0.096184 (-0.001056)\n",
      "  Top 50 | seg 28 | MSE 0.096855 (-0.001727)\n",
      "  Top 51 | seg 51 | MSE 0.097148 (-0.002020)\n",
      "  Top 52 | seg 32 | MSE 0.097370 (-0.002243)\n",
      "  Top 53 | seg 39 | MSE 0.097538 (-0.002411)\n",
      "  Top 54 | seg 16 | MSE 0.097692 (-0.002565)\n",
      "  Top 55 | seg 04 | MSE 0.097779 (-0.002652)\n",
      "  Top 56 | seg 57 | MSE 0.099990 (-0.004863)\n",
      "  Top 57 | seg 41 | MSE 0.100638 (-0.005511)\n",
      "  Top 58 | seg 64 | MSE 0.101102 (-0.005974)\n",
      "  Top 59 | seg 24 | MSE 0.101262 (-0.006135)\n",
      "  Top 60 | seg 21 | MSE 0.101477 (-0.006349)\n",
      "  Top 61 | seg 23 | MSE 0.102099 (-0.006972)\n",
      "  Top 62 | seg 31 | MSE 0.102481 (-0.007353)\n",
      "  Top 63 | seg 43 | MSE 0.103948 (-0.008820)\n",
      "  Top 64 | seg 27 | MSE 0.104538 (-0.009411)\n",
      "  Top 65 | seg 44 | MSE 0.113486 (-0.018358)\n",
      "\n",
      "Saved top segment indices per channel:\n",
      "Channel 0: [3, 10, 15, 0, 30, 25, 60, 2, 34, 19, 35, 8, 54, 48, 17, 20, 59, 6, 36, 58, 53, 14, 9, 12, 62, 52, 50, 1, 63, 47, 61, 49, 38, 42, 29, 7, 46, 11, 55, 22, 33, 40, 37, 45, 56, 13, 26, 5, 18, 28, 51, 32, 39, 16, 4, 57, 41, 64, 24, 21, 23, 31, 43, 27, 44]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TOP_N       = 65\n",
    "SEG_CNT     = 65\n",
    "CH_CNT      = 1\n",
    "metric_idx  = 0          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mse_table = np.full((SEG_CNT, CH_CNT), np.inf)\n",
    "\n",
    "for seg in range(SEG_CNT):\n",
    "    if seg not in results2_ETTm2_E1_val_1E:\n",
    "        continue\n",
    "    for ch in range(CH_CNT):\n",
    "        if ch in results2_ETTm2_E1_val_1E[seg][\"metrics2_E1_val_1E\"]:\n",
    "            mse_table[seg, ch] = results2_ETTm2_E1_val_1E[seg][\"metrics2_E1_val_1E\"][ch][metric_idx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n▶ Train-set  Per-Channel  Top-N  MSE\\n\")\n",
    "top_seg_idx_E1_val_1E = {}                       \n",
    "\n",
    "for ch in range(CH_CNT):\n",
    "    print(f\"=== Channel {ch} ===\")\n",
    "    v_mse = results1_ETTm2_val[1]['mse_val_E1']\n",
    "    print(f\"Vanilla MSE : {v_mse:.6f}\\n\")\n",
    "\n",
    "    \n",
    "    pairs = [(seg, mse_table[seg, ch]) for seg in range(SEG_CNT)\n",
    "             if np.isfinite(mse_table[seg, ch])]\n",
    "    top   = sorted(pairs, key=lambda x: x[1])[:TOP_N]\n",
    "\n",
    "    \n",
    "    top_seg_idx_E1_val_1E[ch] = [seg for seg, _ in top]   \n",
    "\n",
    "    \n",
    "    for rank, (seg_id, mse_val) in enumerate(top, 1):\n",
    "        delta = v_mse - mse_val\n",
    "        sign  = \"+\" if delta > 0 else \"-\"\n",
    "        print(f\"  Top {rank:2d} | seg {seg_id:02d} | MSE {mse_val:.6f} \"\n",
    "              f\"({sign}{abs(delta):.6f})\")\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Saved top segment indices per channel:\")\n",
    "for ch, seg_list in top_seg_idx_E1_val_1E.items():\n",
    "    print(f\"Channel {ch}: {seg_list}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccfac3a",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de39ffb0",
   "metadata": {},
   "source": [
    "## ES->1E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354ecd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Channel 0 ===\n",
      "[Vanilla]   MSE : 0.066214 | MAE : 0.189404\n",
      "  — Var / |Corr| / Score —\n",
      "   K= 5 | Var=2.954e-03 | |ρ|=0.9928 | S=1.0000 \n",
      "   K=10 | Var=3.516e-03 | |ρ|=0.9916 | S=0.9594 \n",
      "   K=15 | Var=3.624e-03 | |ρ|=0.9911 | S=0.9223 \n",
      "   K=20 | Var=4.040e-03 | |ρ|=0.9907 | S=0.9383 \n",
      "   K=25 | Var=4.516e-03 | |ρ|=0.9904 | S=0.9868 \n",
      "   K=30 | Var=4.804e-03 | |ρ|=0.9899 | S=0.9762 \n",
      "   K=35 | Var=5.122e-03 | |ρ|=0.9894 | S=0.9732 \n",
      "   K=40 | Var=5.581e-03 | |ρ|=0.9881 | S=0.8977 \n",
      "   K=45 | Var=6.044e-03 | |ρ|=0.9875 | S=0.9090 \n",
      "   K=50 | Var=6.644e-03 | |ρ|=0.9870 | S=0.9456 \n",
      "   K=55 | Var=7.116e-03 | |ρ|=0.9861 | S=0.9217 \n",
      "   K=60 | Var=7.760e-03 | |ρ|=0.9848 | S=0.8776 <- pick\n",
      "   K=65 | Var=9.391e-03 | |ρ|=0.9836 | S=1.0000 \n",
      "[Var-Corr]  K=60\n",
      "  MSE = 0.066206 | Δ = +0.000008 | Δ% = +0.01%\n",
      "  MAE = 0.189814 | Δ = -0.000410 | Δ% = -0.22%\n",
      "\n",
      "──────── Summary (Var-Corr) ───────\n",
      "Vanilla  mean MSE : 0.066214\n",
      "Ensemble mean MSE : 0.066206\n",
      "Average Δ MSE     : +0.000008\n",
      "Average Δ MSE (%) : +0.01%\n",
      "\n",
      "Vanilla  mean MAE : 0.189404\n",
      "Ensemble mean MAE : 0.189814\n",
      "Average Δ MAE     : -0.000410\n",
      "Average Δ MAE (%) : -0.22%\n"
     ]
    }
   ],
   "source": [
    "import torch, os, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "TOP_K    = 65\n",
    "CH_CNT   = 1\n",
    "batch_sz = 32\n",
    "\n",
    "def infer_one(model, loader, ch):\n",
    "    buf = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb, pv in loader:\n",
    "            xb, pv = xb.to(device), pv.to(device)\n",
    "            buf.append(model(xb, pv)[:, :, ch].cpu())   \n",
    "    return torch.cat(buf, 0)   \n",
    "\n",
    "\n",
    "van_mse_list, ens_mse_list, delta_mse_list, delta_mse_pct_list = [], [], [], []\n",
    "van_mae_list, ens_mae_list, delta_mae_list, delta_mae_pct_list = [], [], [], []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for ch in range(CH_CNT):\n",
    "    print(f\"\\n=== Channel {ch} ===\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    v_mse = results1_ETTm2_test['ES']['mse_test_EES']\n",
    "    v_mae = results1_ETTm2_test['ES']['mae_test_EES']\n",
    "\n",
    "    print(f\"[Vanilla]   MSE : {v_mse:.6f} | MAE : {v_mae:.6f}\")\n",
    "\n",
    "    van_mse_list.append(v_mse)\n",
    "    van_mae_list.append(v_mae)\n",
    "\n",
    "    preds_test_arr = []\n",
    "    ok_segs = []\n",
    "\n",
    "    \n",
    "    for seg in top_seg_idx_ES_val_1E[ch][:TOP_K]:\n",
    "        ckpt = f\"./model2_ETTm2_EES_1E/seg{seg}/ch{ch}/checkpoint.pth\"\n",
    "        if not os.path.exists(ckpt):\n",
    "            print(f\"  [skip] ckpt missing : seg{seg}\")\n",
    "            continue\n",
    "\n",
    "        pv_seg = test_pred_segments_ES[:, seg, :, :]\n",
    "        dl     = DataLoader(TensorDataset(test_sequences, test_labels, pv_seg),\n",
    "                            batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "        mdl = Model(base_cfg).to(device)\n",
    "        mdl.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "\n",
    "        preds_test_arr.append(infer_one(mdl, dl, ch))   \n",
    "        ok_segs.append(seg)\n",
    "\n",
    "    if len(preds_test_arr) < 5:\n",
    "        print(\"  Not enough valid models.\")\n",
    "        continue\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    step = 5\n",
    "    Ks = list(range(step, len(preds_test_arr)+1, step))\n",
    "\n",
    "    var_list, rho_list = [], []\n",
    "\n",
    "    for K in Ks:\n",
    "        F = torch.stack(preds_test_arr[:K], dim=0)\n",
    "\n",
    "        V = torch.var(F, dim=0).mean().item()\n",
    "        var_list.append(V)\n",
    "\n",
    "        flat = F.reshape(K, -1).numpy()\n",
    "        corr = np.corrcoef(flat)\n",
    "        R = np.mean(np.abs(corr[np.triu_indices(K, 1)]))\n",
    "        rho_list.append(R)\n",
    "\n",
    "    \n",
    "    V_min, V_max = min(var_list), max(var_list)\n",
    "    R_min, R_max = min(rho_list), max(rho_list)\n",
    "\n",
    "    V_norm = [(v - V_min)/(V_max - V_min + 1e-12) for v in var_list]\n",
    "    R_norm = [(r - R_min)/(R_max - R_min + 1e-12) for r in rho_list]\n",
    "\n",
    "    alpha, beta = 1, 1\n",
    "    scores = [alpha*v + beta*r for v, r in zip(V_norm, R_norm)]\n",
    "\n",
    "    best_K = Ks[int(np.argmin(scores))]\n",
    "\n",
    "    print(\"  — Var / |Corr| / Score —\")\n",
    "    for k, v, r, s in zip(Ks, var_list, rho_list, scores):\n",
    "        tag = \"<- pick\" if k == best_K else \"\"\n",
    "        print(f\"   K={k:2d} | Var={v:.3e} | |ρ|={r:.4f} | S={s:.4f} {tag}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ens_pred = torch.mean(torch.stack(preds_test_arr[:best_K]), dim=0)\n",
    "    y_true   = test_labels[:, -base_cfg.pred_len:, ch].cpu()\n",
    "\n",
    "    mse_ens = torch.mean((ens_pred - y_true)**2).item()\n",
    "    mae_ens = torch.mean(torch.abs(ens_pred - y_true)).item()\n",
    "\n",
    "    ens_mse_list.append(mse_ens)\n",
    "    ens_mae_list.append(mae_ens)\n",
    "\n",
    "    \n",
    "    delta_mse = v_mse - mse_ens\n",
    "    delta_mae = v_mae - mae_ens\n",
    "\n",
    "    \n",
    "    delta_mse_pct = (delta_mse / v_mse) * 100\n",
    "    delta_mae_pct = (delta_mae / v_mae) * 100\n",
    "\n",
    "    delta_mse_list.append(delta_mse)\n",
    "    delta_mae_list.append(delta_mae)\n",
    "\n",
    "    delta_mse_pct_list.append(delta_mse_pct)\n",
    "    delta_mae_pct_list.append(delta_mae_pct)\n",
    "\n",
    "    print(f\"[Var-Corr]  K={best_K}\")\n",
    "    print(f\"  MSE = {mse_ens:.6f} | Δ = {delta_mse:+.6f} | Δ% = {delta_mse_pct:+.2f}%\")\n",
    "    print(f\"  MAE = {mae_ens:.6f} | Δ = {delta_mae:+.6f} | Δ% = {delta_mae_pct:+.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if ens_mse_list:\n",
    "    print(\"\\n──────── Summary (Var-Corr) ───────\")\n",
    "    print(f\"Vanilla  mean MSE : {np.mean(van_mse_list):.6f}\")\n",
    "    print(f\"Ensemble mean MSE : {np.mean(ens_mse_list):.6f}\")\n",
    "    print(f\"Average Δ MSE     : {np.mean(delta_mse_list):+.6f}\")\n",
    "    print(f\"Average Δ MSE (%) : {np.mean(delta_mse_pct_list):+.2f}%\\n\")\n",
    "\n",
    "    print(f\"Vanilla  mean MAE : {np.mean(van_mae_list):.6f}\")\n",
    "    print(f\"Ensemble mean MAE : {np.mean(ens_mae_list):.6f}\")\n",
    "    print(f\"Average Δ MAE     : {np.mean(delta_mae_list):+.6f}\")\n",
    "    print(f\"Average Δ MAE (%) : {np.mean(delta_mae_pct_list):+.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e06296a",
   "metadata": {},
   "source": [
    "## 1E->1E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5d94a07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18940357863903046"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1_ETTm2_test['ES']['mae_test_EES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8812ddf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Channel 0 ===\n",
      "[Vanilla]   MSE : 0.066214 | MAE : 0.189404\n",
      "  — Var / |Corr| / Score —\n",
      "   K= 5 | Var=2.427e-03 | |ρ|=0.9938 | S=1.1000 \n",
      "   K=10 | Var=2.961e-03 | |ρ|=0.9920 | S=1.0139 \n",
      "   K=15 | Var=3.326e-03 | |ρ|=0.9913 | S=1.0010 \n",
      "   K=20 | Var=3.602e-03 | |ρ|=0.9906 | S=0.9778 \n",
      "   K=25 | Var=3.900e-03 | |ρ|=0.9897 | S=0.9444 \n",
      "   K=30 | Var=4.199e-03 | |ρ|=0.9893 | S=0.9493 \n",
      "   K=35 | Var=4.558e-03 | |ρ|=0.9885 | S=0.9379 \n",
      "   K=40 | Var=4.837e-03 | |ρ|=0.9881 | S=0.9429 \n",
      "   K=45 | Var=5.290e-03 | |ρ|=0.9872 | S=0.9268 \n",
      "   K=50 | Var=5.870e-03 | |ρ|=0.9860 | S=0.9066 <- pick\n",
      "   K=55 | Var=6.522e-03 | |ρ|=0.9852 | S=0.9300 \n",
      "   K=60 | Var=7.441e-03 | |ρ|=0.9837 | S=0.9408 \n",
      "   K=65 | Var=8.785e-03 | |ρ|=0.9821 | S=1.0000 \n",
      "[Var-Corr]  K=50\n",
      "   MSE = 0.067356 | Δ = -0.001142 | Δ% = -1.72%\n",
      "   MAE = 0.191693 | Δ = -0.002289 | Δ% = -1.21%\n",
      "\n",
      "──────── Summary (Var-Corr) ───────\n",
      "Vanilla  mean MSE  : 0.066214\n",
      "Ensemble mean MSE  : 0.067356\n",
      "Average Δ MSE      : -0.001142\n",
      "Average Δ MSE (%)  : -1.72%\n",
      "\n",
      "Vanilla  mean MAE  : 0.189404\n",
      "Ensemble mean MAE  : 0.191693\n",
      "Average Δ MAE      : -0.002289\n",
      "Average Δ MAE (%)  : -1.21%\n"
     ]
    }
   ],
   "source": [
    "import torch, os, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "TOP_K    = 65\n",
    "CH_CNT   = 1\n",
    "batch_sz = 32\n",
    "\n",
    "def infer_one(model, loader, ch):\n",
    "    buf = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb, pv in loader:\n",
    "            xb, pv = xb.to(device), pv.to(device)\n",
    "            buf.append(model(xb, pv)[:, :, ch].cpu())   \n",
    "    return torch.cat(buf, 0)    \n",
    "\n",
    "\n",
    "\n",
    "van_mse_list, ens_mse_list, delta_mse_list, delta_mse_pct_list = [], [], [], []\n",
    "van_mae_list, ens_mae_list, delta_mae_list, delta_mae_pct_list = [], [], [], []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for ch in range(CH_CNT):\n",
    "\n",
    "    print(f\"\\n=== Channel {ch} ===\")\n",
    "\n",
    "    \n",
    "    v_mse = results1_ETTm2_test['ES']['mse_test_EES']\n",
    "    v_mae = results1_ETTm2_test['ES']['mae_test_EES']\n",
    "\n",
    "    print(f\"[Vanilla]   MSE : {v_mse:.6f} | MAE : {v_mae:.6f}\")\n",
    "\n",
    "    van_mse_list.append(v_mse)\n",
    "    van_mae_list.append(v_mae)\n",
    "\n",
    "    preds_test_arr = []\n",
    "    ok_segs = []\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    for seg in top_seg_idx_E1_val_1E[ch][:TOP_K]:\n",
    "\n",
    "        ckpt = f\"./model2_ETTm2_E1_1E/seg{seg}/ch{ch}/checkpoint.pth\"\n",
    "        if not os.path.exists(ckpt):\n",
    "            print(f\"  [skip] missing checkpoint : seg{seg}\")\n",
    "            continue\n",
    "\n",
    "        mdl = Model(base_cfg).to(device)\n",
    "        mdl.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "\n",
    "        pv_seg = test_pred_segments_E1[:, seg, :, :]\n",
    "        dl = DataLoader(\n",
    "            TensorDataset(test_sequences, test_labels, pv_seg),\n",
    "            batch_size=batch_sz, shuffle=False\n",
    "        )\n",
    "\n",
    "        preds_test_arr.append(infer_one(mdl, dl, ch))\n",
    "        ok_segs.append(seg)\n",
    "\n",
    "    if len(preds_test_arr) < 5:\n",
    "        print(\"  Not enough valid models.\")\n",
    "        continue\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    step = 5\n",
    "    Ks = list(range(step, len(preds_test_arr)+1, step))\n",
    "\n",
    "    var_list = []\n",
    "    rho_list = []\n",
    "\n",
    "    for K in Ks:\n",
    "        F = torch.stack(preds_test_arr[:K], dim=0)   \n",
    "\n",
    "        \n",
    "        V = torch.var(F, dim=0).mean().item()\n",
    "        var_list.append(V)\n",
    "\n",
    "        \n",
    "        flat = F.reshape(K, -1).numpy()\n",
    "        corr = np.corrcoef(flat)\n",
    "        R    = np.mean(np.abs(corr[np.triu_indices(K, 1)]))\n",
    "        rho_list.append(R)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    V_min, V_max = min(var_list), max(var_list)\n",
    "    R_min, R_max = min(rho_list), max(rho_list)\n",
    "\n",
    "    V_norm = [(v - V_min) / (V_max - V_min + 1e-12) for v in var_list]\n",
    "    R_norm = [(r - R_min) / (R_max - R_min + 1e-12) for r in rho_list]\n",
    "\n",
    "    alpha, beta = 1, 1.1   \n",
    "\n",
    "    scores = [alpha*v + beta*r for v, r in zip(V_norm, R_norm)]\n",
    "    best_K = Ks[int(np.argmin(scores))]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"  — Var / |Corr| / Score —\")\n",
    "    for k, v, r, s in zip(Ks, var_list, rho_list, scores):\n",
    "        tag = \"<- pick\" if k == best_K else \"\"\n",
    "        print(f\"   K={k:2d} | Var={v:.3e} | |ρ|={r:.4f} | S={s:.4f} {tag}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ens_pred = torch.mean(torch.stack(preds_test_arr[:best_K]), dim=0)  \n",
    "    y_true   = test_labels[:, -base_cfg.pred_len:, ch].cpu()\n",
    "\n",
    "    mse_ens = torch.mean((ens_pred - y_true)**2).item()\n",
    "    mae_ens = torch.mean(torch.abs(ens_pred - y_true)).item()\n",
    "\n",
    "    ens_mse_list.append(mse_ens)\n",
    "    ens_mae_list.append(mae_ens)\n",
    "\n",
    "    \n",
    "    delta_mse = v_mse - mse_ens\n",
    "    delta_mae = v_mae - mae_ens\n",
    "\n",
    "    \n",
    "    delta_mse_pct = (delta_mse / v_mse) * 100\n",
    "    delta_mae_pct = (delta_mae / v_mae) * 100\n",
    "\n",
    "    delta_mse_list.append(delta_mse)\n",
    "    delta_mae_list.append(delta_mae)\n",
    "    delta_mse_pct_list.append(delta_mse_pct)\n",
    "    delta_mae_pct_list.append(delta_mae_pct)\n",
    "\n",
    "    sign = \"+\" if delta_mse > 0 else \"-\"\n",
    "    print(f\"[Var-Corr]  K={best_K}\")\n",
    "    print(f\"   MSE = {mse_ens:.6f} | Δ = {delta_mse:+.6f} | Δ% = {delta_mse_pct:+.2f}%\")\n",
    "    print(f\"   MAE = {mae_ens:.6f} | Δ = {delta_mae:+.6f} | Δ% = {delta_mae_pct:+.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if ens_mse_list:\n",
    "    print(\"\\n──────── Summary (Var-Corr) ───────\")\n",
    "    print(f\"Vanilla  mean MSE  : {np.mean(van_mse_list):.6f}\")\n",
    "    print(f\"Ensemble mean MSE  : {np.mean(ens_mse_list):.6f}\")\n",
    "    print(f\"Average Δ MSE      : {np.mean(delta_mse_list):+.6f}\")\n",
    "    print(f\"Average Δ MSE (%)  : {np.mean(delta_mse_pct_list):+.2f}%\\n\")\n",
    "\n",
    "    print(f\"Vanilla  mean MAE  : {np.mean(van_mae_list):.6f}\")\n",
    "    print(f\"Ensemble mean MAE  : {np.mean(ens_mae_list):.6f}\")\n",
    "    print(f\"Average Δ MAE      : {np.mean(delta_mae_list):+.6f}\")\n",
    "    print(f\"Average Δ MAE (%)  : {np.mean(delta_mae_pct_list):+.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6309ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9afc40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc34a6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a6af78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sunho_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
