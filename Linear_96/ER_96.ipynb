{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f069f348",
   "metadata": {},
   "source": [
    "# Environment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00f9270d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "38ee0f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of GPU: 4\n",
      "Total GPU memory: 51.033931776 GB\n",
      "GPU ID: 0\n",
      "GPU Name: NVIDIA RTX A6000\n",
      "GPU Compute Capability: (8, 6)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_id = torch.cuda.current_device()\n",
    "    gpu_name = torch.cuda.get_device_name(gpu_id)\n",
    "    gpu_capability = torch.cuda.get_device_capability(gpu_id)\n",
    "    total_memory = torch.cuda.get_device_properties(gpu_id).total_memory\n",
    "    \n",
    "    print(f\"Total number of GPU: {torch.cuda.device_count()}\")  # Number of GPUs available\n",
    "    print(f\"Total GPU memory: {total_memory / 1e9} GB\")\n",
    "    print(f\"GPU ID: {gpu_id}\")\n",
    "    print(f\"GPU Name: {gpu_name}\")\n",
    "    print(f\"GPU Compute Capability: {gpu_capability}\")\n",
    "else:\n",
    "    print(\"No GPU is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a2bacc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device: 0\n",
      "Device Name: NVIDIA RTX A6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 강제로 CUDA 디바이스 설정\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# 확인\n",
    "print(\"Current Device:\", torch.cuda.current_device())\n",
    "print(\"Device Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e651b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2223b08",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df722425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "145148d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../dataset/exchange_rate.csv', index_col='date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a6953b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>OT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-01</th>\n",
       "      <td>0.7855</td>\n",
       "      <td>1.6110</td>\n",
       "      <td>0.861698</td>\n",
       "      <td>0.634196</td>\n",
       "      <td>0.211242</td>\n",
       "      <td>0.006838</td>\n",
       "      <td>0.525486</td>\n",
       "      <td>0.5930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-02</th>\n",
       "      <td>0.7818</td>\n",
       "      <td>1.6100</td>\n",
       "      <td>0.861104</td>\n",
       "      <td>0.633513</td>\n",
       "      <td>0.211242</td>\n",
       "      <td>0.006863</td>\n",
       "      <td>0.523972</td>\n",
       "      <td>0.5940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-03</th>\n",
       "      <td>0.7867</td>\n",
       "      <td>1.6293</td>\n",
       "      <td>0.861030</td>\n",
       "      <td>0.648508</td>\n",
       "      <td>0.211242</td>\n",
       "      <td>0.006975</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.5973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-04</th>\n",
       "      <td>0.7860</td>\n",
       "      <td>1.6370</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.650618</td>\n",
       "      <td>0.211242</td>\n",
       "      <td>0.006953</td>\n",
       "      <td>0.523834</td>\n",
       "      <td>0.5970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-05</th>\n",
       "      <td>0.7849</td>\n",
       "      <td>1.6530</td>\n",
       "      <td>0.861995</td>\n",
       "      <td>0.656254</td>\n",
       "      <td>0.211242</td>\n",
       "      <td>0.006940</td>\n",
       "      <td>0.527426</td>\n",
       "      <td>0.5985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0       1         2         3         4         5         6  \\\n",
       "date                                                                           \n",
       "1990-01-01  0.7855  1.6110  0.861698  0.634196  0.211242  0.006838  0.525486   \n",
       "1990-01-02  0.7818  1.6100  0.861104  0.633513  0.211242  0.006863  0.523972   \n",
       "1990-01-03  0.7867  1.6293  0.861030  0.648508  0.211242  0.006975  0.526316   \n",
       "1990-01-04  0.7860  1.6370  0.862069  0.650618  0.211242  0.006953  0.523834   \n",
       "1990-01-05  0.7849  1.6530  0.861995  0.656254  0.211242  0.006940  0.527426   \n",
       "\n",
       "                OT  \n",
       "date                \n",
       "1990-01-01  0.5930  \n",
       "1990-01-02  0.5940  \n",
       "1990-01-03  0.5973  \n",
       "1990-01-04  0.5970  \n",
       "1990-01-05  0.5985  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5cd787b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "OT    float64\n",
      "dtype: object\n",
      "shape:  (7588, 8)\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes)\n",
    "print('shape: ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0107b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['OT']\n",
    "features = data.drop(['OT'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d2a39d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['DATE'] = features.index.strftime('%Y%m%d%H').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31cb65a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1990-01-01', '1990-01-02', '1990-01-03', '1990-01-04',\n",
       "               '1990-01-05', '1990-01-06', '1990-01-07', '1990-01-08',\n",
       "               '1990-01-09', '1990-01-10',\n",
       "               ...\n",
       "               '2010-10-01', '2010-10-02', '2010-10-03', '2010-10-04',\n",
       "               '2010-10-05', '2010-10-06', '2010-10-07', '2010-10-08',\n",
       "               '2010-10-09', '2010-10-10'],\n",
       "              dtype='datetime64[ns]', name='date', length=7588, freq=None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2195d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)                           # Python random\n",
    "    np.random.seed(seed)                        # NumPy\n",
    "    torch.manual_seed(seed)                     # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)                # PyTorch GPU (single)\n",
    "    torch.cuda.manual_seed_all(seed)            # PyTorch GPU (multi)\n",
    "    torch.backends.cudnn.deterministic = True   # 연산 순서 고정\n",
    "    torch.backends.cudnn.benchmark = False      # 성능 대신 일관성 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "51f47c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(24) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71abe0c3",
   "metadata": {},
   "source": [
    "# Model Modification for Linear (Look-ahead Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "76a0ec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Linear model with prediction-based augmentation (attach_pv)\n",
    "    \"\"\"\n",
    "    def __init__(self, configs):\n",
    "        super(Model, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.channels = configs.enc_in\n",
    "\n",
    "        # --- 새 옵션: attach_pv ---\n",
    "        self.attach_pv = getattr(configs, \"attach_pv\", False)\n",
    "\n",
    "        # 추가 시퀀스 길이 = pred_len // 3 (DLinear 개선 버전과 동일)\n",
    "        self.extra_len = self.pred_len // 3\n",
    "\n",
    "        # augmented seq_len = 기본 seq_len + extra_len (if attach_pv)\n",
    "        self.seq_len_aug = self.seq_len + (self.extra_len if self.attach_pv else 0)\n",
    "\n",
    "        self.individual = configs.individual\n",
    "\n",
    "        # ----- Linear layer(s) -----\n",
    "        if self.individual:\n",
    "            self.Linear = nn.ModuleList()\n",
    "            for i in range(self.channels):\n",
    "                self.Linear.append(nn.Linear(self.seq_len_aug, self.pred_len))\n",
    "        else:\n",
    "            self.Linear = nn.Linear(self.seq_len_aug, self.pred_len)\n",
    "\n",
    "\n",
    "    def forward(self, x, ground_truth=None):\n",
    "        \"\"\"\n",
    "        x: [B, L, C]\n",
    "        ground_truth: [B, L_gt, C] or None\n",
    "        \"\"\"\n",
    "        B, L, C = x.size()\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 1) 예측값 기반 증강: attach_pv = True & ground_truth 제공\n",
    "        # --------------------------------------------------\n",
    "        if self.attach_pv and (ground_truth is not None):\n",
    "            # ground truth의 앞 extra_len 만큼만 사용 (DLinear 개선 버전과 동일)\n",
    "            gt_part = ground_truth[:, :self.extra_len, :]  # [B, extra_len, C]\n",
    "\n",
    "            # concat → [B, L + extra_len, C]\n",
    "            x = torch.cat([x, gt_part], dim=1)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 2) Linear projection (기존 Linear.py 구조 동일)\n",
    "        # --------------------------------------------------\n",
    "        if self.individual:\n",
    "            out = torch.zeros([B, self.pred_len, C], dtype=x.dtype).to(x.device)\n",
    "            for i in range(C):\n",
    "                out[:, :, i] = self.Linear[i](x[:, :, i])\n",
    "            return out\n",
    "\n",
    "        else:\n",
    "            # shared linear: (B, C, L_aug) → Linear → (B, C, pred_len)\n",
    "            out = self.Linear(x.permute(0, 2, 1))\n",
    "            return out.permute(0, 2, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8999e6bc",
   "metadata": {},
   "source": [
    "# Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "de9744c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sequences: torch.Size([4880, 336, 1])\n",
      "Train Labels:    torch.Size([4880, 96, 1])\n",
      "Val Sequences:   torch.Size([665, 336, 1])\n",
      "Val Labels:      torch.Size([665, 96, 1])\n",
      "Test Sequences:  torch.Size([1422, 336, 1])\n",
      "Test Labels:     torch.Size([1422, 96, 1])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 0. 데이터 불러오기\n",
    "target = data['OT'].values.reshape(-1, 1)  # 단변량 시계열\n",
    "\n",
    "# 1. 입력/출력 길이 정의\n",
    "seq_len  = 336\n",
    "pred_len = 96\n",
    "\n",
    "# 2. 비율 기반 분할 (Dataset_Custom 기준)\n",
    "total_len  = len(target)\n",
    "num_train  = int(total_len * 0.7)\n",
    "num_test   = int(total_len * 0.2)\n",
    "num_val    = total_len - num_train - num_test\n",
    "\n",
    "border1s = [\n",
    "    0,\n",
    "    num_train - seq_len,\n",
    "    total_len - num_test - seq_len\n",
    "]\n",
    "border2s = [\n",
    "    num_train,\n",
    "    num_train + num_val,\n",
    "    total_len\n",
    "]\n",
    "\n",
    "# 3. 구간 나누기\n",
    "train = target[border1s[0]:border2s[0]]\n",
    "val   = target[border1s[1]:border2s[1]]\n",
    "test  = target[border1s[2]:border2s[2]]\n",
    "\n",
    "# 4. 표준화 (train 기준)\n",
    "scaler = StandardScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "val   = scaler.transform(val)\n",
    "test  = scaler.transform(test)\n",
    "\n",
    "# 5. 시퀀스 생성 함수 (단변량)\n",
    "def create_inout_sequences_univariate(data, seq_len, pred_len):\n",
    "    seqs = []\n",
    "    for i in range(len(data) - seq_len - pred_len + 1):\n",
    "        seq_x = data[i : i + seq_len]\n",
    "        seq_y = data[i + seq_len : i + seq_len + pred_len]\n",
    "        seqs.append((seq_x, seq_y))\n",
    "    return seqs\n",
    "\n",
    "train_data = create_inout_sequences_univariate(train, seq_len, pred_len)\n",
    "val_data   = create_inout_sequences_univariate(val,   seq_len, pred_len)\n",
    "test_data  = create_inout_sequences_univariate(test,  seq_len, pred_len)\n",
    "\n",
    "# 6. 텐서 변환\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_sequences = torch.tensor([x[0] for x in train_data]).float().to(device)\n",
    "train_labels    = torch.tensor([x[1] for x in train_data]).float().to(device)\n",
    "\n",
    "val_sequences   = torch.tensor([x[0] for x in val_data]).float().to(device)\n",
    "val_labels      = torch.tensor([x[1] for x in val_data]).float().to(device)\n",
    "\n",
    "test_sequences  = torch.tensor([x[0] for x in test_data]).float().to(device)\n",
    "test_labels     = torch.tensor([x[1] for x in test_data]).float().to(device)\n",
    "\n",
    "# 7. 확인\n",
    "print(\"Train Sequences:\", train_sequences.shape)\n",
    "print(\"Train Labels:   \", train_labels.shape)\n",
    "print(\"Val Sequences:  \", val_sequences.shape)\n",
    "print(\"Val Labels:     \", val_labels.shape)\n",
    "print(\"Test Sequences: \", test_sequences.shape)\n",
    "print(\"Test Labels:    \", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7ed4af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 설정\n",
    "batch_size = 8\n",
    "\n",
    "# Train DataLoader\n",
    "train_dataset = TensorDataset(train_sequences, train_labels)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Validation DataLoader\n",
    "val_dataset = TensorDataset(val_sequences, val_labels)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Test DataLoader\n",
    "test_dataset = TensorDataset(test_sequences, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cf6f31",
   "metadata": {},
   "source": [
    "# 1st Model Training (Early Stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "156855c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "81b063e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating learning rate to 0.001\n",
      "Epoch 0 | Train Loss: 0.15261425166772527 | Val Loss: 0.3597180667732443\n",
      "Validation loss decreased (inf --> 0.359718).  Saving model ...\n",
      "Updating learning rate to 0.0005\n",
      "Epoch 1 | Train Loss: 0.11488621577193014 | Val Loss: 0.2180175588776668\n",
      "Validation loss decreased (0.359718 --> 0.218018).  Saving model ...\n",
      "Updating learning rate to 0.00025\n",
      "Epoch 2 | Train Loss: 0.11183011307854389 | Val Loss: 0.3296408844845636\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.000125\n",
      "Epoch 3 | Train Loss: 0.1080545814830016 | Val Loss: 0.3142980486598043\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-05\n",
      "Epoch 4 | Train Loss: 0.10638638578477454 | Val Loss: 0.2644095815984266\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "# Assuming that data is already scaled before being passed to the DataLoader\n",
    "seq_len = 336\n",
    "pred_len = 96  # Set pred_len to the desired prediction horizon\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual, learning_rate, lradj, patience, save_path, attach_pv):\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len  # Set pred_len appropriately\n",
    "        self.enc_in = enc_in\n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv = attach_pv\n",
    "\n",
    "configs = Configs(seq_len=seq_len, pred_len=pred_len, enc_in=1, individual=False,\n",
    "                   learning_rate=0.0005, lradj='type1',  patience=3, save_path=\"./model_ER\", attach_pv=False) # 원하는 값으로 설정\n",
    "\n",
    "\n",
    "model = Model(configs).to(device)\n",
    "loss_function = nn.MSELoss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=configs.learning_rate)\n",
    "\n",
    "if not os.path.exists(configs.save_path):\n",
    "    os.makedirs(configs.save_path)\n",
    "\n",
    "# EarlyStopping 클래스 정의\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model, path):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, path):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), os.path.join(path, 'checkpoint_ES.pth'))\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "\n",
    "\n",
    "# Dynamic learning rate adjustment function\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    if args.lradj == 'type1':\n",
    "        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "    elif args.lradj == 'type2':\n",
    "        lr_adjust = {\n",
    "            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "            10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "        }\n",
    "    elif args.lradj == '3':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 10 else args.learning_rate*0.1}\n",
    "    elif args.lradj == '4':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 15 else args.learning_rate*0.1}\n",
    "    elif args.lradj == '5':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 25 else args.learning_rate*0.1}\n",
    "    elif args.lradj == '6':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 5 else args.learning_rate*0.1}  \n",
    "\n",
    "    if epoch in lr_adjust.keys():\n",
    "        lr = lr_adjust[epoch]\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        print(f'Updating learning rate to {lr}')\n",
    "\n",
    "\n",
    "# Training loop using DataLoader\n",
    "def train_model(model, dataloader, val_dataloader, optimizer, loss_function, epochs, pred_len, args):\n",
    "    early_stopping = EarlyStopping(patience=args.patience, verbose=True)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        # Adjust learning rate\n",
    "        adjust_learning_rate(optimizer, epoch, args)\n",
    "        \n",
    "        for batch_sequences, batch_labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(batch_sequences)\n",
    "            \n",
    "            # Focus on the prediction horizon for loss calculation\n",
    "            # Ensure output and batch_labels have the same length (pred_len)\n",
    "            output = output[:, -pred_len:, :]  # Slice to only use the prediction length\n",
    "            batch_labels = batch_labels[:, -pred_len:, :]  # Adjust labels to match\n",
    "            \n",
    "            # Ensure shapes match before calculating loss\n",
    "            assert output.shape == batch_labels.shape, f\"Output shape {output.shape} and batch_labels shape {batch_labels.shape} must match\"\n",
    "            \n",
    "            loss = loss_function(output, batch_labels)  # Compute loss\n",
    "            \n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Validation step\n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_batch_sequences, val_batch_labels in val_dataloader:\n",
    "                val_output = model(val_batch_sequences)\n",
    "                val_output = val_output[:, -args.pred_len:, :]\n",
    "                val_batch_labels = val_batch_labels[:, -args.pred_len:, :]\n",
    "                \n",
    "                val_loss += loss_function(val_output, val_batch_labels).item()\n",
    "        \n",
    "        val_loss /= len(val_dataloader)\n",
    "\n",
    "        # Log epoch loss\n",
    "        print(f'Epoch {epoch} | Train Loss: {total_loss / len(dataloader)} | Val Loss: {val_loss}')\n",
    "        \n",
    "        # Early Stopping check\n",
    "        early_stopping(val_loss, model, args.save_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered. Stopping training.\")\n",
    "            break\n",
    "\n",
    "# Run training\n",
    "train_model(model, train_dataloader, val_dataloader, optimizer, loss_function, epochs=10, pred_len=configs.pred_len, args=configs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385a9e49",
   "metadata": {},
   "source": [
    "# 1st Model Training (1 Epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3e8bd238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating learning rate to 0.001\n",
      "Epoch 0 | Train Loss: 0.15705875295718186 | Val Loss: 0.21789498651577605\n",
      "Model saved at epoch 1\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "\n",
    "# Assuming that data is already scaled before being passed to the DataLoader\n",
    "seq_len = 336\n",
    "pred_len = 96  # Set pred_len to the desired prediction horizon\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual, learning_rate, lradj, patience, save_path, attach_pv):\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len  # Set pred_len appropriately\n",
    "        self.enc_in = enc_in\n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv = attach_pv\n",
    "\n",
    "configs = Configs(seq_len=seq_len, pred_len=pred_len, enc_in=1, individual=False,\n",
    "                   learning_rate=0.0005, lradj='type1',  patience=3, save_path=\"./model_ER\", attach_pv=False) # 원하는 값으로 설정\n",
    "\n",
    "\n",
    "model = Model(configs).to(device)\n",
    "loss_function = nn.MSELoss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=configs.learning_rate)\n",
    "\n",
    "if not os.path.exists(configs.save_path):\n",
    "    os.makedirs(configs.save_path)\n",
    "\n",
    "# Dynamic learning rate adjustment function\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    if args.lradj == 'type1':\n",
    "        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "    elif args.lradj == 'type2':\n",
    "        lr_adjust = {\n",
    "            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "            10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "        }\n",
    "    elif args.lradj == '3':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 10 else args.learning_rate*0.1}\n",
    "    elif args.lradj == '4':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 15 else args.learning_rate*0.1}\n",
    "    elif args.lradj == '5':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 25 else args.learning_rate*0.1}\n",
    "    elif args.lradj == '6':\n",
    "        lr_adjust = {epoch: args.learning_rate if epoch < 5 else args.learning_rate*0.1}  \n",
    "\n",
    "    if epoch in lr_adjust.keys():\n",
    "        lr = lr_adjust[epoch]\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        print(f'Updating learning rate to {lr}')\n",
    "\n",
    "\n",
    "# Training loop using DataLoader\n",
    "def train_model(model, dataloader, val_dataloader, optimizer, loss_function, epochs, pred_len, args):\n",
    "    # early_stopping = EarlyStopping(patience=args.patience, verbose=True)\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        if epoch == 1:\n",
    "            torch.save(model.state_dict(), os.path.join(args.save_path, 'checkpoint_1.pth'))\n",
    "            print(\"Model saved at epoch 1\")\n",
    "\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        # Adjust learning rate\n",
    "        adjust_learning_rate(optimizer, epoch, args)\n",
    "        \n",
    "        for batch_sequences, batch_labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(batch_sequences)\n",
    "            \n",
    "            # Focus on the prediction horizon for loss calculation\n",
    "            # Ensure output and batch_labels have the same length (pred_len)\n",
    "            output = output[:, -pred_len:, :]  # Slice to only use the prediction length\n",
    "            batch_labels = batch_labels[:, -pred_len:, :]  # Adjust labels to match\n",
    "            \n",
    "            # Ensure shapes match before calculating loss\n",
    "            assert output.shape == batch_labels.shape, f\"Output shape {output.shape} and batch_labels shape {batch_labels.shape} must match\"\n",
    "            \n",
    "            loss = loss_function(output, batch_labels)  # Compute loss\n",
    "            \n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Validation step\n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_batch_sequences, val_batch_labels in val_dataloader:\n",
    "                val_output = model(val_batch_sequences)\n",
    "                val_output = val_output[:, -args.pred_len:, :]\n",
    "                val_batch_labels = val_batch_labels[:, -args.pred_len:, :]\n",
    "                \n",
    "                val_loss += loss_function(val_output, val_batch_labels).item()\n",
    "        \n",
    "        val_loss /= len(val_dataloader)\n",
    "\n",
    "        # Log epoch loss\n",
    "        print(f'Epoch {epoch} | Train Loss: {total_loss / len(dataloader)} | Val Loss: {val_loss}')\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(args.save_path, f'checkpoint_{epochs}.pth'))\n",
    "    print(f\"Model saved at epoch {epochs}\")\n",
    "        \n",
    "        # # Early Stopping check\n",
    "        # early_stopping(val_loss, model, args.save_path)\n",
    "        # if early_stopping.early_stop:\n",
    "        #     print(\"Early stopping triggered. Stopping training.\")\n",
    "        #     break\n",
    "\n",
    "# Run training\n",
    "train_model(model, train_dataloader, val_dataloader, optimizer, loss_function, epochs=1, pred_len=configs.pred_len, args=configs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab25061d",
   "metadata": {},
   "source": [
    "# Perform Inference and Form Predicted Value (PV) Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b411dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Predicting with model from epoch ES]\n",
      "Epoch ES | MSE: 0.11179079860448837 | MAE: 0.2555276155471802\n",
      "\n",
      "[Predicting with model from epoch 1]\n",
      "Epoch 1 | MSE: 0.12221892178058624 | MAE: 0.26797738671302795\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "\n",
    "# 모델 체크포인트가 저장된 epoch 리스트\n",
    "checkpoint_epochs = ['ES', 1]\n",
    "\n",
    "# 결과 저장용 딕셔너리\n",
    "test_1st_results = {}\n",
    "\n",
    "for ckpt_epoch in checkpoint_epochs:\n",
    "    print(f'\\n[Predicting with model from epoch {ckpt_epoch}]')\n",
    "\n",
    "    # 모델 불러오기\n",
    "    model_path = os.path.join(configs.save_path, f'checkpoint_{ckpt_epoch}.pth')\n",
    "    \n",
    "    model = Model(configs).to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_sequence, batch_label in test_dataloader:\n",
    "            batch_sequence = batch_sequence.float().to(device)\n",
    "            batch_label = batch_label.float().to(device)\n",
    "\n",
    "            output = model(batch_sequence)\n",
    "            output = output[:, -configs.pred_len:, :]\n",
    "            batch_label = batch_label[:, -configs.pred_len:, :]\n",
    "\n",
    "            predictions.append(output.detach().cpu().numpy())\n",
    "            actuals.append(batch_label.detach().cpu().numpy())\n",
    "\n",
    "    # 배치 전체 결합\n",
    "    predictions = np.concatenate(predictions, axis=0)  # shape: (N, pred_len, 1)\n",
    "    actuals = np.concatenate(actuals, axis=0)\n",
    "\n",
    "    # 플랫화\n",
    "    predictions_flatten = predictions.flatten()\n",
    "    actuals_flatten = actuals.flatten()\n",
    "\n",
    "    # 지표 계산\n",
    "    mse = mean_squared_error(actuals_flatten, predictions_flatten)\n",
    "    mae = mean_absolute_error(actuals_flatten, predictions_flatten)\n",
    "\n",
    "    print(f'Epoch {ckpt_epoch} | MSE: {mse} | MAE: {mae}')\n",
    "\n",
    "    # test prediction을 torch.tensor로 변환해서 저장\n",
    "    num_samples = len(predictions_flatten) // configs.pred_len\n",
    "    test_pv = torch.tensor(\n",
    "        predictions_flatten.reshape(num_samples, configs.pred_len, 1),\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    # 딕셔너리에 저장\n",
    "    test_1st_results[ckpt_epoch] = {\n",
    "        f'mse_test_E{ckpt_epoch}': mse,\n",
    "        f'mae_test_E{ckpt_epoch}': mae,\n",
    "        f'test_pv_E{ckpt_epoch}': test_pv\n",
    "    }\n",
    "\n",
    "# 필요 시 전체 결과를 저장하거나 후처리 가능\n",
    "# 예: torch.save(all_results, 'all_model_predictions.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24967302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ES', 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1st_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca78013d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Predicting with model from epoch ES]\n",
      "Epoch ES | MSE: 0.21841749548912048 | MAE: 0.36545875668525696\n",
      "\n",
      "[Predicting with model from epoch 1]\n",
      "Epoch 1 | MSE: 0.217507466673851 | MAE: 0.36675718426704407\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "\n",
    "# 모델 체크포인트가 저장된 epoch 리스트\n",
    "checkpoint_epochs = ['ES', 1]\n",
    "\n",
    "# 결과 저장용 딕셔너리\n",
    "val_1st_results = {}\n",
    "\n",
    "for ckpt_epoch in checkpoint_epochs:\n",
    "    print(f'\\n[Predicting with model from epoch {ckpt_epoch}]')\n",
    "\n",
    "    # 모델 불러오기\n",
    "    model_path = os.path.join(configs.save_path, f'checkpoint_{ckpt_epoch}.pth')\n",
    "    \n",
    "    model = Model(configs).to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_sequence, batch_label in val_dataloader:\n",
    "            batch_sequence = batch_sequence.float().to(device)\n",
    "            batch_label = batch_label.float().to(device)\n",
    "\n",
    "            output = model(batch_sequence)\n",
    "            output = output[:, -configs.pred_len:, :]\n",
    "            batch_label = batch_label[:, -configs.pred_len:, :]\n",
    "\n",
    "            predictions.append(output.detach().cpu().numpy())\n",
    "            actuals.append(batch_label.detach().cpu().numpy())\n",
    "\n",
    "    # 배치 전체 결합\n",
    "    predictions = np.concatenate(predictions, axis=0)  # shape: (N, pred_len, 1)\n",
    "    actuals = np.concatenate(actuals, axis=0)\n",
    "\n",
    "    # 플랫화\n",
    "    predictions_flatten = predictions.flatten()\n",
    "    actuals_flatten = actuals.flatten()\n",
    "\n",
    "    # 지표 계산\n",
    "    mse = mean_squared_error(actuals_flatten, predictions_flatten)\n",
    "    mae = mean_absolute_error(actuals_flatten, predictions_flatten)\n",
    "\n",
    "    print(f'Epoch {ckpt_epoch} | MSE: {mse} | MAE: {mae}')\n",
    "\n",
    "    # test prediction을 torch.tensor로 변환해서 저장\n",
    "    num_samples = len(predictions_flatten) // configs.pred_len\n",
    "    val_pv = torch.tensor(\n",
    "        predictions_flatten.reshape(num_samples, configs.pred_len, 1),\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    # 딕셔너리에 저장\n",
    "    val_1st_results[ckpt_epoch] = {\n",
    "        f'mse_val_E{ckpt_epoch}': mse,\n",
    "        f'mae_val_E{ckpt_epoch}': mae,\n",
    "        f'val_pv_E{ckpt_epoch}': val_pv\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa39f440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Predicting with model from epoch ES]\n",
      "Epoch ES | MSE: 0.11328338086605072 | MAE: 0.23653222620487213\n",
      "\n",
      "[Predicting with model from epoch 1]\n",
      "Epoch 1 | MSE: 0.12368978559970856 | MAE: 0.2478981614112854\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "\n",
    "# Train DataLoader for inference\n",
    "train_dataloader_infer = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 모델 체크포인트가 저장된 epoch 리스트\n",
    "checkpoint_epochs = ['ES', 1]\n",
    "\n",
    "# 결과 저장용 딕셔너리\n",
    "train_1st_results = {}\n",
    "\n",
    "for ckpt_epoch in checkpoint_epochs:\n",
    "    print(f'\\n[Predicting with model from epoch {ckpt_epoch}]')\n",
    "\n",
    "    # 모델 불러오기\n",
    "    model_path = os.path.join(configs.save_path, f'checkpoint_{ckpt_epoch}.pth')\n",
    "    \n",
    "    model = Model(configs).to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_sequence, batch_label in train_dataloader_infer:\n",
    "            batch_sequence = batch_sequence.float().to(device)\n",
    "            batch_label = batch_label.float().to(device)\n",
    "\n",
    "            output = model(batch_sequence)\n",
    "            output = output[:, -configs.pred_len:, :]\n",
    "            batch_label = batch_label[:, -configs.pred_len:, :]\n",
    "\n",
    "            predictions.append(output.detach().cpu().numpy())\n",
    "            actuals.append(batch_label.detach().cpu().numpy())\n",
    "\n",
    "    # 배치 전체 결합\n",
    "    predictions = np.concatenate(predictions, axis=0)  # shape: (N, pred_len, 1)\n",
    "    actuals = np.concatenate(actuals, axis=0)\n",
    "\n",
    "    # 플랫화\n",
    "    predictions_flatten = predictions.flatten()\n",
    "    actuals_flatten = actuals.flatten()\n",
    "\n",
    "    # 지표 계산\n",
    "    mse = mean_squared_error(actuals_flatten, predictions_flatten)\n",
    "    mae = mean_absolute_error(actuals_flatten, predictions_flatten)\n",
    "\n",
    "    print(f'Epoch {ckpt_epoch} | MSE: {mse} | MAE: {mae}')\n",
    "\n",
    "    # test prediction을 torch.tensor로 변환해서 저장\n",
    "    num_samples = len(predictions_flatten) // configs.pred_len\n",
    "    train_pv = torch.tensor(\n",
    "        predictions_flatten.reshape(num_samples, configs.pred_len, 1),\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    # 딕셔너리에 저장\n",
    "    train_1st_results[ckpt_epoch] = {\n",
    "        f'mse_train_E{ckpt_epoch}': mse,\n",
    "        f'mae_train_E{ckpt_epoch}': mae,\n",
    "        f'train_pv_E{ckpt_epoch}': train_pv\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e65a4ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sequences shape:  torch.Size([4880, 336, 1])\n",
      "val_sequences shape:  torch.Size([665, 336, 1])\n",
      "test_sequences shape:  torch.Size([1422, 336, 1])\n",
      "---------------------------------------------\n",
      "train_pv shape:  torch.Size([4880, 96, 1])\n",
      "val_pv shape:  torch.Size([665, 96, 1])\n",
      "test_pv shape:  torch.Size([1422, 96, 1])\n",
      "---------------------------------------------\n",
      "train_labels shape:  torch.Size([4880, 96, 1])\n",
      "val_labels shape:  torch.Size([665, 96, 1])\n",
      "test_labels shape:  torch.Size([1422, 96, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"train_sequences shape: \",train_sequences.shape)\n",
    "print(\"val_sequences shape: \",val_sequences.shape)\n",
    "print(\"test_sequences shape: \",test_sequences.shape)\n",
    "\n",
    "print('---------------------------------------------')\n",
    "\n",
    "print(\"train_pv shape: \",train_pv.shape)\n",
    "print(\"val_pv shape: \",val_pv.shape)\n",
    "print(\"test_pv shape: \",test_pv.shape)\n",
    "\n",
    "\n",
    "print('---------------------------------------------')\n",
    "\n",
    "print(\"train_labels shape: \",train_labels.shape)\n",
    "print(\"val_labels shape: \",val_labels.shape)\n",
    "print(\"test_labels shape: \",test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b4eaa3",
   "metadata": {},
   "source": [
    "# Segment Generation Function (sliding window-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e029308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_segments(predictions, labels, segment_length, stride=1):\n",
    "    \"\"\"\n",
    "    시퀀스에 슬라이딩 윈도우를 stride 간격으로 적용하여\n",
    "    (B, num_segments, segment_length, C) 형태로 반환합니다.\n",
    "\n",
    "    Args:\n",
    "        predictions: Tensor of shape (B, T, C)\n",
    "        labels: Tensor of shape (B, T, C)\n",
    "        segment_length: int, 각 세그먼트의 길이 (예: pred_len // 3)\n",
    "        stride: int, 슬라이딩 윈도우 stride 간격\n",
    "\n",
    "    Returns:\n",
    "        pred_segments: (B, num_segments, segment_length, C)\n",
    "        label_segments: (B, num_segments, segment_length, C)\n",
    "    \"\"\"\n",
    "    B, T, C = predictions.shape\n",
    "    num_segments = (T - segment_length) // stride + 1\n",
    "\n",
    "    pred_segments = []\n",
    "    label_segments = []\n",
    "\n",
    "    for i in range(0, T - segment_length + 1, stride):\n",
    "        pred_seg = predictions[:, i:i+segment_length, :]  # (B, segment_length, C)\n",
    "        label_seg = labels[:, i:i+segment_length, :]      # (B, segment_length, C)\n",
    "        pred_segments.append(pred_seg.unsqueeze(1))       # (B, 1, segment_length, C)\n",
    "        label_segments.append(label_seg.unsqueeze(1))\n",
    "\n",
    "    pred_segments = torch.cat(pred_segments, dim=1)       # (B, num_segments, segment_length, C)\n",
    "    label_segments = torch.cat(label_segments, dim=1)     # (B, num_segments, segment_length, C)\n",
    "\n",
    "    return pred_segments, label_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e563efc",
   "metadata": {},
   "source": [
    "# Segmentation for PV Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56babf5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs.pred_len # pred_len // n 을 통해 덧붙일 세그먼트의 길이를 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f06aa7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch ES] Train seg shape: torch.Size([4880, 65, 32, 1]), Val: torch.Size([665, 65, 32, 1]), Test: torch.Size([1422, 65, 32, 1])\n",
      "[Epoch 1] Train seg shape: torch.Size([4880, 65, 32, 1]), Val: torch.Size([665, 65, 32, 1]), Test: torch.Size([1422, 65, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "segment_len = configs.pred_len // 3\n",
    "stride = 1  \n",
    "\n",
    "train_segments_by_epoch = {}\n",
    "val_segments_by_epoch = {}\n",
    "test_segments_by_epoch = {}\n",
    "\n",
    "for epoch in checkpoint_epochs:\n",
    "    train_pv = train_1st_results[epoch][f'train_pv_E{epoch}']  # (B, T)\n",
    "    val_pv = val_1st_results[epoch][f'val_pv_E{epoch}']        # (B, T)\n",
    "    test_pv = test_1st_results[epoch][f'test_pv_E{epoch}']     # (B, T)\n",
    "\n",
    "    # 라벨은 동일한 GT를 사용\n",
    "    train_pred_segments, train_label_segments = create_sliding_segments(train_pv, train_labels, segment_len,stride)\n",
    "    val_pred_segments, val_label_segments = create_sliding_segments(val_pv, val_labels, segment_len, stride)\n",
    "    test_pred_segments, test_label_segments = create_sliding_segments(test_pv, test_labels, segment_len, stride)\n",
    "\n",
    "    train_segments_by_epoch[epoch] = {\n",
    "        f'train_pred_segments_E{epoch}': train_pred_segments,  # shape: (B, 65, segment_len, 1)\n",
    "        f'train_label_segments_E{epoch}': train_label_segments\n",
    "    }\n",
    "\n",
    "    val_segments_by_epoch[epoch] = {\n",
    "        f'val_pred_segments_E{epoch}': val_pred_segments,\n",
    "        f'val_label_segments_E{epoch}': val_label_segments\n",
    "    }\n",
    "\n",
    "    test_segments_by_epoch[epoch] = {\n",
    "        f'test_pred_segments_E{epoch}': test_pred_segments,\n",
    "        f'test_label_segments_E{epoch}': test_label_segments\n",
    "    }\n",
    "\n",
    "    # 확인용 로그\n",
    "    print(f\"[Epoch {epoch}] Train seg shape: {train_pred_segments.shape}, Val: {val_pred_segments.shape}, Test: {test_pred_segments.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9a6c51",
   "metadata": {},
   "source": [
    "## Save 1st Performance Metrics, PV, and Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d88b418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All dictionaries saved successfully in ./saved_results\n"
     ]
    }
   ],
   "source": [
    "save_dir = './1st_results_ER'  # 저장할 디렉토리\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 1st stage prediction 결과 저장\n",
    "torch.save(train_1st_results, os.path.join(save_dir, 'train_1st_results.pt'))\n",
    "torch.save(val_1st_results, os.path.join(save_dir, 'val_1st_results.pt'))\n",
    "torch.save(test_1st_results, os.path.join(save_dir, 'test_1st_results.pt'))\n",
    "\n",
    "# 세그먼트 결과 저장\n",
    "torch.save(train_segments_by_epoch, os.path.join(save_dir, 'train_segments_by_epoch.pt'))\n",
    "torch.save(val_segments_by_epoch, os.path.join(save_dir, 'val_segments_by_epoch.pt'))\n",
    "torch.save(test_segments_by_epoch, os.path.join(save_dir, 'test_segments_by_epoch.pt'))\n",
    "\n",
    "print(\"✅ All dictionaries saved successfully in ./saved_results\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25d3449",
   "metadata": {},
   "source": [
    "# 2nd Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35b4f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_segments_by_epoch = torch.load('./1st_results_ER/train_segments_by_epoch.pt', weights_only=False)\n",
    "val_segments_by_epoch = torch.load('./1st_results_ER/val_segments_by_epoch.pt', weights_only=False)\n",
    "test_segments_by_epoch = torch.load('./1st_results_ER/test_segments_by_epoch.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "244e64c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ES', 1])\n",
      "dict_keys(['train_pred_segments_EES', 'train_label_segments_EES'])\n",
      "dict_keys(['train_pred_segments_E1', 'train_label_segments_E1'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_segments_by_epoch.keys())\n",
    "print(train_segments_by_epoch['ES'].keys())\n",
    "print(train_segments_by_epoch[1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f6b3d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_pred_segments_ES = train_segments_by_epoch['ES']['train_pred_segments_EES']  # shape: (B, 65, segment_len, 1)\n",
    "train_label_segments_ES = train_segments_by_epoch['ES']['train_label_segments_EES']\n",
    "val_pred_segments_ES = val_segments_by_epoch['ES']['val_pred_segments_EES']  # shape: (B, 65, segment_len, 1)\n",
    "val_label_segments_ES = val_segments_by_epoch['ES']['val_label_segments_EES']\n",
    "test_pred_segments_ES = test_segments_by_epoch['ES']['test_pred_segments_EES']  # shape: (B, 65, segment_len, 1)\n",
    "test_label_segments_ES = test_segments_by_epoch['ES']['test_label_segments_EES']\n",
    "\n",
    "\n",
    "train_pred_segments_E1 = train_segments_by_epoch[1]['train_pred_segments_E1']  # shape: (B, 65, segment_len, 1)\n",
    "train_label_segments_E1 = train_segments_by_epoch[1]['train_label_segments_E1']\n",
    "val_pred_segments_E1 = val_segments_by_epoch[1]['val_pred_segments_E1']  # shape: (B, 65, segment_len, 1)\n",
    "val_label_segments_E1 = val_segments_by_epoch[1]['val_label_segments_E1']\n",
    "test_pred_segments_E1 = test_segments_by_epoch[1]['test_pred_segments_E1']  # shape: (B, 65, segment_len, 1)\n",
    "test_label_segments_E1 = test_segments_by_epoch[1]['test_label_segments_E1']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c201d5f0",
   "metadata": {},
   "source": [
    "## ES->1E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e96ec0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== Segment 0 ===========\n",
      "[Segment 0] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 0] Training Time = 1.97 sec\n",
      "[Segment 0] GPU Memory Start = 196.38 MB\n",
      "[Segment 0] GPU Memory End   = 196.94 MB\n",
      "[Segment 0] GPU Peak Memory  = 197.96 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 1 ===========\n",
      "[Segment 1] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 1] Training Time = 1.27 sec\n",
      "[Segment 1] GPU Memory Start = 196.94 MB\n",
      "[Segment 1] GPU Memory End   = 197.08 MB\n",
      "[Segment 1] GPU Peak Memory  = 198.10 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 2 ===========\n",
      "[Segment 2] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 2] Training Time = 2.12 sec\n",
      "[Segment 2] GPU Memory Start = 197.08 MB\n",
      "[Segment 2] GPU Memory End   = 197.21 MB\n",
      "[Segment 2] GPU Peak Memory  = 198.23 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 3 ===========\n",
      "[Segment 3] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 3] Training Time = 1.29 sec\n",
      "[Segment 3] GPU Memory Start = 197.21 MB\n",
      "[Segment 3] GPU Memory End   = 197.35 MB\n",
      "[Segment 3] GPU Peak Memory  = 198.37 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 4 ===========\n",
      "[Segment 4] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 4] Training Time = 1.28 sec\n",
      "[Segment 4] GPU Memory Start = 197.35 MB\n",
      "[Segment 4] GPU Memory End   = 197.48 MB\n",
      "[Segment 4] GPU Peak Memory  = 198.50 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 5 ===========\n",
      "[Segment 5] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 5] Training Time = 1.28 sec\n",
      "[Segment 5] GPU Memory Start = 197.48 MB\n",
      "[Segment 5] GPU Memory End   = 197.62 MB\n",
      "[Segment 5] GPU Peak Memory  = 198.64 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 6 ===========\n",
      "[Segment 6] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 6] Training Time = 1.28 sec\n",
      "[Segment 6] GPU Memory Start = 197.62 MB\n",
      "[Segment 6] GPU Memory End   = 197.75 MB\n",
      "[Segment 6] GPU Peak Memory  = 198.77 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 7 ===========\n",
      "[Segment 7] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 7] Training Time = 1.29 sec\n",
      "[Segment 7] GPU Memory Start = 196.94 MB\n",
      "[Segment 7] GPU Memory End   = 197.08 MB\n",
      "[Segment 7] GPU Peak Memory  = 198.10 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 8 ===========\n",
      "[Segment 8] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 8] Training Time = 1.39 sec\n",
      "[Segment 8] GPU Memory Start = 197.08 MB\n",
      "[Segment 8] GPU Memory End   = 197.21 MB\n",
      "[Segment 8] GPU Peak Memory  = 198.23 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 9 ===========\n",
      "[Segment 9] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 9] Training Time = 1.64 sec\n",
      "[Segment 9] GPU Memory Start = 197.21 MB\n",
      "[Segment 9] GPU Memory End   = 197.35 MB\n",
      "[Segment 9] GPU Peak Memory  = 198.37 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 10 ===========\n",
      "[Segment 10] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 10] Training Time = 2.21 sec\n",
      "[Segment 10] GPU Memory Start = 197.35 MB\n",
      "[Segment 10] GPU Memory End   = 197.48 MB\n",
      "[Segment 10] GPU Peak Memory  = 198.50 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 11 ===========\n",
      "[Segment 11] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 11] Training Time = 2.07 sec\n",
      "[Segment 11] GPU Memory Start = 197.48 MB\n",
      "[Segment 11] GPU Memory End   = 197.62 MB\n",
      "[Segment 11] GPU Peak Memory  = 198.64 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 12 ===========\n",
      "[Segment 12] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 12] Training Time = 1.73 sec\n",
      "[Segment 12] GPU Memory Start = 197.62 MB\n",
      "[Segment 12] GPU Memory End   = 197.75 MB\n",
      "[Segment 12] GPU Peak Memory  = 198.77 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 13 ===========\n",
      "[Segment 13] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 13] Training Time = 1.28 sec\n",
      "[Segment 13] GPU Memory Start = 197.75 MB\n",
      "[Segment 13] GPU Memory End   = 197.89 MB\n",
      "[Segment 13] GPU Peak Memory  = 198.91 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 14 ===========\n",
      "[Segment 14] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 14] Training Time = 1.27 sec\n",
      "[Segment 14] GPU Memory Start = 197.89 MB\n",
      "[Segment 14] GPU Memory End   = 198.03 MB\n",
      "[Segment 14] GPU Peak Memory  = 199.05 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 15 ===========\n",
      "[Segment 15] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 15] Training Time = 1.84 sec\n",
      "[Segment 15] GPU Memory Start = 198.03 MB\n",
      "[Segment 15] GPU Memory End   = 198.16 MB\n",
      "[Segment 15] GPU Peak Memory  = 199.18 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 16 ===========\n",
      "[Segment 16] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 16] Training Time = 1.53 sec\n",
      "[Segment 16] GPU Memory Start = 198.16 MB\n",
      "[Segment 16] GPU Memory End   = 198.30 MB\n",
      "[Segment 16] GPU Peak Memory  = 199.32 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 17 ===========\n",
      "[Segment 17] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 17] Training Time = 1.28 sec\n",
      "[Segment 17] GPU Memory Start = 196.94 MB\n",
      "[Segment 17] GPU Memory End   = 197.08 MB\n",
      "[Segment 17] GPU Peak Memory  = 198.10 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 18 ===========\n",
      "[Segment 18] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 18] Training Time = 1.27 sec\n",
      "[Segment 18] GPU Memory Start = 197.08 MB\n",
      "[Segment 18] GPU Memory End   = 197.21 MB\n",
      "[Segment 18] GPU Peak Memory  = 198.23 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 19 ===========\n",
      "[Segment 19] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 19] Training Time = 1.71 sec\n",
      "[Segment 19] GPU Memory Start = 197.21 MB\n",
      "[Segment 19] GPU Memory End   = 197.35 MB\n",
      "[Segment 19] GPU Peak Memory  = 198.37 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 20 ===========\n",
      "[Segment 20] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 20] Training Time = 1.82 sec\n",
      "[Segment 20] GPU Memory Start = 197.35 MB\n",
      "[Segment 20] GPU Memory End   = 197.48 MB\n",
      "[Segment 20] GPU Peak Memory  = 198.50 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 21 ===========\n",
      "[Segment 21] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 21] Training Time = 2.26 sec\n",
      "[Segment 21] GPU Memory Start = 197.48 MB\n",
      "[Segment 21] GPU Memory End   = 197.62 MB\n",
      "[Segment 21] GPU Peak Memory  = 198.64 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 22 ===========\n",
      "[Segment 22] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 22] Training Time = 1.30 sec\n",
      "[Segment 22] GPU Memory Start = 197.62 MB\n",
      "[Segment 22] GPU Memory End   = 197.75 MB\n",
      "[Segment 22] GPU Peak Memory  = 198.77 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 23 ===========\n",
      "[Segment 23] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 23] Training Time = 1.51 sec\n",
      "[Segment 23] GPU Memory Start = 197.75 MB\n",
      "[Segment 23] GPU Memory End   = 197.89 MB\n",
      "[Segment 23] GPU Peak Memory  = 198.91 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 24 ===========\n",
      "[Segment 24] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 24] Training Time = 1.27 sec\n",
      "[Segment 24] GPU Memory Start = 197.89 MB\n",
      "[Segment 24] GPU Memory End   = 198.03 MB\n",
      "[Segment 24] GPU Peak Memory  = 199.05 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 25 ===========\n",
      "[Segment 25] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 25] Training Time = 1.28 sec\n",
      "[Segment 25] GPU Memory Start = 198.03 MB\n",
      "[Segment 25] GPU Memory End   = 198.16 MB\n",
      "[Segment 25] GPU Peak Memory  = 199.18 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 26 ===========\n",
      "[Segment 26] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 26] Training Time = 1.27 sec\n",
      "[Segment 26] GPU Memory Start = 198.16 MB\n",
      "[Segment 26] GPU Memory End   = 198.30 MB\n",
      "[Segment 26] GPU Peak Memory  = 199.32 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 27 ===========\n",
      "[Segment 27] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 27] Training Time = 1.28 sec\n",
      "[Segment 27] GPU Memory Start = 196.94 MB\n",
      "[Segment 27] GPU Memory End   = 197.08 MB\n",
      "[Segment 27] GPU Peak Memory  = 198.10 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 28 ===========\n",
      "[Segment 28] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 28] Training Time = 1.87 sec\n",
      "[Segment 28] GPU Memory Start = 197.08 MB\n",
      "[Segment 28] GPU Memory End   = 197.21 MB\n",
      "[Segment 28] GPU Peak Memory  = 198.23 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 29 ===========\n",
      "[Segment 29] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 29] Training Time = 1.81 sec\n",
      "[Segment 29] GPU Memory Start = 197.21 MB\n",
      "[Segment 29] GPU Memory End   = 197.35 MB\n",
      "[Segment 29] GPU Peak Memory  = 198.37 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 30 ===========\n",
      "[Segment 30] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 30] Training Time = 1.90 sec\n",
      "[Segment 30] GPU Memory Start = 197.35 MB\n",
      "[Segment 30] GPU Memory End   = 197.48 MB\n",
      "[Segment 30] GPU Peak Memory  = 198.50 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 31 ===========\n",
      "[Segment 31] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 31] Training Time = 1.27 sec\n",
      "[Segment 31] GPU Memory Start = 197.48 MB\n",
      "[Segment 31] GPU Memory End   = 197.62 MB\n",
      "[Segment 31] GPU Peak Memory  = 198.64 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 32 ===========\n",
      "[Segment 32] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 32] Training Time = 1.28 sec\n",
      "[Segment 32] GPU Memory Start = 197.62 MB\n",
      "[Segment 32] GPU Memory End   = 197.75 MB\n",
      "[Segment 32] GPU Peak Memory  = 198.77 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 33 ===========\n",
      "[Segment 33] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 33] Training Time = 1.28 sec\n",
      "[Segment 33] GPU Memory Start = 197.75 MB\n",
      "[Segment 33] GPU Memory End   = 197.89 MB\n",
      "[Segment 33] GPU Peak Memory  = 198.91 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 34 ===========\n",
      "[Segment 34] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 34] Training Time = 1.27 sec\n",
      "[Segment 34] GPU Memory Start = 197.89 MB\n",
      "[Segment 34] GPU Memory End   = 198.03 MB\n",
      "[Segment 34] GPU Peak Memory  = 199.05 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 35 ===========\n",
      "[Segment 35] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 35] Training Time = 1.18 sec\n",
      "[Segment 35] GPU Memory Start = 198.03 MB\n",
      "[Segment 35] GPU Memory End   = 198.16 MB\n",
      "[Segment 35] GPU Peak Memory  = 199.18 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 36 ===========\n",
      "[Segment 36] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 36] Training Time = 1.26 sec\n",
      "[Segment 36] GPU Memory Start = 198.16 MB\n",
      "[Segment 36] GPU Memory End   = 198.30 MB\n",
      "[Segment 36] GPU Peak Memory  = 199.32 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 37 ===========\n",
      "[Segment 37] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 37] Training Time = 1.25 sec\n",
      "[Segment 37] GPU Memory Start = 196.94 MB\n",
      "[Segment 37] GPU Memory End   = 197.08 MB\n",
      "[Segment 37] GPU Peak Memory  = 198.10 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 38 ===========\n",
      "[Segment 38] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 38] Training Time = 2.19 sec\n",
      "[Segment 38] GPU Memory Start = 197.08 MB\n",
      "[Segment 38] GPU Memory End   = 197.21 MB\n",
      "[Segment 38] GPU Peak Memory  = 198.23 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 39 ===========\n",
      "[Segment 39] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 39] Training Time = 1.28 sec\n",
      "[Segment 39] GPU Memory Start = 197.21 MB\n",
      "[Segment 39] GPU Memory End   = 197.35 MB\n",
      "[Segment 39] GPU Peak Memory  = 198.37 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 40 ===========\n",
      "[Segment 40] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 40] Training Time = 1.32 sec\n",
      "[Segment 40] GPU Memory Start = 197.35 MB\n",
      "[Segment 40] GPU Memory End   = 197.48 MB\n",
      "[Segment 40] GPU Peak Memory  = 198.50 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 41 ===========\n",
      "[Segment 41] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 41] Training Time = 1.30 sec\n",
      "[Segment 41] GPU Memory Start = 197.48 MB\n",
      "[Segment 41] GPU Memory End   = 197.62 MB\n",
      "[Segment 41] GPU Peak Memory  = 198.64 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 42 ===========\n",
      "[Segment 42] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 42] Training Time = 1.29 sec\n",
      "[Segment 42] GPU Memory Start = 197.62 MB\n",
      "[Segment 42] GPU Memory End   = 197.75 MB\n",
      "[Segment 42] GPU Peak Memory  = 198.77 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 43 ===========\n",
      "[Segment 43] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 43] Training Time = 1.30 sec\n",
      "[Segment 43] GPU Memory Start = 197.75 MB\n",
      "[Segment 43] GPU Memory End   = 197.89 MB\n",
      "[Segment 43] GPU Peak Memory  = 198.91 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 44 ===========\n",
      "[Segment 44] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 44] Training Time = 1.29 sec\n",
      "[Segment 44] GPU Memory Start = 197.89 MB\n",
      "[Segment 44] GPU Memory End   = 198.03 MB\n",
      "[Segment 44] GPU Peak Memory  = 199.05 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 45 ===========\n",
      "[Segment 45] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 45] Training Time = 1.38 sec\n",
      "[Segment 45] GPU Memory Start = 198.03 MB\n",
      "[Segment 45] GPU Memory End   = 198.16 MB\n",
      "[Segment 45] GPU Peak Memory  = 199.18 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 46 ===========\n",
      "[Segment 46] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 46] Training Time = 1.30 sec\n",
      "[Segment 46] GPU Memory Start = 198.16 MB\n",
      "[Segment 46] GPU Memory End   = 198.30 MB\n",
      "[Segment 46] GPU Peak Memory  = 199.32 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 47 ===========\n",
      "[Segment 47] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 47] Training Time = 1.29 sec\n",
      "[Segment 47] GPU Memory Start = 196.94 MB\n",
      "[Segment 47] GPU Memory End   = 197.08 MB\n",
      "[Segment 47] GPU Peak Memory  = 198.10 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 48 ===========\n",
      "[Segment 48] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 48] Training Time = 2.25 sec\n",
      "[Segment 48] GPU Memory Start = 197.08 MB\n",
      "[Segment 48] GPU Memory End   = 197.21 MB\n",
      "[Segment 48] GPU Peak Memory  = 198.23 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 49 ===========\n",
      "[Segment 49] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 49] Training Time = 1.27 sec\n",
      "[Segment 49] GPU Memory Start = 197.21 MB\n",
      "[Segment 49] GPU Memory End   = 197.35 MB\n",
      "[Segment 49] GPU Peak Memory  = 198.37 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 50 ===========\n",
      "[Segment 50] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 50] Training Time = 1.83 sec\n",
      "[Segment 50] GPU Memory Start = 197.35 MB\n",
      "[Segment 50] GPU Memory End   = 197.48 MB\n",
      "[Segment 50] GPU Peak Memory  = 198.50 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 51 ===========\n",
      "[Segment 51] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 51] Training Time = 1.28 sec\n",
      "[Segment 51] GPU Memory Start = 197.48 MB\n",
      "[Segment 51] GPU Memory End   = 197.62 MB\n",
      "[Segment 51] GPU Peak Memory  = 198.64 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 52 ===========\n",
      "[Segment 52] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 52] Training Time = 1.83 sec\n",
      "[Segment 52] GPU Memory Start = 197.62 MB\n",
      "[Segment 52] GPU Memory End   = 197.75 MB\n",
      "[Segment 52] GPU Peak Memory  = 198.77 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 53 ===========\n",
      "[Segment 53] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 53] Training Time = 2.26 sec\n",
      "[Segment 53] GPU Memory Start = 197.75 MB\n",
      "[Segment 53] GPU Memory End   = 197.89 MB\n",
      "[Segment 53] GPU Peak Memory  = 198.91 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 54 ===========\n",
      "[Segment 54] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 54] Training Time = 1.05 sec\n",
      "[Segment 54] GPU Memory Start = 197.89 MB\n",
      "[Segment 54] GPU Memory End   = 198.03 MB\n",
      "[Segment 54] GPU Peak Memory  = 199.05 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 55 ===========\n",
      "[Segment 55] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 55] Training Time = 0.90 sec\n",
      "[Segment 55] GPU Memory Start = 198.03 MB\n",
      "[Segment 55] GPU Memory End   = 198.16 MB\n",
      "[Segment 55] GPU Peak Memory  = 199.18 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 56 ===========\n",
      "[Segment 56] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 56] Training Time = 1.18 sec\n",
      "[Segment 56] GPU Memory Start = 198.16 MB\n",
      "[Segment 56] GPU Memory End   = 198.30 MB\n",
      "[Segment 56] GPU Peak Memory  = 199.32 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 57 ===========\n",
      "[Segment 57] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 57] Training Time = 2.14 sec\n",
      "[Segment 57] GPU Memory Start = 196.94 MB\n",
      "[Segment 57] GPU Memory End   = 197.08 MB\n",
      "[Segment 57] GPU Peak Memory  = 198.10 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 58 ===========\n",
      "[Segment 58] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 58] Training Time = 1.28 sec\n",
      "[Segment 58] GPU Memory Start = 197.08 MB\n",
      "[Segment 58] GPU Memory End   = 197.21 MB\n",
      "[Segment 58] GPU Peak Memory  = 198.23 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 59 ===========\n",
      "[Segment 59] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 59] Training Time = 1.28 sec\n",
      "[Segment 59] GPU Memory Start = 197.21 MB\n",
      "[Segment 59] GPU Memory End   = 197.35 MB\n",
      "[Segment 59] GPU Peak Memory  = 198.37 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 60 ===========\n",
      "[Segment 60] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 60] Training Time = 1.24 sec\n",
      "[Segment 60] GPU Memory Start = 197.35 MB\n",
      "[Segment 60] GPU Memory End   = 197.48 MB\n",
      "[Segment 60] GPU Peak Memory  = 198.50 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 61 ===========\n",
      "[Segment 61] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 61] Training Time = 1.27 sec\n",
      "[Segment 61] GPU Memory Start = 197.48 MB\n",
      "[Segment 61] GPU Memory End   = 197.62 MB\n",
      "[Segment 61] GPU Peak Memory  = 198.64 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 62 ===========\n",
      "[Segment 62] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 62] Training Time = 1.29 sec\n",
      "[Segment 62] GPU Memory Start = 197.62 MB\n",
      "[Segment 62] GPU Memory End   = 197.75 MB\n",
      "[Segment 62] GPU Peak Memory  = 198.77 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 63 ===========\n",
      "[Segment 63] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 63] Training Time = 1.02 sec\n",
      "[Segment 63] GPU Memory Start = 197.75 MB\n",
      "[Segment 63] GPU Memory End   = 197.89 MB\n",
      "[Segment 63] GPU Peak Memory  = 198.91 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 64 ===========\n",
      "[Segment 64] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 64] Training Time = 1.29 sec\n",
      "[Segment 64] GPU Memory Start = 197.89 MB\n",
      "[Segment 64] GPU Memory End   = 198.03 MB\n",
      "[Segment 64] GPU Peak Memory  = 199.05 MB\n",
      "\n",
      "============= Done =============\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "\n",
    "epo = 'ES'\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual,\n",
    "                 learning_rate, lradj, patience,\n",
    "                 save_path, attach_pv):\n",
    "        self.seq_len  = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in   = enc_in          # 채널 수\n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv    = attach_pv\n",
    "\n",
    "\n",
    "# ── 공통 Config ───────────────────────────────────────────────\n",
    "base_cfg = Configs(\n",
    "    seq_len          = 336,\n",
    "    pred_len         = 96,\n",
    "    enc_in           = 1,\n",
    "    individual       = True,\n",
    "    learning_rate    = 0.0005,\n",
    "    lradj            = 'type1',\n",
    "    patience         = 3,\n",
    "    save_path        = f\"./model2_ER_E{epo}_1E\",\n",
    "    attach_pv  = True\n",
    ")\n",
    "Path(base_cfg.save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# ── 세그먼트 루프 (65개) ──────────────────────────────────────\n",
    "for seg in range(len(train_pred_segments_ES[0])):\n",
    "    print(f\"\\n=========== Segment {seg} ===========\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # GPU memory 사용량 초기화\n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    mem_start = torch.cuda.memory_allocated(device)\n",
    "\n",
    "    # ── 데이터로더 생성 (세그먼트 전용 pv) ───────────────\n",
    "    tr_pv = train_pred_segments_ES[:, seg, :, :]   # (N,P,C)\n",
    "    va_pv = val_pred_segments_ES[:,  seg, :, :]\n",
    "\n",
    "    tr_ds = TensorDataset(train_sequences, train_labels, tr_pv)\n",
    "    va_ds = TensorDataset(val_sequences,   val_labels,   va_pv)\n",
    "    tr_dl = DataLoader(tr_ds, batch_size=8, shuffle=True)\n",
    "    va_dl = DataLoader(va_ds, batch_size=8, shuffle=False)\n",
    "\n",
    "    # ── 모델·채널별 옵티마이저·ES ───────────────────────\n",
    "    model = Model(base_cfg).to(device)\n",
    "    C     = model.channels                                    # =1\n",
    "\n",
    "    opts = []\n",
    "    for c in range(C):\n",
    "        params = list(model.Linear[c].parameters())\n",
    "        opts.append(optim.Adam(params, lr=base_cfg.learning_rate))\n",
    "        path = Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{c}\"\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    active = set(range(C))            # 현재 학습 중 채널 id\n",
    "\n",
    "    # ── 학습 루프 (세그먼트별) ──────────────────────────\n",
    "    for epoch in range(1, 2):\n",
    "        if not active: break          # 모든 채널 종료 시 탈출\n",
    "\n",
    "        # ‣ Train ------------------------------------------------d\n",
    "        model.train()\n",
    "        for c in active:                              # LR decay\n",
    "            if base_cfg.lradj=='type1':\n",
    "                lr = base_cfg.learning_rate * 0.5**((epoch-1)//1)\n",
    "                for g in opts[c].param_groups: g['lr'] = lr\n",
    "\n",
    "        printed_tensor_info = False  \n",
    "\n",
    "        for xb, yb, pv in tr_dl:\n",
    "            xb, yb, pv = xb.float().to(device), yb.float().to(device), pv.float().to(device)\n",
    "\n",
    "            if not printed_tensor_info:\n",
    "                # batch 당 tensor size 계산\n",
    "                xb_size = xb.numel() * xb.element_size() / 1024**2\n",
    "                yb_size = yb.numel() * yb.element_size() / 1024**2\n",
    "                pv_size = pv.numel() * pv.element_size() / 1024**2\n",
    "\n",
    "                # ─────────────────────────────\n",
    "                # ① 전체 batch 개수 계산\n",
    "                num_batches = len(tr_dl)\n",
    "\n",
    "                # ② 전체 tensor 크기 계산\n",
    "                total_xb_MB = num_batches * xb_size\n",
    "                total_yb_MB = num_batches * yb_size\n",
    "                total_pv_MB = num_batches * pv_size\n",
    "                # ─────────────────────────────\n",
    "\n",
    "\n",
    "                print(f\"[Segment {seg}] Batch Size Info:\")\n",
    "                print(f\"  xb per batch = {xb_size:.4f} MB, total = {total_xb_MB:.4f} MB\")\n",
    "                print(f\"  yb per batch = {yb_size:.4f} MB, total = {total_yb_MB:.4f} MB\")\n",
    "                print(f\"  pv per batch = {pv_size:.4f} MB, total = {total_pv_MB:.4f} MB\")\n",
    "\n",
    "                printed_tensor_info = True\n",
    "\n",
    "\n",
    "            out = model(xb, pv)                       # fwd 1회\n",
    "\n",
    "            loss_list = []\n",
    "            for c in active:\n",
    "                pred = out[:, -base_cfg.pred_len:, c]\n",
    "                tgt  = yb[:, -base_cfg.pred_len:, c]\n",
    "                loss_list.append(loss_fn(pred, tgt))\n",
    "\n",
    "            total = torch.stack(loss_list).sum()\n",
    "            for opt in opts:\n",
    "                if opt: opt.zero_grad()\n",
    "            total.backward()\n",
    "            for c in active:\n",
    "                opts[c].step()\n",
    "        # ── 학습 시간 & 메모리 로깅 ─────────────────────────────\n",
    "    elapsed = time.time() - start_time\n",
    "    mem_end = torch.cuda.memory_allocated(device)\n",
    "    peak_mem = torch.cuda.max_memory_allocated(device)\n",
    "\n",
    "\n",
    "    print(f\"[Segment {seg}] Training Time = {elapsed:.2f} sec\")\n",
    "    print(f\"[Segment {seg}] GPU Memory Start = {mem_start/1024**2:.2f} MB\")\n",
    "    print(f\"[Segment {seg}] GPU Memory End   = {mem_end/1024**2:.2f} MB\")\n",
    "    print(f\"[Segment {seg}] GPU Peak Memory  = {peak_mem/1024**2:.2f} MB\")\n",
    "\n",
    "    print(f\"\\n============= Done =============\")\n",
    "\n",
    "    # ── seg 완료: 최종 state_dict(선택) 저장 --------------------\n",
    "    torch.save(model.state_dict(),\n",
    "                Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{c}\" / \"checkpoint.pth\")\n",
    "    del model, opts; torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73fc3e7",
   "metadata": {},
   "source": [
    "## 1E->1E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "726c47d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== Segment 0 ===========\n",
      "[Segment 0] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 0] Training Time = 2.45 sec\n",
      "[Segment 0] GPU Memory Start = 196.94 MB\n",
      "[Segment 0] GPU Memory End   = 196.94 MB\n",
      "[Segment 0] GPU Peak Memory  = 198.10 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 1 ===========\n",
      "[Segment 1] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 1] Training Time = 1.40 sec\n",
      "[Segment 1] GPU Memory Start = 196.94 MB\n",
      "[Segment 1] GPU Memory End   = 197.08 MB\n",
      "[Segment 1] GPU Peak Memory  = 198.10 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 2 ===========\n",
      "[Segment 2] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 2] Training Time = 1.28 sec\n",
      "[Segment 2] GPU Memory Start = 197.08 MB\n",
      "[Segment 2] GPU Memory End   = 197.21 MB\n",
      "[Segment 2] GPU Peak Memory  = 198.23 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 3 ===========\n",
      "[Segment 3] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 3] Training Time = 2.18 sec\n",
      "[Segment 3] GPU Memory Start = 197.21 MB\n",
      "[Segment 3] GPU Memory End   = 197.35 MB\n",
      "[Segment 3] GPU Peak Memory  = 198.37 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 4 ===========\n",
      "[Segment 4] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 4] Training Time = 1.97 sec\n",
      "[Segment 4] GPU Memory Start = 197.35 MB\n",
      "[Segment 4] GPU Memory End   = 197.48 MB\n",
      "[Segment 4] GPU Peak Memory  = 198.50 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 5 ===========\n",
      "[Segment 5] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 5] Training Time = 1.30 sec\n",
      "[Segment 5] GPU Memory Start = 197.48 MB\n",
      "[Segment 5] GPU Memory End   = 197.62 MB\n",
      "[Segment 5] GPU Peak Memory  = 198.64 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 6 ===========\n",
      "[Segment 6] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 6] Training Time = 1.27 sec\n",
      "[Segment 6] GPU Memory Start = 196.94 MB\n",
      "[Segment 6] GPU Memory End   = 197.08 MB\n",
      "[Segment 6] GPU Peak Memory  = 198.10 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 7 ===========\n",
      "[Segment 7] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 7] Training Time = 2.35 sec\n",
      "[Segment 7] GPU Memory Start = 197.08 MB\n",
      "[Segment 7] GPU Memory End   = 197.21 MB\n",
      "[Segment 7] GPU Peak Memory  = 198.23 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 8 ===========\n",
      "[Segment 8] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 8] Training Time = 1.49 sec\n",
      "[Segment 8] GPU Memory Start = 197.21 MB\n",
      "[Segment 8] GPU Memory End   = 197.35 MB\n",
      "[Segment 8] GPU Peak Memory  = 198.37 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 9 ===========\n",
      "[Segment 9] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 9] Training Time = 1.42 sec\n",
      "[Segment 9] GPU Memory Start = 197.35 MB\n",
      "[Segment 9] GPU Memory End   = 197.48 MB\n",
      "[Segment 9] GPU Peak Memory  = 198.50 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 10 ===========\n",
      "[Segment 10] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 10] Training Time = 1.43 sec\n",
      "[Segment 10] GPU Memory Start = 197.48 MB\n",
      "[Segment 10] GPU Memory End   = 197.62 MB\n",
      "[Segment 10] GPU Peak Memory  = 198.64 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 11 ===========\n",
      "[Segment 11] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 11] Training Time = 1.27 sec\n",
      "[Segment 11] GPU Memory Start = 197.62 MB\n",
      "[Segment 11] GPU Memory End   = 197.75 MB\n",
      "[Segment 11] GPU Peak Memory  = 198.77 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 12 ===========\n",
      "[Segment 12] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 12] Training Time = 1.29 sec\n",
      "[Segment 12] GPU Memory Start = 197.75 MB\n",
      "[Segment 12] GPU Memory End   = 197.89 MB\n",
      "[Segment 12] GPU Peak Memory  = 198.91 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 13 ===========\n",
      "[Segment 13] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 13] Training Time = 1.28 sec\n",
      "[Segment 13] GPU Memory Start = 197.89 MB\n",
      "[Segment 13] GPU Memory End   = 198.03 MB\n",
      "[Segment 13] GPU Peak Memory  = 199.05 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 14 ===========\n",
      "[Segment 14] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 14] Training Time = 1.66 sec\n",
      "[Segment 14] GPU Memory Start = 198.03 MB\n",
      "[Segment 14] GPU Memory End   = 198.16 MB\n",
      "[Segment 14] GPU Peak Memory  = 199.18 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 15 ===========\n",
      "[Segment 15] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 15] Training Time = 1.29 sec\n",
      "[Segment 15] GPU Memory Start = 198.16 MB\n",
      "[Segment 15] GPU Memory End   = 198.30 MB\n",
      "[Segment 15] GPU Peak Memory  = 199.32 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 16 ===========\n",
      "[Segment 16] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 16] Training Time = 2.21 sec\n",
      "[Segment 16] GPU Memory Start = 196.94 MB\n",
      "[Segment 16] GPU Memory End   = 197.08 MB\n",
      "[Segment 16] GPU Peak Memory  = 198.10 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 17 ===========\n",
      "[Segment 17] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 17] Training Time = 1.28 sec\n",
      "[Segment 17] GPU Memory Start = 197.08 MB\n",
      "[Segment 17] GPU Memory End   = 197.21 MB\n",
      "[Segment 17] GPU Peak Memory  = 198.23 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 18 ===========\n",
      "[Segment 18] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 18] Training Time = 1.27 sec\n",
      "[Segment 18] GPU Memory Start = 197.21 MB\n",
      "[Segment 18] GPU Memory End   = 197.35 MB\n",
      "[Segment 18] GPU Peak Memory  = 198.37 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 19 ===========\n",
      "[Segment 19] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 19] Training Time = 1.29 sec\n",
      "[Segment 19] GPU Memory Start = 197.35 MB\n",
      "[Segment 19] GPU Memory End   = 197.48 MB\n",
      "[Segment 19] GPU Peak Memory  = 198.50 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 20 ===========\n",
      "[Segment 20] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 20] Training Time = 1.28 sec\n",
      "[Segment 20] GPU Memory Start = 197.48 MB\n",
      "[Segment 20] GPU Memory End   = 197.62 MB\n",
      "[Segment 20] GPU Peak Memory  = 198.64 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 21 ===========\n",
      "[Segment 21] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 21] Training Time = 1.28 sec\n",
      "[Segment 21] GPU Memory Start = 197.62 MB\n",
      "[Segment 21] GPU Memory End   = 197.75 MB\n",
      "[Segment 21] GPU Peak Memory  = 198.77 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 22 ===========\n",
      "[Segment 22] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 22] Training Time = 2.15 sec\n",
      "[Segment 22] GPU Memory Start = 197.75 MB\n",
      "[Segment 22] GPU Memory End   = 197.89 MB\n",
      "[Segment 22] GPU Peak Memory  = 198.91 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 23 ===========\n",
      "[Segment 23] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 23] Training Time = 1.29 sec\n",
      "[Segment 23] GPU Memory Start = 197.89 MB\n",
      "[Segment 23] GPU Memory End   = 198.03 MB\n",
      "[Segment 23] GPU Peak Memory  = 199.05 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 24 ===========\n",
      "[Segment 24] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 24] Training Time = 1.29 sec\n",
      "[Segment 24] GPU Memory Start = 198.03 MB\n",
      "[Segment 24] GPU Memory End   = 198.16 MB\n",
      "[Segment 24] GPU Peak Memory  = 199.18 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 25 ===========\n",
      "[Segment 25] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 25] Training Time = 2.24 sec\n",
      "[Segment 25] GPU Memory Start = 198.16 MB\n",
      "[Segment 25] GPU Memory End   = 198.30 MB\n",
      "[Segment 25] GPU Peak Memory  = 199.32 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 26 ===========\n",
      "[Segment 26] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 26] Training Time = 1.29 sec\n",
      "[Segment 26] GPU Memory Start = 196.94 MB\n",
      "[Segment 26] GPU Memory End   = 197.08 MB\n",
      "[Segment 26] GPU Peak Memory  = 198.10 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 27 ===========\n",
      "[Segment 27] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 27] Training Time = 1.50 sec\n",
      "[Segment 27] GPU Memory Start = 197.08 MB\n",
      "[Segment 27] GPU Memory End   = 197.21 MB\n",
      "[Segment 27] GPU Peak Memory  = 198.23 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 28 ===========\n",
      "[Segment 28] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 28] Training Time = 1.62 sec\n",
      "[Segment 28] GPU Memory Start = 197.21 MB\n",
      "[Segment 28] GPU Memory End   = 197.35 MB\n",
      "[Segment 28] GPU Peak Memory  = 198.37 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 29 ===========\n",
      "[Segment 29] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 29] Training Time = 1.31 sec\n",
      "[Segment 29] GPU Memory Start = 197.35 MB\n",
      "[Segment 29] GPU Memory End   = 197.48 MB\n",
      "[Segment 29] GPU Peak Memory  = 198.50 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 30 ===========\n",
      "[Segment 30] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 30] Training Time = 1.30 sec\n",
      "[Segment 30] GPU Memory Start = 197.48 MB\n",
      "[Segment 30] GPU Memory End   = 197.62 MB\n",
      "[Segment 30] GPU Peak Memory  = 198.64 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 31 ===========\n",
      "[Segment 31] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 31] Training Time = 1.31 sec\n",
      "[Segment 31] GPU Memory Start = 197.62 MB\n",
      "[Segment 31] GPU Memory End   = 197.75 MB\n",
      "[Segment 31] GPU Peak Memory  = 198.77 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 32 ===========\n",
      "[Segment 32] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 32] Training Time = 1.30 sec\n",
      "[Segment 32] GPU Memory Start = 197.75 MB\n",
      "[Segment 32] GPU Memory End   = 197.89 MB\n",
      "[Segment 32] GPU Peak Memory  = 198.91 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 33 ===========\n",
      "[Segment 33] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 33] Training Time = 1.29 sec\n",
      "[Segment 33] GPU Memory Start = 197.89 MB\n",
      "[Segment 33] GPU Memory End   = 198.03 MB\n",
      "[Segment 33] GPU Peak Memory  = 199.05 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 34 ===========\n",
      "[Segment 34] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 34] Training Time = 1.31 sec\n",
      "[Segment 34] GPU Memory Start = 198.03 MB\n",
      "[Segment 34] GPU Memory End   = 198.16 MB\n",
      "[Segment 34] GPU Peak Memory  = 199.18 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 35 ===========\n",
      "[Segment 35] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 35] Training Time = 1.32 sec\n",
      "[Segment 35] GPU Memory Start = 198.16 MB\n",
      "[Segment 35] GPU Memory End   = 198.30 MB\n",
      "[Segment 35] GPU Peak Memory  = 199.32 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 36 ===========\n",
      "[Segment 36] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 36] Training Time = 1.30 sec\n",
      "[Segment 36] GPU Memory Start = 196.94 MB\n",
      "[Segment 36] GPU Memory End   = 197.08 MB\n",
      "[Segment 36] GPU Peak Memory  = 198.10 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 37 ===========\n",
      "[Segment 37] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 37] Training Time = 2.30 sec\n",
      "[Segment 37] GPU Memory Start = 197.08 MB\n",
      "[Segment 37] GPU Memory End   = 197.21 MB\n",
      "[Segment 37] GPU Peak Memory  = 198.23 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 38 ===========\n",
      "[Segment 38] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 38] Training Time = 1.30 sec\n",
      "[Segment 38] GPU Memory Start = 197.21 MB\n",
      "[Segment 38] GPU Memory End   = 197.35 MB\n",
      "[Segment 38] GPU Peak Memory  = 198.37 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 39 ===========\n",
      "[Segment 39] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 39] Training Time = 1.29 sec\n",
      "[Segment 39] GPU Memory Start = 197.35 MB\n",
      "[Segment 39] GPU Memory End   = 197.48 MB\n",
      "[Segment 39] GPU Peak Memory  = 198.50 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 40 ===========\n",
      "[Segment 40] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 40] Training Time = 1.30 sec\n",
      "[Segment 40] GPU Memory Start = 197.48 MB\n",
      "[Segment 40] GPU Memory End   = 197.62 MB\n",
      "[Segment 40] GPU Peak Memory  = 198.64 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 41 ===========\n",
      "[Segment 41] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 41] Training Time = 1.30 sec\n",
      "[Segment 41] GPU Memory Start = 197.62 MB\n",
      "[Segment 41] GPU Memory End   = 197.75 MB\n",
      "[Segment 41] GPU Peak Memory  = 198.77 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 42 ===========\n",
      "[Segment 42] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 42] Training Time = 1.29 sec\n",
      "[Segment 42] GPU Memory Start = 197.75 MB\n",
      "[Segment 42] GPU Memory End   = 197.89 MB\n",
      "[Segment 42] GPU Peak Memory  = 198.91 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 43 ===========\n",
      "[Segment 43] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 43] Training Time = 1.31 sec\n",
      "[Segment 43] GPU Memory Start = 197.89 MB\n",
      "[Segment 43] GPU Memory End   = 198.03 MB\n",
      "[Segment 43] GPU Peak Memory  = 199.05 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 44 ===========\n",
      "[Segment 44] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 44] Training Time = 1.25 sec\n",
      "[Segment 44] GPU Memory Start = 198.03 MB\n",
      "[Segment 44] GPU Memory End   = 198.16 MB\n",
      "[Segment 44] GPU Peak Memory  = 199.18 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 45 ===========\n",
      "[Segment 45] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 45] Training Time = 1.29 sec\n",
      "[Segment 45] GPU Memory Start = 198.16 MB\n",
      "[Segment 45] GPU Memory End   = 198.30 MB\n",
      "[Segment 45] GPU Peak Memory  = 199.32 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 46 ===========\n",
      "[Segment 46] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 46] Training Time = 1.64 sec\n",
      "[Segment 46] GPU Memory Start = 196.94 MB\n",
      "[Segment 46] GPU Memory End   = 197.08 MB\n",
      "[Segment 46] GPU Peak Memory  = 198.10 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 47 ===========\n",
      "[Segment 47] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 47] Training Time = 1.27 sec\n",
      "[Segment 47] GPU Memory Start = 197.08 MB\n",
      "[Segment 47] GPU Memory End   = 197.21 MB\n",
      "[Segment 47] GPU Peak Memory  = 198.23 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 48 ===========\n",
      "[Segment 48] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 48] Training Time = 1.76 sec\n",
      "[Segment 48] GPU Memory Start = 197.21 MB\n",
      "[Segment 48] GPU Memory End   = 197.35 MB\n",
      "[Segment 48] GPU Peak Memory  = 198.37 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 49 ===========\n",
      "[Segment 49] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 49] Training Time = 1.83 sec\n",
      "[Segment 49] GPU Memory Start = 197.35 MB\n",
      "[Segment 49] GPU Memory End   = 197.48 MB\n",
      "[Segment 49] GPU Peak Memory  = 198.50 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 50 ===========\n",
      "[Segment 50] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 50] Training Time = 2.29 sec\n",
      "[Segment 50] GPU Memory Start = 197.48 MB\n",
      "[Segment 50] GPU Memory End   = 197.62 MB\n",
      "[Segment 50] GPU Peak Memory  = 198.64 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 51 ===========\n",
      "[Segment 51] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 51] Training Time = 1.30 sec\n",
      "[Segment 51] GPU Memory Start = 197.62 MB\n",
      "[Segment 51] GPU Memory End   = 197.75 MB\n",
      "[Segment 51] GPU Peak Memory  = 198.77 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 52 ===========\n",
      "[Segment 52] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 52] Training Time = 1.29 sec\n",
      "[Segment 52] GPU Memory Start = 197.75 MB\n",
      "[Segment 52] GPU Memory End   = 197.89 MB\n",
      "[Segment 52] GPU Peak Memory  = 198.91 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 53 ===========\n",
      "[Segment 53] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 53] Training Time = 1.31 sec\n",
      "[Segment 53] GPU Memory Start = 197.89 MB\n",
      "[Segment 53] GPU Memory End   = 198.03 MB\n",
      "[Segment 53] GPU Peak Memory  = 199.05 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 54 ===========\n",
      "[Segment 54] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 54] Training Time = 1.29 sec\n",
      "[Segment 54] GPU Memory Start = 198.03 MB\n",
      "[Segment 54] GPU Memory End   = 198.16 MB\n",
      "[Segment 54] GPU Peak Memory  = 199.18 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 55 ===========\n",
      "[Segment 55] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 55] Training Time = 1.31 sec\n",
      "[Segment 55] GPU Memory Start = 198.16 MB\n",
      "[Segment 55] GPU Memory End   = 198.30 MB\n",
      "[Segment 55] GPU Peak Memory  = 199.32 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 56 ===========\n",
      "[Segment 56] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 56] Training Time = 1.29 sec\n",
      "[Segment 56] GPU Memory Start = 196.94 MB\n",
      "[Segment 56] GPU Memory End   = 197.08 MB\n",
      "[Segment 56] GPU Peak Memory  = 198.10 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 57 ===========\n",
      "[Segment 57] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 57] Training Time = 2.12 sec\n",
      "[Segment 57] GPU Memory Start = 197.08 MB\n",
      "[Segment 57] GPU Memory End   = 197.21 MB\n",
      "[Segment 57] GPU Peak Memory  = 198.23 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 58 ===========\n",
      "[Segment 58] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 58] Training Time = 1.34 sec\n",
      "[Segment 58] GPU Memory Start = 197.21 MB\n",
      "[Segment 58] GPU Memory End   = 197.35 MB\n",
      "[Segment 58] GPU Peak Memory  = 198.37 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 59 ===========\n",
      "[Segment 59] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 59] Training Time = 1.33 sec\n",
      "[Segment 59] GPU Memory Start = 197.35 MB\n",
      "[Segment 59] GPU Memory End   = 197.48 MB\n",
      "[Segment 59] GPU Peak Memory  = 198.50 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 60 ===========\n",
      "[Segment 60] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 60] Training Time = 1.31 sec\n",
      "[Segment 60] GPU Memory Start = 197.48 MB\n",
      "[Segment 60] GPU Memory End   = 197.62 MB\n",
      "[Segment 60] GPU Peak Memory  = 198.64 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 61 ===========\n",
      "[Segment 61] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 61] Training Time = 1.33 sec\n",
      "[Segment 61] GPU Memory Start = 197.62 MB\n",
      "[Segment 61] GPU Memory End   = 197.75 MB\n",
      "[Segment 61] GPU Peak Memory  = 198.77 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 62 ===========\n",
      "[Segment 62] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 62] Training Time = 1.35 sec\n",
      "[Segment 62] GPU Memory Start = 197.75 MB\n",
      "[Segment 62] GPU Memory End   = 197.89 MB\n",
      "[Segment 62] GPU Peak Memory  = 198.91 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 63 ===========\n",
      "[Segment 63] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 63] Training Time = 2.11 sec\n",
      "[Segment 63] GPU Memory Start = 197.89 MB\n",
      "[Segment 63] GPU Memory End   = 198.03 MB\n",
      "[Segment 63] GPU Peak Memory  = 199.05 MB\n",
      "\n",
      "============= Done =============\n",
      "\n",
      "=========== Segment 64 ===========\n",
      "[Segment 64] Batch Size Info:\n",
      "  xb per batch = 0.0103 MB, total = 6.2549 MB\n",
      "  yb per batch = 0.0029 MB, total = 1.7871 MB\n",
      "  pv per batch = 0.0010 MB, total = 0.5957 MB\n",
      "[Segment 64] Training Time = 1.78 sec\n",
      "[Segment 64] GPU Memory Start = 198.03 MB\n",
      "[Segment 64] GPU Memory End   = 198.16 MB\n",
      "[Segment 64] GPU Peak Memory  = 199.18 MB\n",
      "\n",
      "============= Done =============\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "epo = 1\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual,\n",
    "                 learning_rate, lradj, patience,\n",
    "                 save_path, attach_pv):\n",
    "        self.seq_len  = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in   = enc_in          # 채널 수\n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv    = attach_pv\n",
    "\n",
    "\n",
    "# ── 공통 Config ───────────────────────────────────────────────\n",
    "base_cfg = Configs(\n",
    "    seq_len          = 336 ,\n",
    "    pred_len         = 96,\n",
    "    enc_in           = 1,\n",
    "    individual       = True,\n",
    "    learning_rate    = 0.0005,\n",
    "    lradj            = 'type1',\n",
    "    patience         = 3,\n",
    "    save_path        = f\"./model2_ER_E{epo}_1E/\",\n",
    "    attach_pv = True\n",
    ")\n",
    "Path(base_cfg.save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "# ── 세그먼트 루프 (65개) ──────────────────────────────────────\n",
    "for seg in range(len(train_pred_segments_E1[0])):\n",
    "    print(f\"\\n=========== Segment {seg} ===========\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # GPU memory 사용량 초기화\n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    mem_start = torch.cuda.memory_allocated(device)\n",
    "\n",
    "    # ── 데이터로더 생성 (세그먼트 전용 pv) ───────────────\n",
    "    tr_pv = train_pred_segments_E1[:, seg, :, :]   # (N,P,C)\n",
    "    va_pv = val_pred_segments_E1[:,  seg, :, :]\n",
    "\n",
    "    tr_ds = TensorDataset(train_sequences, train_labels, tr_pv)\n",
    "    va_ds = TensorDataset(val_sequences,   val_labels,   va_pv)\n",
    "    tr_dl = DataLoader(tr_ds, batch_size=8, shuffle=True)\n",
    "    va_dl = DataLoader(va_ds, batch_size=8, shuffle=False)\n",
    "\n",
    "    # ── 모델·채널별 옵티마이저·ES ───────────────────────\n",
    "    model = Model(base_cfg).to(device)\n",
    "    C     = model.channels                                    # =1\n",
    "\n",
    "    opts = []\n",
    "    for c in range(C):\n",
    "        params = list(model.Linear[c].parameters())\n",
    "        opts.append(optim.Adam(params, lr=base_cfg.learning_rate))\n",
    "        path = Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{c}\"\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    active = set(range(C))            # 현재 학습 중 채널 id\n",
    "\n",
    "    # ── 학습 루프 (세그먼트별) ──────────────────────────\n",
    "    for epoch in range(1, 2):\n",
    "        if not active: break          # 모든 채널 종료 시 탈출\n",
    "\n",
    "        # ‣ Train ------------------------------------------------d\n",
    "        model.train()\n",
    "        for c in active:                              # LR decay\n",
    "            if base_cfg.lradj=='type1':\n",
    "                lr = base_cfg.learning_rate * 0.5**((epoch-1)//1)\n",
    "                for g in opts[c].param_groups: g['lr'] = lr\n",
    "\n",
    "        printed_tensor_info = False\n",
    "        \n",
    "        for xb, yb, pv in tr_dl:\n",
    "            xb, yb, pv = xb.float().to(device), yb.float().to(device), pv.float().to(device)\n",
    "\n",
    "            if not printed_tensor_info:\n",
    "                # batch 당 tensor size 계산\n",
    "                xb_size = xb.numel() * xb.element_size() / 1024**2\n",
    "                yb_size = yb.numel() * yb.element_size() / 1024**2\n",
    "                pv_size = pv.numel() * pv.element_size() / 1024**2\n",
    "\n",
    "                # ─────────────────────────────\n",
    "                # ① 전체 batch 개수 계산\n",
    "                num_batches = len(tr_dl)\n",
    "\n",
    "                # ② 전체 tensor 크기 계산\n",
    "                total_xb_MB = num_batches * xb_size\n",
    "                total_yb_MB = num_batches * yb_size\n",
    "                total_pv_MB = num_batches * pv_size\n",
    "                # ─────────────────────────────\n",
    "\n",
    "\n",
    "                print(f\"[Segment {seg}] Batch Size Info:\")\n",
    "                print(f\"  xb per batch = {xb_size:.4f} MB, total = {total_xb_MB:.4f} MB\")\n",
    "                print(f\"  yb per batch = {yb_size:.4f} MB, total = {total_yb_MB:.4f} MB\")\n",
    "                print(f\"  pv per batch = {pv_size:.4f} MB, total = {total_pv_MB:.4f} MB\")\n",
    "\n",
    "                printed_tensor_info = True\n",
    "\n",
    "\n",
    "\n",
    "            out = model(xb, pv)                       # fwd 1회\n",
    "\n",
    "            loss_list = []\n",
    "            for c in active:\n",
    "                pred = out[:, -base_cfg.pred_len:, c]\n",
    "                tgt  = yb[:, -base_cfg.pred_len:, c]\n",
    "                loss_list.append(loss_fn(pred, tgt))\n",
    "\n",
    "            total = torch.stack(loss_list).sum()\n",
    "            for opt in opts:\n",
    "                if opt: opt.zero_grad()\n",
    "            total.backward()\n",
    "            for c in active:\n",
    "                opts[c].step()\n",
    "\n",
    "        # ── 학습 시간 & 메모리 로깅 ─────────────────────────────\n",
    "    elapsed = time.time() - start_time\n",
    "    mem_end = torch.cuda.memory_allocated(device)\n",
    "    peak_mem = torch.cuda.max_memory_allocated(device)\n",
    "\n",
    "\n",
    "    print(f\"[Segment {seg}] Training Time = {elapsed:.2f} sec\")\n",
    "    print(f\"[Segment {seg}] GPU Memory Start = {mem_start/1024**2:.2f} MB\")\n",
    "    print(f\"[Segment {seg}] GPU Memory End   = {mem_end/1024**2:.2f} MB\")\n",
    "    print(f\"[Segment {seg}] GPU Peak Memory  = {peak_mem/1024**2:.2f} MB\")\n",
    "\n",
    "    print(f\"\\n============= Done =============\")\n",
    "\n",
    "    # ── seg 완료: 최종 state_dict(선택) 저장 --------------------\n",
    "    torch.save(model.state_dict(),\n",
    "                Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{c}\" / \"checkpoint.pth\")\n",
    "    del model, opts; torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b815d287",
   "metadata": {},
   "source": [
    "# 2nd Inference for Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "418acff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_segments_by_epoch = torch.load('./1st_results_ER/train_segments_by_epoch.pt', weights_only=False)\n",
    "val_segments_by_epoch = torch.load('./1st_results_ER/val_segments_by_epoch.pt', weights_only=False)\n",
    "test_segments_by_epoch = torch.load('./1st_results_ER/test_segments_by_epoch.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa3ec412",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_segments_ES = train_segments_by_epoch['ES']['train_pred_segments_EES']  # shape: (B, 65, segment_len, 1)\n",
    "train_label_segments_ES = train_segments_by_epoch['ES']['train_label_segments_EES']\n",
    "val_pred_segments_ES = val_segments_by_epoch['ES']['val_pred_segments_EES']  # shape: (B, 65, segment_len, 1)\n",
    "val_label_segments_ES = val_segments_by_epoch['ES']['val_label_segments_EES']\n",
    "test_pred_segments_ES = test_segments_by_epoch['ES']['test_pred_segments_EES']  # shape: (B, 65, segment_len, 1)\n",
    "test_label_segments_ES = test_segments_by_epoch['ES']['test_label_segments_EES']\n",
    "\n",
    "\n",
    "train_pred_segments_E1 = train_segments_by_epoch[1]['train_pred_segments_E1']  # shape: (B, 65, segment_len, 1)\n",
    "train_label_segments_E1 = train_segments_by_epoch[1]['train_label_segments_E1']\n",
    "val_pred_segments_E1 = val_segments_by_epoch[1]['val_pred_segments_E1']  # shape: (B, 65, segment_len, 1)\n",
    "val_label_segments_E1 = val_segments_by_epoch[1]['val_label_segments_E1']\n",
    "test_pred_segments_E1 = test_segments_by_epoch[1]['test_pred_segments_E1']  # shape: (B, 65, segment_len, 1)\n",
    "test_label_segments_E1 = test_segments_by_epoch[1]['test_label_segments_E1']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c846adf",
   "metadata": {},
   "source": [
    "## ES->1E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03df0215",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "595173ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual,\n",
    "                 learning_rate, lradj, patience,\n",
    "                 save_path, attach_pv):\n",
    "        self.seq_len  = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in   = enc_in          # 채널 수\n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv    = attach_pv\n",
    "\n",
    "\n",
    "# ── 공통 Config ───────────────────────────────────────────────\n",
    "base_cfg = Configs(\n",
    "    pred_len         = 96,\n",
    "    seq_len          = 336 ,\n",
    "    enc_in           = 1,\n",
    "    individual       = True,\n",
    "    learning_rate    = 0.0005,\n",
    "    lradj            = 'type1',\n",
    "    patience         = 3,\n",
    "    save_path        = \"./model2_ER_EES_1E\",\n",
    "    attach_pv  = True,\n",
    "\n",
    ")\n",
    "Path(base_cfg.save_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8958f5",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d226ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "―――― Inference  |  Segment 0 ――――\n",
      "  seg0-ch0  MSE:0.316741406917572  MAE:0.43975862860679626\n",
      "▶ seg0  mean  MSE:0.316741406917572  MAE:0.43975862860679626\n",
      "\n",
      "―――― Inference  |  Segment 1 ――――\n",
      "  seg1-ch0  MSE:0.23960784077644348  MAE:0.38832491636276245\n",
      "▶ seg1  mean  MSE:0.23960784077644348  MAE:0.38832491636276245\n",
      "\n",
      "―――― Inference  |  Segment 2 ――――\n",
      "  seg2-ch0  MSE:0.24296164512634277  MAE:0.39656826853752136\n",
      "▶ seg2  mean  MSE:0.24296164512634277  MAE:0.39656826853752136\n",
      "\n",
      "―――― Inference  |  Segment 3 ――――\n",
      "  seg3-ch0  MSE:0.44119352102279663  MAE:0.5201039910316467\n",
      "▶ seg3  mean  MSE:0.44119352102279663  MAE:0.5201039910316467\n",
      "\n",
      "―――― Inference  |  Segment 4 ――――\n",
      "  seg4-ch0  MSE:0.2359120100736618  MAE:0.3806155323982239\n",
      "▶ seg4  mean  MSE:0.2359120100736618  MAE:0.3806155323982239\n",
      "\n",
      "―――― Inference  |  Segment 5 ――――\n",
      "  seg5-ch0  MSE:0.21146160364151  MAE:0.35858890414237976\n",
      "▶ seg5  mean  MSE:0.21146160364151  MAE:0.35858890414237976\n",
      "\n",
      "―――― Inference  |  Segment 6 ――――\n",
      "  seg6-ch0  MSE:0.25045013427734375  MAE:0.3889952003955841\n",
      "▶ seg6  mean  MSE:0.25045013427734375  MAE:0.3889952003955841\n",
      "\n",
      "―――― Inference  |  Segment 7 ――――\n",
      "  seg7-ch0  MSE:0.2367774248123169  MAE:0.38190558552742004\n",
      "▶ seg7  mean  MSE:0.2367774248123169  MAE:0.38190558552742004\n",
      "\n",
      "―――― Inference  |  Segment 8 ――――\n",
      "  seg8-ch0  MSE:0.28476765751838684  MAE:0.4160895049571991\n",
      "▶ seg8  mean  MSE:0.28476765751838684  MAE:0.4160895049571991\n",
      "\n",
      "―――― Inference  |  Segment 9 ――――\n",
      "  seg9-ch0  MSE:0.25251075625419617  MAE:0.395760715007782\n",
      "▶ seg9  mean  MSE:0.25251075625419617  MAE:0.395760715007782\n",
      "\n",
      "―――― Inference  |  Segment 10 ――――\n",
      "  seg10-ch0  MSE:0.25014591217041016  MAE:0.3946174085140228\n",
      "▶ seg10  mean  MSE:0.25014591217041016  MAE:0.3946174085140228\n",
      "\n",
      "―――― Inference  |  Segment 11 ――――\n",
      "  seg11-ch0  MSE:0.28731152415275574  MAE:0.41705048084259033\n",
      "▶ seg11  mean  MSE:0.28731152415275574  MAE:0.41705048084259033\n",
      "\n",
      "―――― Inference  |  Segment 12 ――――\n",
      "  seg12-ch0  MSE:0.2813493609428406  MAE:0.4173608720302582\n",
      "▶ seg12  mean  MSE:0.2813493609428406  MAE:0.4173608720302582\n",
      "\n",
      "―――― Inference  |  Segment 13 ――――\n",
      "  seg13-ch0  MSE:0.2504994571208954  MAE:0.3893878757953644\n",
      "▶ seg13  mean  MSE:0.2504994571208954  MAE:0.3893878757953644\n",
      "\n",
      "―――― Inference  |  Segment 14 ――――\n",
      "  seg14-ch0  MSE:0.2255237102508545  MAE:0.3732822835445404\n",
      "▶ seg14  mean  MSE:0.2255237102508545  MAE:0.3732822835445404\n",
      "\n",
      "―――― Inference  |  Segment 15 ――――\n",
      "  seg15-ch0  MSE:0.2507062554359436  MAE:0.3924001455307007\n",
      "▶ seg15  mean  MSE:0.2507062554359436  MAE:0.3924001455307007\n",
      "\n",
      "―――― Inference  |  Segment 16 ――――\n",
      "  seg16-ch0  MSE:0.24414590001106262  MAE:0.38724473118782043\n",
      "▶ seg16  mean  MSE:0.24414590001106262  MAE:0.38724473118782043\n",
      "\n",
      "―――― Inference  |  Segment 17 ――――\n",
      "  seg17-ch0  MSE:0.32352787256240845  MAE:0.4427725672721863\n",
      "▶ seg17  mean  MSE:0.32352787256240845  MAE:0.4427725672721863\n",
      "\n",
      "―――― Inference  |  Segment 18 ――――\n",
      "  seg18-ch0  MSE:0.264310747385025  MAE:0.40510714054107666\n",
      "▶ seg18  mean  MSE:0.264310747385025  MAE:0.40510714054107666\n",
      "\n",
      "―――― Inference  |  Segment 19 ――――\n",
      "  seg19-ch0  MSE:0.22376275062561035  MAE:0.37169334292411804\n",
      "▶ seg19  mean  MSE:0.22376275062561035  MAE:0.37169334292411804\n",
      "\n",
      "―――― Inference  |  Segment 20 ――――\n",
      "  seg20-ch0  MSE:0.4090054929256439  MAE:0.49440544843673706\n",
      "▶ seg20  mean  MSE:0.4090054929256439  MAE:0.49440544843673706\n",
      "\n",
      "―――― Inference  |  Segment 21 ――――\n",
      "  seg21-ch0  MSE:0.23410184681415558  MAE:0.3839093744754791\n",
      "▶ seg21  mean  MSE:0.23410184681415558  MAE:0.3839093744754791\n",
      "\n",
      "―――― Inference  |  Segment 22 ――――\n",
      "  seg22-ch0  MSE:0.2578687369823456  MAE:0.40162989497184753\n",
      "▶ seg22  mean  MSE:0.2578687369823456  MAE:0.40162989497184753\n",
      "\n",
      "―――― Inference  |  Segment 23 ――――\n",
      "  seg23-ch0  MSE:0.23504287004470825  MAE:0.37627139687538147\n",
      "▶ seg23  mean  MSE:0.23504287004470825  MAE:0.37627139687538147\n",
      "\n",
      "―――― Inference  |  Segment 24 ――――\n",
      "  seg24-ch0  MSE:0.21882586181163788  MAE:0.3656647205352783\n",
      "▶ seg24  mean  MSE:0.21882586181163788  MAE:0.3656647205352783\n",
      "\n",
      "―――― Inference  |  Segment 25 ――――\n",
      "  seg25-ch0  MSE:0.26795753836631775  MAE:0.4110826849937439\n",
      "▶ seg25  mean  MSE:0.26795753836631775  MAE:0.4110826849937439\n",
      "\n",
      "―――― Inference  |  Segment 26 ――――\n",
      "  seg26-ch0  MSE:0.2920807898044586  MAE:0.41836148500442505\n",
      "▶ seg26  mean  MSE:0.2920807898044586  MAE:0.41836148500442505\n",
      "\n",
      "―――― Inference  |  Segment 27 ――――\n",
      "  seg27-ch0  MSE:0.28819510340690613  MAE:0.41375261545181274\n",
      "▶ seg27  mean  MSE:0.28819510340690613  MAE:0.41375261545181274\n",
      "\n",
      "―――― Inference  |  Segment 28 ――――\n",
      "  seg28-ch0  MSE:0.35638123750686646  MAE:0.46103012561798096\n",
      "▶ seg28  mean  MSE:0.35638123750686646  MAE:0.46103012561798096\n",
      "\n",
      "―――― Inference  |  Segment 29 ――――\n",
      "  seg29-ch0  MSE:0.2162691354751587  MAE:0.3626832664012909\n",
      "▶ seg29  mean  MSE:0.2162691354751587  MAE:0.3626832664012909\n",
      "\n",
      "―――― Inference  |  Segment 30 ――――\n",
      "  seg30-ch0  MSE:0.3980448246002197  MAE:0.4912068247795105\n",
      "▶ seg30  mean  MSE:0.3980448246002197  MAE:0.4912068247795105\n",
      "\n",
      "―――― Inference  |  Segment 31 ――――\n",
      "  seg31-ch0  MSE:0.37465041875839233  MAE:0.48742803931236267\n",
      "▶ seg31  mean  MSE:0.37465041875839233  MAE:0.48742803931236267\n",
      "\n",
      "―――― Inference  |  Segment 32 ――――\n",
      "  seg32-ch0  MSE:0.2464720755815506  MAE:0.3913961946964264\n",
      "▶ seg32  mean  MSE:0.2464720755815506  MAE:0.3913961946964264\n",
      "\n",
      "―――― Inference  |  Segment 33 ――――\n",
      "  seg33-ch0  MSE:0.27249255776405334  MAE:0.4078700542449951\n",
      "▶ seg33  mean  MSE:0.27249255776405334  MAE:0.4078700542449951\n",
      "\n",
      "―――― Inference  |  Segment 34 ――――\n",
      "  seg34-ch0  MSE:0.3606478273868561  MAE:0.4729738235473633\n",
      "▶ seg34  mean  MSE:0.3606478273868561  MAE:0.4729738235473633\n",
      "\n",
      "―――― Inference  |  Segment 35 ――――\n",
      "  seg35-ch0  MSE:0.3317861258983612  MAE:0.45630964636802673\n",
      "▶ seg35  mean  MSE:0.3317861258983612  MAE:0.45630964636802673\n",
      "\n",
      "―――― Inference  |  Segment 36 ――――\n",
      "  seg36-ch0  MSE:0.2229105532169342  MAE:0.3694486618041992\n",
      "▶ seg36  mean  MSE:0.2229105532169342  MAE:0.3694486618041992\n",
      "\n",
      "―――― Inference  |  Segment 37 ――――\n",
      "  seg37-ch0  MSE:0.267513245344162  MAE:0.40689951181411743\n",
      "▶ seg37  mean  MSE:0.267513245344162  MAE:0.40689951181411743\n",
      "\n",
      "―――― Inference  |  Segment 38 ――――\n",
      "  seg38-ch0  MSE:0.24801339209079742  MAE:0.3907329738140106\n",
      "▶ seg38  mean  MSE:0.24801339209079742  MAE:0.3907329738140106\n",
      "\n",
      "―――― Inference  |  Segment 39 ――――\n",
      "  seg39-ch0  MSE:0.224821999669075  MAE:0.37076184153556824\n",
      "▶ seg39  mean  MSE:0.224821999669075  MAE:0.37076184153556824\n",
      "\n",
      "―――― Inference  |  Segment 40 ――――\n",
      "  seg40-ch0  MSE:0.2448660433292389  MAE:0.38571053743362427\n",
      "▶ seg40  mean  MSE:0.2448660433292389  MAE:0.38571053743362427\n",
      "\n",
      "―――― Inference  |  Segment 41 ――――\n",
      "  seg41-ch0  MSE:0.29364681243896484  MAE:0.4231986105442047\n",
      "▶ seg41  mean  MSE:0.29364681243896484  MAE:0.4231986105442047\n",
      "\n",
      "―――― Inference  |  Segment 42 ――――\n",
      "  seg42-ch0  MSE:0.22288082540035248  MAE:0.36244961619377136\n",
      "▶ seg42  mean  MSE:0.22288082540035248  MAE:0.36244961619377136\n",
      "\n",
      "―――― Inference  |  Segment 43 ――――\n",
      "  seg43-ch0  MSE:0.2673242688179016  MAE:0.4032963514328003\n",
      "▶ seg43  mean  MSE:0.2673242688179016  MAE:0.4032963514328003\n",
      "\n",
      "―――― Inference  |  Segment 44 ――――\n",
      "  seg44-ch0  MSE:0.39857029914855957  MAE:0.48820069432258606\n",
      "▶ seg44  mean  MSE:0.39857029914855957  MAE:0.48820069432258606\n",
      "\n",
      "―――― Inference  |  Segment 45 ――――\n",
      "  seg45-ch0  MSE:0.24412943422794342  MAE:0.3901103138923645\n",
      "▶ seg45  mean  MSE:0.24412943422794342  MAE:0.3901103138923645\n",
      "\n",
      "―――― Inference  |  Segment 46 ――――\n",
      "  seg46-ch0  MSE:0.231695294380188  MAE:0.3782846927642822\n",
      "▶ seg46  mean  MSE:0.231695294380188  MAE:0.3782846927642822\n",
      "\n",
      "―――― Inference  |  Segment 47 ――――\n",
      "  seg47-ch0  MSE:0.23004958033561707  MAE:0.37594279646873474\n",
      "▶ seg47  mean  MSE:0.23004958033561707  MAE:0.37594279646873474\n",
      "\n",
      "―――― Inference  |  Segment 48 ――――\n",
      "  seg48-ch0  MSE:0.23141583800315857  MAE:0.37405577301979065\n",
      "▶ seg48  mean  MSE:0.23141583800315857  MAE:0.37405577301979065\n",
      "\n",
      "―――― Inference  |  Segment 49 ――――\n",
      "  seg49-ch0  MSE:0.5225183367729187  MAE:0.5574589967727661\n",
      "▶ seg49  mean  MSE:0.5225183367729187  MAE:0.5574589967727661\n",
      "\n",
      "―――― Inference  |  Segment 50 ――――\n",
      "  seg50-ch0  MSE:0.2703065872192383  MAE:0.41086554527282715\n",
      "▶ seg50  mean  MSE:0.2703065872192383  MAE:0.41086554527282715\n",
      "\n",
      "―――― Inference  |  Segment 51 ――――\n",
      "  seg51-ch0  MSE:0.2741337716579437  MAE:0.4092889726161957\n",
      "▶ seg51  mean  MSE:0.2741337716579437  MAE:0.4092889726161957\n",
      "\n",
      "―――― Inference  |  Segment 52 ――――\n",
      "  seg52-ch0  MSE:0.2463051825761795  MAE:0.3891528844833374\n",
      "▶ seg52  mean  MSE:0.2463051825761795  MAE:0.3891528844833374\n",
      "\n",
      "―――― Inference  |  Segment 53 ――――\n",
      "  seg53-ch0  MSE:0.21880319714546204  MAE:0.36569294333457947\n",
      "▶ seg53  mean  MSE:0.21880319714546204  MAE:0.36569294333457947\n",
      "\n",
      "―――― Inference  |  Segment 54 ――――\n",
      "  seg54-ch0  MSE:0.26934540271759033  MAE:0.4061691164970398\n",
      "▶ seg54  mean  MSE:0.26934540271759033  MAE:0.4061691164970398\n",
      "\n",
      "―――― Inference  |  Segment 55 ――――\n",
      "  seg55-ch0  MSE:0.23808763921260834  MAE:0.3858787715435028\n",
      "▶ seg55  mean  MSE:0.23808763921260834  MAE:0.3858787715435028\n",
      "\n",
      "―――― Inference  |  Segment 56 ――――\n",
      "  seg56-ch0  MSE:0.23910994827747345  MAE:0.3830045759677887\n",
      "▶ seg56  mean  MSE:0.23910994827747345  MAE:0.3830045759677887\n",
      "\n",
      "―――― Inference  |  Segment 57 ――――\n",
      "  seg57-ch0  MSE:0.22142885625362396  MAE:0.36485329270362854\n",
      "▶ seg57  mean  MSE:0.22142885625362396  MAE:0.36485329270362854\n",
      "\n",
      "―――― Inference  |  Segment 58 ――――\n",
      "  seg58-ch0  MSE:0.2458445131778717  MAE:0.3858720362186432\n",
      "▶ seg58  mean  MSE:0.2458445131778717  MAE:0.3858720362186432\n",
      "\n",
      "―――― Inference  |  Segment 59 ――――\n",
      "  seg59-ch0  MSE:0.2710023820400238  MAE:0.4136901795864105\n",
      "▶ seg59  mean  MSE:0.2710023820400238  MAE:0.4136901795864105\n",
      "\n",
      "―――― Inference  |  Segment 60 ――――\n",
      "  seg60-ch0  MSE:0.3423105478286743  MAE:0.4697096049785614\n",
      "▶ seg60  mean  MSE:0.3423105478286743  MAE:0.4697096049785614\n",
      "\n",
      "―――― Inference  |  Segment 61 ――――\n",
      "  seg61-ch0  MSE:0.2344871461391449  MAE:0.3789660930633545\n",
      "▶ seg61  mean  MSE:0.2344871461391449  MAE:0.3789660930633545\n",
      "\n",
      "―――― Inference  |  Segment 62 ――――\n",
      "  seg62-ch0  MSE:0.2401002198457718  MAE:0.38429129123687744\n",
      "▶ seg62  mean  MSE:0.2401002198457718  MAE:0.38429129123687744\n",
      "\n",
      "―――― Inference  |  Segment 63 ――――\n",
      "  seg63-ch0  MSE:0.2658997178077698  MAE:0.3973332941532135\n",
      "▶ seg63  mean  MSE:0.2658997178077698  MAE:0.3973332941532135\n",
      "\n",
      "―――― Inference  |  Segment 64 ――――\n",
      "  seg64-ch0  MSE:0.3299576938152313  MAE:0.44835925102233887\n",
      "▶ seg64  mean  MSE:0.3299576938152313  MAE:0.44835925102233887\n",
      "\n",
      "seg10 ch0 MSE : 0.2501459\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import r2_score\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "C        = 1                                # 채널 수\n",
    "P        = base_cfg.pred_len                # 96\n",
    "seg_cnt  = 65\n",
    "batch_sz = 8\n",
    "\n",
    "results2_ER_ES_val_1E = {}  # 수정 x3   # {seg: { 'pred':(N,P,C), 'true':(N,P,C), 'metrics':{ch:(mse,mae,r2)} } }\n",
    "\n",
    "for seg in range(seg_cnt):\n",
    "    print(f\"\\n―――― Inference  |  Segment {seg} ――――\")\n",
    "\n",
    "    # ── 세그먼트 전용 DataLoader (pv 포함) ─────────────────────\n",
    "    pv = val_pred_segments_ES[:, seg, :, :]         # 수정         # (N,P,C)\n",
    "    ds = TensorDataset(val_sequences, val_labels, pv) # 수정\n",
    "    dl = DataLoader(ds, batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "    # ── 예측 컨테이너 ────────────────────────────────────────\n",
    "    pred_ch, true_ch, metrics = [], [], {}\n",
    "\n",
    "    # ── 채널 루프 ────────────────────────────────────────────\n",
    "    for ch in range(C):\n",
    "        ckpt = Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{ch}\" / \"checkpoint.pth\"\n",
    "        if not ckpt.exists():\n",
    "            print(f\"[Warn] seg{seg}-ch{ch} ckpt 없음 → skip\");  continue\n",
    "\n",
    "        # ① 모델 생성 & ckpt 로드\n",
    "        model = Model(base_cfg).to(device)\n",
    "        model.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        preds, trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, pv_batch in dl:                 # xb:[B,S,C], yb:[B,P,C]\n",
    "                xb  = xb.float().to(device)\n",
    "                yb  = yb.float()      \n",
    "                pv_ = pv_batch.float().to(device)\n",
    "\n",
    "                out = model(xb, pv_)                     # [B,P,C]\n",
    "                preds.append(out[:, -P:, ch].cpu())\n",
    "                trues.append(yb[:, -P:, ch])\n",
    "\n",
    "        preds = torch.cat(preds, 0)     \n",
    "        trues = torch.cat(trues, 0)\n",
    "        pred_ch.append(preds)\n",
    "        true_ch.append(trues)\n",
    "\n",
    "        # ② 지표\n",
    "        p, t = preds.reshape(-1).cpu().numpy(), trues.reshape(-1).cpu().numpy()\n",
    "        mse  = np.mean((p - t)**2)\n",
    "        mae  = np.mean(np.abs(p - t))\n",
    "        metrics[ch] = (mse, mae)\n",
    "\n",
    "        print(f\"  seg{seg}-ch{ch}  MSE:{mse}  MAE:{mae}\")\n",
    "\n",
    "        del model; torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "    pred_all = torch.stack(pred_ch,  dim=2)   # (N,P,C)\n",
    "    true_all = torch.stack(true_ch,  dim=2)\n",
    "\n",
    "    # 세그먼트별 평균 지표\n",
    "    mse_avg = np.mean([m for m,_ in metrics.values()])\n",
    "    mae_avg = np.mean([a for _,a in metrics.values()])\n",
    "    print(f\"▶ seg{seg}  mean  MSE:{mse_avg}  MAE:{mae_avg}\")\n",
    "\n",
    "    # 저장(메모리)\n",
    "    results2_ER_ES_val_1E[seg] = {\n",
    "        \"pred2_ES_val_1E\"    : pred_all,   # 수정    # (N,P,C) tensor\n",
    "        \"true2_ES_val_1E\"    : true_all,   # 수정\n",
    "        \"metrics2_ES_val_1E\" : metrics     # 수정           # {ch:(mse,mae,r2)}\n",
    "    }\n",
    "\n",
    "\n",
    "seg10_ch0_mse = results2_ER_ES_val_1E[10][\"metrics2_ES_val_1E\"][0][0]\n",
    "print(\"\\nseg10 ch0 MSE :\", seg10_ch0_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c356a91",
   "metadata": {},
   "source": [
    "## 1E->1E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50f45cb",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a43ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual,\n",
    "                 learning_rate, lradj, patience,\n",
    "                 save_path, attach_pv):\n",
    "        self.seq_len  = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in   = enc_in          # 채널 수\n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv    = attach_pv\n",
    "\n",
    "\n",
    "# ── 공통 Config ───────────────────────────────────────────────\n",
    "base_cfg = Configs(\n",
    "    pred_len         = 96,\n",
    "    seq_len          = 336 ,\n",
    "    enc_in           = 1,\n",
    "    individual       = True,\n",
    "    learning_rate    = 0.0005,\n",
    "    lradj            = 'type1',\n",
    "    patience         = 3,\n",
    "    save_path        = \"./model2_ER_E1_1E\",\n",
    "    attach_pv  = True,\n",
    "\n",
    ")\n",
    "Path(base_cfg.save_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc13a794",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a083892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "―――― Inference  |  Segment 0 ――――\n",
      "  seg0-ch0  MSE:0.31565213203430176  MAE:0.43641915917396545\n",
      "▶ seg0  mean  MSE:0.31565213203430176  MAE:0.43641915917396545\n",
      "\n",
      "―――― Inference  |  Segment 1 ――――\n",
      "  seg1-ch0  MSE:0.2538796067237854  MAE:0.3942962884902954\n",
      "▶ seg1  mean  MSE:0.2538796067237854  MAE:0.3942962884902954\n",
      "\n",
      "―――― Inference  |  Segment 2 ――――\n",
      "  seg2-ch0  MSE:0.21912875771522522  MAE:0.3621671199798584\n",
      "▶ seg2  mean  MSE:0.21912875771522522  MAE:0.3621671199798584\n",
      "\n",
      "―――― Inference  |  Segment 3 ――――\n",
      "  seg3-ch0  MSE:0.42152124643325806  MAE:0.5196309089660645\n",
      "▶ seg3  mean  MSE:0.42152124643325806  MAE:0.5196309089660645\n",
      "\n",
      "―――― Inference  |  Segment 4 ――――\n",
      "  seg4-ch0  MSE:0.2903937101364136  MAE:0.4313209354877472\n",
      "▶ seg4  mean  MSE:0.2903937101364136  MAE:0.4313209354877472\n",
      "\n",
      "―――― Inference  |  Segment 5 ――――\n",
      "  seg5-ch0  MSE:0.2247549593448639  MAE:0.3736395835876465\n",
      "▶ seg5  mean  MSE:0.2247549593448639  MAE:0.3736395835876465\n",
      "\n",
      "―――― Inference  |  Segment 6 ――――\n",
      "  seg6-ch0  MSE:0.2432183176279068  MAE:0.39133697748184204\n",
      "▶ seg6  mean  MSE:0.2432183176279068  MAE:0.39133697748184204\n",
      "\n",
      "―――― Inference  |  Segment 7 ――――\n",
      "  seg7-ch0  MSE:0.26569631695747375  MAE:0.41026443243026733\n",
      "▶ seg7  mean  MSE:0.26569631695747375  MAE:0.41026443243026733\n",
      "\n",
      "―――― Inference  |  Segment 8 ――――\n",
      "  seg8-ch0  MSE:0.3207738399505615  MAE:0.44145098328590393\n",
      "▶ seg8  mean  MSE:0.3207738399505615  MAE:0.44145098328590393\n",
      "\n",
      "―――― Inference  |  Segment 9 ――――\n",
      "  seg9-ch0  MSE:0.3013100028038025  MAE:0.43311807513237\n",
      "▶ seg9  mean  MSE:0.3013100028038025  MAE:0.43311807513237\n",
      "\n",
      "―――― Inference  |  Segment 10 ――――\n",
      "  seg10-ch0  MSE:0.24713070690631866  MAE:0.3906259834766388\n",
      "▶ seg10  mean  MSE:0.24713070690631866  MAE:0.3906259834766388\n",
      "\n",
      "―――― Inference  |  Segment 11 ――――\n",
      "  seg11-ch0  MSE:0.3479960858821869  MAE:0.4558228552341461\n",
      "▶ seg11  mean  MSE:0.3479960858821869  MAE:0.4558228552341461\n",
      "\n",
      "―――― Inference  |  Segment 12 ――――\n",
      "  seg12-ch0  MSE:0.30337661504745483  MAE:0.43583953380584717\n",
      "▶ seg12  mean  MSE:0.30337661504745483  MAE:0.43583953380584717\n",
      "\n",
      "―――― Inference  |  Segment 13 ――――\n",
      "  seg13-ch0  MSE:0.2462870180606842  MAE:0.3960486054420471\n",
      "▶ seg13  mean  MSE:0.2462870180606842  MAE:0.3960486054420471\n",
      "\n",
      "―――― Inference  |  Segment 14 ――――\n",
      "  seg14-ch0  MSE:0.4531223475933075  MAE:0.5297904014587402\n",
      "▶ seg14  mean  MSE:0.4531223475933075  MAE:0.5297904014587402\n",
      "\n",
      "―――― Inference  |  Segment 15 ――――\n",
      "  seg15-ch0  MSE:0.3764001727104187  MAE:0.4818565845489502\n",
      "▶ seg15  mean  MSE:0.3764001727104187  MAE:0.4818565845489502\n",
      "\n",
      "―――― Inference  |  Segment 16 ――――\n",
      "  seg16-ch0  MSE:0.26582416892051697  MAE:0.4049105644226074\n",
      "▶ seg16  mean  MSE:0.26582416892051697  MAE:0.4049105644226074\n",
      "\n",
      "―――― Inference  |  Segment 17 ――――\n",
      "  seg17-ch0  MSE:0.28152045607566833  MAE:0.41597670316696167\n",
      "▶ seg17  mean  MSE:0.28152045607566833  MAE:0.41597670316696167\n",
      "\n",
      "―――― Inference  |  Segment 18 ――――\n",
      "  seg18-ch0  MSE:0.27466917037963867  MAE:0.4111660420894623\n",
      "▶ seg18  mean  MSE:0.27466917037963867  MAE:0.4111660420894623\n",
      "\n",
      "―――― Inference  |  Segment 19 ――――\n",
      "  seg19-ch0  MSE:0.3184032142162323  MAE:0.4426176846027374\n",
      "▶ seg19  mean  MSE:0.3184032142162323  MAE:0.4426176846027374\n",
      "\n",
      "―――― Inference  |  Segment 20 ――――\n",
      "  seg20-ch0  MSE:0.4501611590385437  MAE:0.525222659111023\n",
      "▶ seg20  mean  MSE:0.4501611590385437  MAE:0.525222659111023\n",
      "\n",
      "―――― Inference  |  Segment 21 ――――\n",
      "  seg21-ch0  MSE:0.22297917306423187  MAE:0.3631019592285156\n",
      "▶ seg21  mean  MSE:0.22297917306423187  MAE:0.3631019592285156\n",
      "\n",
      "―――― Inference  |  Segment 22 ――――\n",
      "  seg22-ch0  MSE:0.2660917639732361  MAE:0.40636909008026123\n",
      "▶ seg22  mean  MSE:0.2660917639732361  MAE:0.40636909008026123\n",
      "\n",
      "―――― Inference  |  Segment 23 ――――\n",
      "  seg23-ch0  MSE:0.3319571614265442  MAE:0.45451223850250244\n",
      "▶ seg23  mean  MSE:0.3319571614265442  MAE:0.45451223850250244\n",
      "\n",
      "―――― Inference  |  Segment 24 ――――\n",
      "  seg24-ch0  MSE:0.34389209747314453  MAE:0.45666706562042236\n",
      "▶ seg24  mean  MSE:0.34389209747314453  MAE:0.45666706562042236\n",
      "\n",
      "―――― Inference  |  Segment 25 ――――\n",
      "  seg25-ch0  MSE:0.22585086524486542  MAE:0.37132731080055237\n",
      "▶ seg25  mean  MSE:0.22585086524486542  MAE:0.37132731080055237\n",
      "\n",
      "―――― Inference  |  Segment 26 ――――\n",
      "  seg26-ch0  MSE:0.3505411148071289  MAE:0.47178441286087036\n",
      "▶ seg26  mean  MSE:0.3505411148071289  MAE:0.47178441286087036\n",
      "\n",
      "―――― Inference  |  Segment 27 ――――\n",
      "  seg27-ch0  MSE:0.25788867473602295  MAE:0.4014447033405304\n",
      "▶ seg27  mean  MSE:0.25788867473602295  MAE:0.4014447033405304\n",
      "\n",
      "―――― Inference  |  Segment 28 ――――\n",
      "  seg28-ch0  MSE:0.2264837771654129  MAE:0.3780979812145233\n",
      "▶ seg28  mean  MSE:0.2264837771654129  MAE:0.3780979812145233\n",
      "\n",
      "―――― Inference  |  Segment 29 ――――\n",
      "  seg29-ch0  MSE:0.3397718667984009  MAE:0.4632314145565033\n",
      "▶ seg29  mean  MSE:0.3397718667984009  MAE:0.4632314145565033\n",
      "\n",
      "―――― Inference  |  Segment 30 ――――\n",
      "  seg30-ch0  MSE:0.3739110231399536  MAE:0.48152726888656616\n",
      "▶ seg30  mean  MSE:0.3739110231399536  MAE:0.48152726888656616\n",
      "\n",
      "―――― Inference  |  Segment 31 ――――\n",
      "  seg31-ch0  MSE:0.2547086179256439  MAE:0.39424678683280945\n",
      "▶ seg31  mean  MSE:0.2547086179256439  MAE:0.39424678683280945\n",
      "\n",
      "―――― Inference  |  Segment 32 ――――\n",
      "  seg32-ch0  MSE:0.25474783778190613  MAE:0.40214455127716064\n",
      "▶ seg32  mean  MSE:0.25474783778190613  MAE:0.40214455127716064\n",
      "\n",
      "―――― Inference  |  Segment 33 ――――\n",
      "  seg33-ch0  MSE:0.22333580255508423  MAE:0.37212279438972473\n",
      "▶ seg33  mean  MSE:0.22333580255508423  MAE:0.37212279438972473\n",
      "\n",
      "―――― Inference  |  Segment 34 ――――\n",
      "  seg34-ch0  MSE:0.23000013828277588  MAE:0.3784836530685425\n",
      "▶ seg34  mean  MSE:0.23000013828277588  MAE:0.3784836530685425\n",
      "\n",
      "―――― Inference  |  Segment 35 ――――\n",
      "  seg35-ch0  MSE:0.24035662412643433  MAE:0.3827268183231354\n",
      "▶ seg35  mean  MSE:0.24035662412643433  MAE:0.3827268183231354\n",
      "\n",
      "―――― Inference  |  Segment 36 ――――\n",
      "  seg36-ch0  MSE:0.44005247950553894  MAE:0.5126143097877502\n",
      "▶ seg36  mean  MSE:0.44005247950553894  MAE:0.5126143097877502\n",
      "\n",
      "―――― Inference  |  Segment 37 ――――\n",
      "  seg37-ch0  MSE:0.28787410259246826  MAE:0.4215666651725769\n",
      "▶ seg37  mean  MSE:0.28787410259246826  MAE:0.4215666651725769\n",
      "\n",
      "―――― Inference  |  Segment 38 ――――\n",
      "  seg38-ch0  MSE:0.3449592590332031  MAE:0.4584161043167114\n",
      "▶ seg38  mean  MSE:0.3449592590332031  MAE:0.4584161043167114\n",
      "\n",
      "―――― Inference  |  Segment 39 ――――\n",
      "  seg39-ch0  MSE:0.2519199550151825  MAE:0.3946957290172577\n",
      "▶ seg39  mean  MSE:0.2519199550151825  MAE:0.3946957290172577\n",
      "\n",
      "―――― Inference  |  Segment 40 ――――\n",
      "  seg40-ch0  MSE:0.22291190922260284  MAE:0.36821338534355164\n",
      "▶ seg40  mean  MSE:0.22291190922260284  MAE:0.36821338534355164\n",
      "\n",
      "―――― Inference  |  Segment 41 ――――\n",
      "  seg41-ch0  MSE:0.22678162157535553  MAE:0.3701850473880768\n",
      "▶ seg41  mean  MSE:0.22678162157535553  MAE:0.3701850473880768\n",
      "\n",
      "―――― Inference  |  Segment 42 ――――\n",
      "  seg42-ch0  MSE:0.22067035734653473  MAE:0.3686893582344055\n",
      "▶ seg42  mean  MSE:0.22067035734653473  MAE:0.3686893582344055\n",
      "\n",
      "―――― Inference  |  Segment 43 ――――\n",
      "  seg43-ch0  MSE:0.23483648896217346  MAE:0.38140803575515747\n",
      "▶ seg43  mean  MSE:0.23483648896217346  MAE:0.38140803575515747\n",
      "\n",
      "―――― Inference  |  Segment 44 ――――\n",
      "  seg44-ch0  MSE:0.23396195471286774  MAE:0.37128108739852905\n",
      "▶ seg44  mean  MSE:0.23396195471286774  MAE:0.37128108739852905\n",
      "\n",
      "―――― Inference  |  Segment 45 ――――\n",
      "  seg45-ch0  MSE:0.2208753526210785  MAE:0.36961251497268677\n",
      "▶ seg45  mean  MSE:0.2208753526210785  MAE:0.36961251497268677\n",
      "\n",
      "―――― Inference  |  Segment 46 ――――\n",
      "  seg46-ch0  MSE:0.22276431322097778  MAE:0.37017881870269775\n",
      "▶ seg46  mean  MSE:0.22276431322097778  MAE:0.37017881870269775\n",
      "\n",
      "―――― Inference  |  Segment 47 ――――\n",
      "  seg47-ch0  MSE:0.2231297343969345  MAE:0.3681325614452362\n",
      "▶ seg47  mean  MSE:0.2231297343969345  MAE:0.3681325614452362\n",
      "\n",
      "―――― Inference  |  Segment 48 ――――\n",
      "  seg48-ch0  MSE:0.2543591856956482  MAE:0.39445561170578003\n",
      "▶ seg48  mean  MSE:0.2543591856956482  MAE:0.39445561170578003\n",
      "\n",
      "―――― Inference  |  Segment 49 ――――\n",
      "  seg49-ch0  MSE:0.2500881254673004  MAE:0.39188703894615173\n",
      "▶ seg49  mean  MSE:0.2500881254673004  MAE:0.39188703894615173\n",
      "\n",
      "―――― Inference  |  Segment 50 ――――\n",
      "  seg50-ch0  MSE:0.2784976661205292  MAE:0.41232866048812866\n",
      "▶ seg50  mean  MSE:0.2784976661205292  MAE:0.41232866048812866\n",
      "\n",
      "―――― Inference  |  Segment 51 ――――\n",
      "  seg51-ch0  MSE:0.2553989291191101  MAE:0.3934001326560974\n",
      "▶ seg51  mean  MSE:0.2553989291191101  MAE:0.3934001326560974\n",
      "\n",
      "―――― Inference  |  Segment 52 ――――\n",
      "  seg52-ch0  MSE:0.29057011008262634  MAE:0.41766130924224854\n",
      "▶ seg52  mean  MSE:0.29057011008262634  MAE:0.41766130924224854\n",
      "\n",
      "―――― Inference  |  Segment 53 ――――\n",
      "  seg53-ch0  MSE:0.21895861625671387  MAE:0.36718156933784485\n",
      "▶ seg53  mean  MSE:0.21895861625671387  MAE:0.36718156933784485\n",
      "\n",
      "―――― Inference  |  Segment 54 ――――\n",
      "  seg54-ch0  MSE:0.26220935583114624  MAE:0.41526883840560913\n",
      "▶ seg54  mean  MSE:0.26220935583114624  MAE:0.41526883840560913\n",
      "\n",
      "―――― Inference  |  Segment 55 ――――\n",
      "  seg55-ch0  MSE:0.42543715238571167  MAE:0.5278720259666443\n",
      "▶ seg55  mean  MSE:0.42543715238571167  MAE:0.5278720259666443\n",
      "\n",
      "―――― Inference  |  Segment 56 ――――\n",
      "  seg56-ch0  MSE:0.2212626338005066  MAE:0.3634530007839203\n",
      "▶ seg56  mean  MSE:0.2212626338005066  MAE:0.3634530007839203\n",
      "\n",
      "―――― Inference  |  Segment 57 ――――\n",
      "  seg57-ch0  MSE:0.2760905623435974  MAE:0.4129561483860016\n",
      "▶ seg57  mean  MSE:0.2760905623435974  MAE:0.4129561483860016\n",
      "\n",
      "―――― Inference  |  Segment 58 ――――\n",
      "  seg58-ch0  MSE:0.2246382087469101  MAE:0.3661820888519287\n",
      "▶ seg58  mean  MSE:0.2246382087469101  MAE:0.3661820888519287\n",
      "\n",
      "―――― Inference  |  Segment 59 ――――\n",
      "  seg59-ch0  MSE:0.3337245285511017  MAE:0.4569561183452606\n",
      "▶ seg59  mean  MSE:0.3337245285511017  MAE:0.4569561183452606\n",
      "\n",
      "―――― Inference  |  Segment 60 ――――\n",
      "  seg60-ch0  MSE:0.24949923157691956  MAE:0.39577287435531616\n",
      "▶ seg60  mean  MSE:0.24949923157691956  MAE:0.39577287435531616\n",
      "\n",
      "―――― Inference  |  Segment 61 ――――\n",
      "  seg61-ch0  MSE:0.21622148156166077  MAE:0.36320939660072327\n",
      "▶ seg61  mean  MSE:0.21622148156166077  MAE:0.36320939660072327\n",
      "\n",
      "―――― Inference  |  Segment 62 ――――\n",
      "  seg62-ch0  MSE:0.3673950731754303  MAE:0.46682244539260864\n",
      "▶ seg62  mean  MSE:0.3673950731754303  MAE:0.46682244539260864\n",
      "\n",
      "―――― Inference  |  Segment 63 ――――\n",
      "  seg63-ch0  MSE:0.2195284217596054  MAE:0.36019498109817505\n",
      "▶ seg63  mean  MSE:0.2195284217596054  MAE:0.36019498109817505\n",
      "\n",
      "―――― Inference  |  Segment 64 ――――\n",
      "  seg64-ch0  MSE:0.2283826619386673  MAE:0.37436169385910034\n",
      "▶ seg64  mean  MSE:0.2283826619386673  MAE:0.37436169385910034\n",
      "\n",
      "seg10 ch0 MSE : 0.2471307\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import r2_score\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "C        = 1                                # 채널 수\n",
    "P        = base_cfg.pred_len                # 96\n",
    "seg_cnt  = 65\n",
    "batch_sz = 8\n",
    "\n",
    "results2_ER_E1_val_1E = {}  # 수정 x3   # {seg: { 'pred':(N,P,C), 'true':(N,P,C), 'metrics':{ch:(mse,mae,r2)} } }\n",
    "\n",
    "for seg in range(seg_cnt):\n",
    "    print(f\"\\n―――― Inference  |  Segment {seg} ――――\")\n",
    "\n",
    "    # ── 세그먼트 전용 DataLoader (pv 포함) ─────────────────────\n",
    "    pv = val_pred_segments_E1[:, seg, :, :]         # 수정         # (N,P,C)\n",
    "    ds = TensorDataset(val_sequences, val_labels, pv) # 수정\n",
    "    dl = DataLoader(ds, batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "    # ── 예측 컨테이너 ────────────────────────────────────────\n",
    "    pred_ch, true_ch, metrics = [], [], {}\n",
    "\n",
    "    # ── 채널 루프 ────────────────────────────────────────────\n",
    "    for ch in range(C):\n",
    "        ckpt = Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{ch}\" / \"checkpoint.pth\"\n",
    "        if not ckpt.exists():\n",
    "            print(f\"[Warn] seg{seg}-ch{ch} ckpt 없음 → skip\");  continue\n",
    "\n",
    "        # ① 모델 생성 & ckpt 로드\n",
    "        model = Model(base_cfg).to(device)\n",
    "        model.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        preds, trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, pv_batch in dl:                 # xb:[B,S,C], yb:[B,P,C]\n",
    "                xb  = xb.float().to(device)\n",
    "                yb  = yb.float()        \n",
    "                pv_ = pv_batch.float().to(device)\n",
    "\n",
    "                out = model(xb, pv_)                     # [B,P,C]\n",
    "                preds.append(out[:, -P:, ch].cpu())\n",
    "                trues.append(yb[:, -P:, ch])\n",
    "\n",
    "        preds = torch.cat(preds, 0)     \n",
    "        trues = torch.cat(trues, 0)\n",
    "        pred_ch.append(preds)\n",
    "        true_ch.append(trues)\n",
    "\n",
    "        # ② 지표\n",
    "        p, t = preds.reshape(-1).cpu().numpy(), trues.reshape(-1).cpu().numpy()\n",
    "        mse  = np.mean((p - t)**2)\n",
    "        mae  = np.mean(np.abs(p - t))\n",
    "        metrics[ch] = (mse, mae)\n",
    "\n",
    "        print(f\"  seg{seg}-ch{ch}  MSE:{mse}  MAE:{mae}\")\n",
    "\n",
    "        del model; torch.cuda.empty_cache()\n",
    "\n",
    "    # ── (N,P,C) 텐서로 스택 ─────────────────────────────────\n",
    "    pred_all = torch.stack(pred_ch,  dim=2)   # (N,P,C)\n",
    "    true_all = torch.stack(true_ch,  dim=2)\n",
    "\n",
    "    # 세그먼트별 평균 지표\n",
    "    mse_avg = np.mean([m for m,_ in metrics.values()])\n",
    "    mae_avg = np.mean([a for _,a in metrics.values()])\n",
    "    print(f\"▶ seg{seg}  mean  MSE:{mse_avg}  MAE:{mae_avg}\")\n",
    "\n",
    "    # 저장(메모리)\n",
    "    results2_ER_E1_val_1E[seg] = {\n",
    "        \"pred2_E1_val_1E\"    : pred_all,   # 수정    # (N,P,C) tensor\n",
    "        \"true2_E1_val_1E\"    : true_all,   # 수정\n",
    "        \"metrics2_E1_val_1E\" : metrics     # 수정           # {ch:(mse,mae,r2)}\n",
    "    }\n",
    "\n",
    "# 예시: 세그먼트 10, 채널 3 의 MSE\n",
    "seg10_ch0_mse = results2_ER_E1_val_1E[10][\"metrics2_E1_val_1E\"][0][0]\n",
    "print(\"\\nseg10 ch0 MSE :\", seg10_ch0_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a6c680",
   "metadata": {},
   "source": [
    "# 2nd Inference for Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e6e64",
   "metadata": {},
   "source": [
    "## ES->1E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaf082a",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "684c64ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "\n",
    "pred_len = 96\n",
    "seq_len = 336\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual,\n",
    "                 learning_rate, lradj, patience,\n",
    "                 save_path, attach_pv):\n",
    "        self.seq_len  = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in   = enc_in          # 채널 수\n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv    = attach_pv\n",
    "\n",
    "\n",
    "# ── 공통 Config ───────────────────────────────────────────────\n",
    "base_cfg = Configs(\n",
    "    pred_len         = 96,\n",
    "    seq_len          = 336,\n",
    "    enc_in           = 1,\n",
    "    individual       = True,\n",
    "    learning_rate    = 0.0005,\n",
    "    lradj            = 'type1',\n",
    "    patience         = 3,\n",
    "    save_path        = \"./model2_ER_EES_1E\",\n",
    "    attach_pv  = True,\n",
    ")\n",
    "Path(base_cfg.save_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a26ad7",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "450844f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "―――― Inference  |  Segment 0 ――――\n",
      "  seg0-ch0  MSE:0.16403837502002716  MAE:0.3170633018016815\n",
      "▶ seg0  mean  MSE:0.16403837502002716  MAE:0.3170633018016815\n",
      "\n",
      "―――― Inference  |  Segment 1 ――――\n",
      "  seg1-ch0  MSE:0.12215931713581085  MAE:0.2742388844490051\n",
      "▶ seg1  mean  MSE:0.12215931713581085  MAE:0.2742388844490051\n",
      "\n",
      "―――― Inference  |  Segment 2 ――――\n",
      "  seg2-ch0  MSE:0.12971220910549164  MAE:0.2902107238769531\n",
      "▶ seg2  mean  MSE:0.12971220910549164  MAE:0.2902107238769531\n",
      "\n",
      "―――― Inference  |  Segment 3 ――――\n",
      "  seg3-ch0  MSE:0.33130884170532227  MAE:0.4619942009449005\n",
      "▶ seg3  mean  MSE:0.33130884170532227  MAE:0.4619942009449005\n",
      "\n",
      "―――― Inference  |  Segment 4 ――――\n",
      "  seg4-ch0  MSE:0.11280112713575363  MAE:0.2577495276927948\n",
      "▶ seg4  mean  MSE:0.11280112713575363  MAE:0.2577495276927948\n",
      "\n",
      "―――― Inference  |  Segment 5 ――――\n",
      "  seg5-ch0  MSE:0.12129656970500946  MAE:0.26184457540512085\n",
      "▶ seg5  mean  MSE:0.12129656970500946  MAE:0.26184457540512085\n",
      "\n",
      "―――― Inference  |  Segment 6 ――――\n",
      "  seg6-ch0  MSE:0.1205112412571907  MAE:0.2661797106266022\n",
      "▶ seg6  mean  MSE:0.1205112412571907  MAE:0.2661797106266022\n",
      "\n",
      "―――― Inference  |  Segment 7 ――――\n",
      "  seg7-ch0  MSE:0.11320365965366364  MAE:0.2610231041908264\n",
      "▶ seg7  mean  MSE:0.11320365965366364  MAE:0.2610231041908264\n",
      "\n",
      "―――― Inference  |  Segment 8 ――――\n",
      "  seg8-ch0  MSE:0.13540224730968475  MAE:0.2880145013332367\n",
      "▶ seg8  mean  MSE:0.13540224730968475  MAE:0.2880145013332367\n",
      "\n",
      "―――― Inference  |  Segment 9 ――――\n",
      "  seg9-ch0  MSE:0.11872713267803192  MAE:0.2700366675853729\n",
      "▶ seg9  mean  MSE:0.11872713267803192  MAE:0.2700366675853729\n",
      "\n",
      "―――― Inference  |  Segment 10 ――――\n",
      "  seg10-ch0  MSE:0.12282323837280273  MAE:0.2745625078678131\n",
      "▶ seg10  mean  MSE:0.12282323837280273  MAE:0.2745625078678131\n",
      "\n",
      "―――― Inference  |  Segment 11 ――――\n",
      "  seg11-ch0  MSE:0.14640040695667267  MAE:0.29771098494529724\n",
      "▶ seg11  mean  MSE:0.14640040695667267  MAE:0.29771098494529724\n",
      "\n",
      "―――― Inference  |  Segment 12 ――――\n",
      "  seg12-ch0  MSE:0.14215588569641113  MAE:0.2969743311405182\n",
      "▶ seg12  mean  MSE:0.14215588569641113  MAE:0.2969743311405182\n",
      "\n",
      "―――― Inference  |  Segment 13 ――――\n",
      "  seg13-ch0  MSE:0.1180080994963646  MAE:0.26333940029144287\n",
      "▶ seg13  mean  MSE:0.1180080994963646  MAE:0.26333940029144287\n",
      "\n",
      "―――― Inference  |  Segment 14 ――――\n",
      "  seg14-ch0  MSE:0.11764242500066757  MAE:0.26680365204811096\n",
      "▶ seg14  mean  MSE:0.11764242500066757  MAE:0.26680365204811096\n",
      "\n",
      "―――― Inference  |  Segment 15 ――――\n",
      "  seg15-ch0  MSE:0.12464955449104309  MAE:0.2755638062953949\n",
      "▶ seg15  mean  MSE:0.12464955449104309  MAE:0.2755638062953949\n",
      "\n",
      "―――― Inference  |  Segment 16 ――――\n",
      "  seg16-ch0  MSE:0.11880946159362793  MAE:0.2688286602497101\n",
      "▶ seg16  mean  MSE:0.11880946159362793  MAE:0.2688286602497101\n",
      "\n",
      "―――― Inference  |  Segment 17 ――――\n",
      "  seg17-ch0  MSE:0.20040512084960938  MAE:0.3497300446033478\n",
      "▶ seg17  mean  MSE:0.20040512084960938  MAE:0.3497300446033478\n",
      "\n",
      "―――― Inference  |  Segment 18 ――――\n",
      "  seg18-ch0  MSE:0.12704628705978394  MAE:0.28262361884117126\n",
      "▶ seg18  mean  MSE:0.12704628705978394  MAE:0.28262361884117126\n",
      "\n",
      "―――― Inference  |  Segment 19 ――――\n",
      "  seg19-ch0  MSE:0.10788560658693314  MAE:0.2525664269924164\n",
      "▶ seg19  mean  MSE:0.10788560658693314  MAE:0.2525664269924164\n",
      "\n",
      "―――― Inference  |  Segment 20 ――――\n",
      "  seg20-ch0  MSE:0.27114635705947876  MAE:0.40866538882255554\n",
      "▶ seg20  mean  MSE:0.27114635705947876  MAE:0.40866538882255554\n",
      "\n",
      "―――― Inference  |  Segment 21 ――――\n",
      "  seg21-ch0  MSE:0.1368602067232132  MAE:0.293032705783844\n",
      "▶ seg21  mean  MSE:0.1368602067232132  MAE:0.293032705783844\n",
      "\n",
      "―――― Inference  |  Segment 22 ――――\n",
      "  seg22-ch0  MSE:0.12466181814670563  MAE:0.27904728055000305\n",
      "▶ seg22  mean  MSE:0.12466181814670563  MAE:0.27904728055000305\n",
      "\n",
      "―――― Inference  |  Segment 23 ――――\n",
      "  seg23-ch0  MSE:0.11956466734409332  MAE:0.26757755875587463\n",
      "▶ seg23  mean  MSE:0.11956466734409332  MAE:0.26757755875587463\n",
      "\n",
      "―――― Inference  |  Segment 24 ――――\n",
      "  seg24-ch0  MSE:0.11390522867441177  MAE:0.2571653723716736\n",
      "▶ seg24  mean  MSE:0.11390522867441177  MAE:0.2571653723716736\n",
      "\n",
      "―――― Inference  |  Segment 25 ――――\n",
      "  seg25-ch0  MSE:0.13129843771457672  MAE:0.28594598174095154\n",
      "▶ seg25  mean  MSE:0.13129843771457672  MAE:0.28594598174095154\n",
      "\n",
      "―――― Inference  |  Segment 26 ――――\n",
      "  seg26-ch0  MSE:0.15303689241409302  MAE:0.30510929226875305\n",
      "▶ seg26  mean  MSE:0.15303689241409302  MAE:0.30510929226875305\n",
      "\n",
      "―――― Inference  |  Segment 27 ――――\n",
      "  seg27-ch0  MSE:0.14951308071613312  MAE:0.29693377017974854\n",
      "▶ seg27  mean  MSE:0.14951308071613312  MAE:0.29693377017974854\n",
      "\n",
      "―――― Inference  |  Segment 28 ――――\n",
      "  seg28-ch0  MSE:0.2037382572889328  MAE:0.3492618501186371\n",
      "▶ seg28  mean  MSE:0.2037382572889328  MAE:0.3492618501186371\n",
      "\n",
      "―――― Inference  |  Segment 29 ――――\n",
      "  seg29-ch0  MSE:0.112335205078125  MAE:0.25864678621292114\n",
      "▶ seg29  mean  MSE:0.112335205078125  MAE:0.25864678621292114\n",
      "\n",
      "―――― Inference  |  Segment 30 ――――\n",
      "  seg30-ch0  MSE:0.26828065514564514  MAE:0.41232919692993164\n",
      "▶ seg30  mean  MSE:0.26828065514564514  MAE:0.41232919692993164\n",
      "\n",
      "―――― Inference  |  Segment 31 ――――\n",
      "  seg31-ch0  MSE:0.2517310678958893  MAE:0.41116195917129517\n",
      "▶ seg31  mean  MSE:0.2517310678958893  MAE:0.41116195917129517\n",
      "\n",
      "―――― Inference  |  Segment 32 ――――\n",
      "  seg32-ch0  MSE:0.1227889433503151  MAE:0.27679234743118286\n",
      "▶ seg32  mean  MSE:0.1227889433503151  MAE:0.27679234743118286\n",
      "\n",
      "―――― Inference  |  Segment 33 ――――\n",
      "  seg33-ch0  MSE:0.13241705298423767  MAE:0.2844519019126892\n",
      "▶ seg33  mean  MSE:0.13241705298423767  MAE:0.2844519019126892\n",
      "\n",
      "―――― Inference  |  Segment 34 ――――\n",
      "  seg34-ch0  MSE:0.18412360548973083  MAE:0.3395446538925171\n",
      "▶ seg34  mean  MSE:0.18412360548973083  MAE:0.3395446538925171\n",
      "\n",
      "―――― Inference  |  Segment 35 ――――\n",
      "  seg35-ch0  MSE:0.18472521007061005  MAE:0.3470391631126404\n",
      "▶ seg35  mean  MSE:0.18472521007061005  MAE:0.3470391631126404\n",
      "\n",
      "―――― Inference  |  Segment 36 ――――\n",
      "  seg36-ch0  MSE:0.11228587478399277  MAE:0.2585870027542114\n",
      "▶ seg36  mean  MSE:0.11228587478399277  MAE:0.2585870027542114\n",
      "\n",
      "―――― Inference  |  Segment 37 ――――\n",
      "  seg37-ch0  MSE:0.1359659731388092  MAE:0.2922113537788391\n",
      "▶ seg37  mean  MSE:0.1359659731388092  MAE:0.2922113537788391\n",
      "\n",
      "―――― Inference  |  Segment 38 ――――\n",
      "  seg38-ch0  MSE:0.12073487788438797  MAE:0.2712116837501526\n",
      "▶ seg38  mean  MSE:0.12073487788438797  MAE:0.2712116837501526\n",
      "\n",
      "―――― Inference  |  Segment 39 ――――\n",
      "  seg39-ch0  MSE:0.11123241484165192  MAE:0.259653776884079\n",
      "▶ seg39  mean  MSE:0.11123241484165192  MAE:0.259653776884079\n",
      "\n",
      "―――― Inference  |  Segment 40 ――――\n",
      "  seg40-ch0  MSE:0.11819413304328918  MAE:0.2687416076660156\n",
      "▶ seg40  mean  MSE:0.11819413304328918  MAE:0.2687416076660156\n",
      "\n",
      "―――― Inference  |  Segment 41 ――――\n",
      "  seg41-ch0  MSE:0.14623484015464783  MAE:0.30238214135169983\n",
      "▶ seg41  mean  MSE:0.14623484015464783  MAE:0.30238214135169983\n",
      "\n",
      "―――― Inference  |  Segment 42 ――――\n",
      "  seg42-ch0  MSE:0.15710583329200745  MAE:0.292563259601593\n",
      "▶ seg42  mean  MSE:0.15710583329200745  MAE:0.292563259601593\n",
      "\n",
      "―――― Inference  |  Segment 43 ――――\n",
      "  seg43-ch0  MSE:0.13844682276248932  MAE:0.29083937406539917\n",
      "▶ seg43  mean  MSE:0.13844682276248932  MAE:0.29083937406539917\n",
      "\n",
      "―――― Inference  |  Segment 44 ――――\n",
      "  seg44-ch0  MSE:0.27526506781578064  MAE:0.4129052460193634\n",
      "▶ seg44  mean  MSE:0.27526506781578064  MAE:0.4129052460193634\n",
      "\n",
      "―――― Inference  |  Segment 45 ――――\n",
      "  seg45-ch0  MSE:0.12023521959781647  MAE:0.27759942412376404\n",
      "▶ seg45  mean  MSE:0.12023521959781647  MAE:0.27759942412376404\n",
      "\n",
      "―――― Inference  |  Segment 46 ――――\n",
      "  seg46-ch0  MSE:0.11069852858781815  MAE:0.2585059702396393\n",
      "▶ seg46  mean  MSE:0.11069852858781815  MAE:0.2585059702396393\n",
      "\n",
      "―――― Inference  |  Segment 47 ――――\n",
      "  seg47-ch0  MSE:0.11249994486570358  MAE:0.26122504472732544\n",
      "▶ seg47  mean  MSE:0.11249994486570358  MAE:0.26122504472732544\n",
      "\n",
      "―――― Inference  |  Segment 48 ――――\n",
      "  seg48-ch0  MSE:0.1329890638589859  MAE:0.27573853731155396\n",
      "▶ seg48  mean  MSE:0.1329890638589859  MAE:0.27573853731155396\n",
      "\n",
      "―――― Inference  |  Segment 49 ――――\n",
      "  seg49-ch0  MSE:0.3840597867965698  MAE:0.47961413860321045\n",
      "▶ seg49  mean  MSE:0.3840597867965698  MAE:0.47961413860321045\n",
      "\n",
      "―――― Inference  |  Segment 50 ――――\n",
      "  seg50-ch0  MSE:0.1532236486673355  MAE:0.31402501463890076\n",
      "▶ seg50  mean  MSE:0.1532236486673355  MAE:0.31402501463890076\n",
      "\n",
      "―――― Inference  |  Segment 51 ――――\n",
      "  seg51-ch0  MSE:0.14780670404434204  MAE:0.3034997284412384\n",
      "▶ seg51  mean  MSE:0.14780670404434204  MAE:0.3034997284412384\n",
      "\n",
      "―――― Inference  |  Segment 52 ――――\n",
      "  seg52-ch0  MSE:0.11366396397352219  MAE:0.26238375902175903\n",
      "▶ seg52  mean  MSE:0.11366396397352219  MAE:0.26238375902175903\n",
      "\n",
      "―――― Inference  |  Segment 53 ――――\n",
      "  seg53-ch0  MSE:0.11605215817689896  MAE:0.25865623354911804\n",
      "▶ seg53  mean  MSE:0.11605215817689896  MAE:0.25865623354911804\n",
      "\n",
      "―――― Inference  |  Segment 54 ――――\n",
      "  seg54-ch0  MSE:0.1418250948190689  MAE:0.29479819536209106\n",
      "▶ seg54  mean  MSE:0.1418250948190689  MAE:0.29479819536209106\n",
      "\n",
      "―――― Inference  |  Segment 55 ――――\n",
      "  seg55-ch0  MSE:0.1196114793419838  MAE:0.2723778784275055\n",
      "▶ seg55  mean  MSE:0.1196114793419838  MAE:0.2723778784275055\n",
      "\n",
      "―――― Inference  |  Segment 56 ――――\n",
      "  seg56-ch0  MSE:0.11397294700145721  MAE:0.26151904463768005\n",
      "▶ seg56  mean  MSE:0.11397294700145721  MAE:0.26151904463768005\n",
      "\n",
      "―――― Inference  |  Segment 57 ――――\n",
      "  seg57-ch0  MSE:0.12335309386253357  MAE:0.27122482657432556\n",
      "▶ seg57  mean  MSE:0.12335309386253357  MAE:0.27122482657432556\n",
      "\n",
      "―――― Inference  |  Segment 58 ――――\n",
      "  seg58-ch0  MSE:0.12005512416362762  MAE:0.26597267389297485\n",
      "▶ seg58  mean  MSE:0.12005512416362762  MAE:0.26597267389297485\n",
      "\n",
      "―――― Inference  |  Segment 59 ――――\n",
      "  seg59-ch0  MSE:0.1500251740217209  MAE:0.31189024448394775\n",
      "▶ seg59  mean  MSE:0.1500251740217209  MAE:0.31189024448394775\n",
      "\n",
      "―――― Inference  |  Segment 60 ――――\n",
      "  seg60-ch0  MSE:0.2095383107662201  MAE:0.3748636841773987\n",
      "▶ seg60  mean  MSE:0.2095383107662201  MAE:0.3748636841773987\n",
      "\n",
      "―――― Inference  |  Segment 61 ――――\n",
      "  seg61-ch0  MSE:0.11868932098150253  MAE:0.26248836517333984\n",
      "▶ seg61  mean  MSE:0.11868932098150253  MAE:0.26248836517333984\n",
      "\n",
      "―――― Inference  |  Segment 62 ――――\n",
      "  seg62-ch0  MSE:0.11209169030189514  MAE:0.2590830326080322\n",
      "▶ seg62  mean  MSE:0.11209169030189514  MAE:0.2590830326080322\n",
      "\n",
      "―――― Inference  |  Segment 63 ――――\n",
      "  seg63-ch0  MSE:0.1381123661994934  MAE:0.27928784489631653\n",
      "▶ seg63  mean  MSE:0.1381123661994934  MAE:0.27928784489631653\n",
      "\n",
      "―――― Inference  |  Segment 64 ――――\n",
      "  seg64-ch0  MSE:0.18412794172763824  MAE:0.3362891376018524\n",
      "▶ seg64  mean  MSE:0.18412794172763824  MAE:0.3362891376018524\n",
      "\n",
      "seg10 ch0 MSE : 0.12282324\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import r2_score\n",
    "from pathlib import Path\n",
    "\n",
    "C        = 1                                # 채널 수\n",
    "P        = base_cfg.pred_len                # 96\n",
    "seg_cnt  = 65\n",
    "batch_sz = 8\n",
    "\n",
    "results2_ER_ES_test_1E = {}  # 수정 x3   # {seg: { 'pred':(N,P,C), 'true':(N,P,C), 'metrics':{ch:(mse,mae,r2)} } }\n",
    "\n",
    "for seg in range(seg_cnt):\n",
    "    print(f\"\\n―――― Inference  |  Segment {seg} ――――\")\n",
    "\n",
    "    # ── 세그먼트 전용 DataLoader (pv 포함) ─────────────────────\n",
    "    pv = test_pred_segments_ES[:, seg, :, :]         # 수정         # (N,P,C)\n",
    "    ds = TensorDataset(test_sequences, test_labels, pv) # 수정\n",
    "    dl = DataLoader(ds, batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "    # ── 예측 컨테이너 ────────────────────────────────────────\n",
    "    pred_ch, true_ch, metrics = [], [], {}\n",
    "\n",
    "    # ── 채널 루프 ────────────────────────────────────────────\n",
    "    for ch in range(C):\n",
    "        ckpt = Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{ch}\" / \"checkpoint.pth\"\n",
    "        if not ckpt.exists():\n",
    "            print(f\"[Warn] seg{seg}-ch{ch} ckpt 없음 → skip\");  continue\n",
    "\n",
    "        # ① 모델 생성 & ckpt 로드\n",
    "        model = Model(base_cfg).to(device)\n",
    "        model.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        preds, trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, pv_batch in dl:                 # xb:[B,S,C], yb:[B,P,C]\n",
    "                xb  = xb.float().to(device)\n",
    "                yb  = yb.float()        # CPU로 두어도 OK\n",
    "                pv_ = pv_batch.float().to(device)\n",
    "\n",
    "                out = model(xb, pv_)                     # [B,P,C]\n",
    "                preds.append(out[:, -P:, ch].cpu())\n",
    "                trues.append(yb[:, -P:, ch])\n",
    "\n",
    "        preds = torch.cat(preds, 0)     # (N,P)\n",
    "        trues = torch.cat(trues, 0)\n",
    "        pred_ch.append(preds)\n",
    "        true_ch.append(trues)\n",
    "\n",
    "        # ② 지표\n",
    "        p, t = preds.reshape(-1).cpu().numpy(), trues.reshape(-1).cpu().numpy()\n",
    "        mse  = np.mean((p - t)**2)\n",
    "        mae  = np.mean(np.abs(p - t))\n",
    "        metrics[ch] = (mse, mae)\n",
    "\n",
    "        print(f\"  seg{seg}-ch{ch}  MSE:{mse}  MAE:{mae}\")\n",
    "\n",
    "        del model; torch.cuda.empty_cache()\n",
    "\n",
    "    # ── (N,P,C) 텐서로 스택 ─────────────────────────────────\n",
    "    pred_all = torch.stack(pred_ch,  dim=2)   # (N,P,C)\n",
    "    true_all = torch.stack(true_ch,  dim=2)\n",
    "\n",
    "    # 세그먼트별 평균 지표\n",
    "    mse_avg = np.mean([m for m,_ in metrics.values()])\n",
    "    mae_avg = np.mean([a for _,a in metrics.values()])\n",
    "    print(f\"▶ seg{seg}  mean  MSE:{mse_avg}  MAE:{mae_avg}\")\n",
    "\n",
    "    # 저장(메모리)\n",
    "    results2_ER_ES_test_1E[seg] = {\n",
    "        \"pred2_ES_test_1E\"    : pred_all,   # 수정    # (N,P,C) tensor\n",
    "        \"true2_ES_test_1E\"    : true_all,   # 수정\n",
    "        \"metrics2_ES_test_1E\" : metrics     # 수정           # {ch:(mse,mae,r2)}\n",
    "    }\n",
    "\n",
    "# 예시: 세그먼트 10, 채널 3 의 MSE\n",
    "seg10_ch0_mse = results2_ER_ES_test_1E[10][\"metrics2_ES_test_1E\"][0][0]\n",
    "print(\"\\nseg10 ch0 MSE :\", seg10_ch0_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16bc08c",
   "metadata": {},
   "source": [
    "## 1E->1E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd10ffe",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66168b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "\n",
    "pred_len = 96\n",
    "seq_len = 336 + pred_len//3\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual,\n",
    "                 learning_rate, lradj, patience,\n",
    "                 save_path, attach_pv):\n",
    "        self.seq_len  = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in   = enc_in          # 채널 수\n",
    "        self.individual = individual\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lradj = lradj\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.attach_pv    = attach_pv\n",
    "\n",
    "\n",
    "# ── 공통 Config ───────────────────────────────────────────────\n",
    "base_cfg = Configs(\n",
    "    pred_len         = 96,\n",
    "    seq_len          = 336 ,\n",
    "    enc_in           = 1,\n",
    "    individual       = True,\n",
    "    learning_rate    = 0.0005,\n",
    "    lradj            = 'type1',\n",
    "    patience         = 3,\n",
    "    save_path        = \"./model2_ER_E1_1E\",\n",
    "    attach_pv  = True,\n",
    ")\n",
    "Path(base_cfg.save_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c5464c",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6eb2ab5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "―――― Inference  |  Segment 0 ――――\n",
      "  seg0-ch0  MSE:0.1615879386663437  MAE:0.3140833377838135\n",
      "▶ seg0  mean  MSE:0.1615879386663437  MAE:0.3140833377838135\n",
      "\n",
      "―――― Inference  |  Segment 1 ――――\n",
      "  seg1-ch0  MSE:0.11811566352844238  MAE:0.2656703591346741\n",
      "▶ seg1  mean  MSE:0.11811566352844238  MAE:0.2656703591346741\n",
      "\n",
      "―――― Inference  |  Segment 2 ――――\n",
      "  seg2-ch0  MSE:0.13090957701206207  MAE:0.27130448818206787\n",
      "▶ seg2  mean  MSE:0.13090957701206207  MAE:0.27130448818206787\n",
      "\n",
      "―――― Inference  |  Segment 3 ――――\n",
      "  seg3-ch0  MSE:0.2727861702442169  MAE:0.4301261901855469\n",
      "▶ seg3  mean  MSE:0.2727861702442169  MAE:0.4301261901855469\n",
      "\n",
      "―――― Inference  |  Segment 4 ――――\n",
      "  seg4-ch0  MSE:0.17446111142635345  MAE:0.3406302034854889\n",
      "▶ seg4  mean  MSE:0.17446111142635345  MAE:0.3406302034854889\n",
      "\n",
      "―――― Inference  |  Segment 5 ――――\n",
      "  seg5-ch0  MSE:0.11139986664056778  MAE:0.2553647756576538\n",
      "▶ seg5  mean  MSE:0.11139986664056778  MAE:0.2553647756576538\n",
      "\n",
      "―――― Inference  |  Segment 6 ――――\n",
      "  seg6-ch0  MSE:0.11887801438570023  MAE:0.27201080322265625\n",
      "▶ seg6  mean  MSE:0.11887801438570023  MAE:0.27201080322265625\n",
      "\n",
      "―――― Inference  |  Segment 7 ――――\n",
      "  seg7-ch0  MSE:0.12858125567436218  MAE:0.28565898537635803\n",
      "▶ seg7  mean  MSE:0.12858125567436218  MAE:0.28565898537635803\n",
      "\n",
      "―――― Inference  |  Segment 8 ――――\n",
      "  seg8-ch0  MSE:0.19533267617225647  MAE:0.3447515070438385\n",
      "▶ seg8  mean  MSE:0.19533267617225647  MAE:0.3447515070438385\n",
      "\n",
      "―――― Inference  |  Segment 9 ――――\n",
      "  seg9-ch0  MSE:0.1893632858991623  MAE:0.34510383009910583\n",
      "▶ seg9  mean  MSE:0.1893632858991623  MAE:0.34510383009910583\n",
      "\n",
      "―――― Inference  |  Segment 10 ――――\n",
      "  seg10-ch0  MSE:0.12007299065589905  MAE:0.2709820866584778\n",
      "▶ seg10  mean  MSE:0.12007299065589905  MAE:0.2709820866584778\n",
      "\n",
      "―――― Inference  |  Segment 11 ――――\n",
      "  seg11-ch0  MSE:0.20966342091560364  MAE:0.3541224002838135\n",
      "▶ seg11  mean  MSE:0.20966342091560364  MAE:0.3541224002838135\n",
      "\n",
      "―――― Inference  |  Segment 12 ――――\n",
      "  seg12-ch0  MSE:0.17095641791820526  MAE:0.3312356472015381\n",
      "▶ seg12  mean  MSE:0.17095641791820526  MAE:0.3312356472015381\n",
      "\n",
      "―――― Inference  |  Segment 13 ――――\n",
      "  seg13-ch0  MSE:0.11832719296216965  MAE:0.2727895975112915\n",
      "▶ seg13  mean  MSE:0.11832719296216965  MAE:0.2727895975112915\n",
      "\n",
      "―――― Inference  |  Segment 14 ――――\n",
      "  seg14-ch0  MSE:0.31390902400016785  MAE:0.4495699405670166\n",
      "▶ seg14  mean  MSE:0.31390902400016785  MAE:0.4495699405670166\n",
      "\n",
      "―――― Inference  |  Segment 15 ――――\n",
      "  seg15-ch0  MSE:0.21911923587322235  MAE:0.37068137526512146\n",
      "▶ seg15  mean  MSE:0.21911923587322235  MAE:0.37068137526512146\n",
      "\n",
      "―――― Inference  |  Segment 16 ――――\n",
      "  seg16-ch0  MSE:0.13087601959705353  MAE:0.28300607204437256\n",
      "▶ seg16  mean  MSE:0.13087601959705353  MAE:0.28300607204437256\n",
      "\n",
      "―――― Inference  |  Segment 17 ――――\n",
      "  seg17-ch0  MSE:0.15202632546424866  MAE:0.3053719699382782\n",
      "▶ seg17  mean  MSE:0.15202632546424866  MAE:0.3053719699382782\n",
      "\n",
      "―――― Inference  |  Segment 18 ――――\n",
      "  seg18-ch0  MSE:0.1336613893508911  MAE:0.28681039810180664\n",
      "▶ seg18  mean  MSE:0.1336613893508911  MAE:0.28681039810180664\n",
      "\n",
      "―――― Inference  |  Segment 19 ――――\n",
      "  seg19-ch0  MSE:0.1682315468788147  MAE:0.3234477937221527\n",
      "▶ seg19  mean  MSE:0.1682315468788147  MAE:0.3234477937221527\n",
      "\n",
      "―――― Inference  |  Segment 20 ――――\n",
      "  seg20-ch0  MSE:0.3205588459968567  MAE:0.4556404650211334\n",
      "▶ seg20  mean  MSE:0.3205588459968567  MAE:0.4556404650211334\n",
      "\n",
      "―――― Inference  |  Segment 21 ――――\n",
      "  seg21-ch0  MSE:0.15765710175037384  MAE:0.2945849299430847\n",
      "▶ seg21  mean  MSE:0.15765710175037384  MAE:0.2945849299430847\n",
      "\n",
      "―――― Inference  |  Segment 22 ――――\n",
      "  seg22-ch0  MSE:0.13177718222141266  MAE:0.28540176153182983\n",
      "▶ seg22  mean  MSE:0.13177718222141266  MAE:0.28540176153182983\n",
      "\n",
      "―――― Inference  |  Segment 23 ――――\n",
      "  seg23-ch0  MSE:0.20199690759181976  MAE:0.35968130826950073\n",
      "▶ seg23  mean  MSE:0.20199690759181976  MAE:0.35968130826950073\n",
      "\n",
      "―――― Inference  |  Segment 24 ――――\n",
      "  seg24-ch0  MSE:0.2145666480064392  MAE:0.3646429777145386\n",
      "▶ seg24  mean  MSE:0.2145666480064392  MAE:0.3646429777145386\n",
      "\n",
      "―――― Inference  |  Segment 25 ――――\n",
      "  seg25-ch0  MSE:0.12388236820697784  MAE:0.26595646142959595\n",
      "▶ seg25  mean  MSE:0.12388236820697784  MAE:0.26595646142959595\n",
      "\n",
      "―――― Inference  |  Segment 26 ――――\n",
      "  seg26-ch0  MSE:0.24525891244411469  MAE:0.4048795700073242\n",
      "▶ seg26  mean  MSE:0.24525891244411469  MAE:0.4048795700073242\n",
      "\n",
      "―――― Inference  |  Segment 27 ――――\n",
      "  seg27-ch0  MSE:0.12552031874656677  MAE:0.2789155840873718\n",
      "▶ seg27  mean  MSE:0.12552031874656677  MAE:0.2789155840873718\n",
      "\n",
      "―――― Inference  |  Segment 28 ――――\n",
      "  seg28-ch0  MSE:0.11071094125509262  MAE:0.25974103808403015\n",
      "▶ seg28  mean  MSE:0.11071094125509262  MAE:0.25974103808403015\n",
      "\n",
      "―――― Inference  |  Segment 29 ――――\n",
      "  seg29-ch0  MSE:0.19594532251358032  MAE:0.35926562547683716\n",
      "▶ seg29  mean  MSE:0.19594532251358032  MAE:0.35926562547683716\n",
      "\n",
      "―――― Inference  |  Segment 30 ――――\n",
      "  seg30-ch0  MSE:0.25967714190483093  MAE:0.4137760400772095\n",
      "▶ seg30  mean  MSE:0.25967714190483093  MAE:0.4137760400772095\n",
      "\n",
      "―――― Inference  |  Segment 31 ――――\n",
      "  seg31-ch0  MSE:0.12203121185302734  MAE:0.268809974193573\n",
      "▶ seg31  mean  MSE:0.12203121185302734  MAE:0.268809974193573\n",
      "\n",
      "―――― Inference  |  Segment 32 ――――\n",
      "  seg32-ch0  MSE:0.13272809982299805  MAE:0.29174813628196716\n",
      "▶ seg32  mean  MSE:0.13272809982299805  MAE:0.29174813628196716\n",
      "\n",
      "―――― Inference  |  Segment 33 ――――\n",
      "  seg33-ch0  MSE:0.10989785194396973  MAE:0.25280100107192993\n",
      "▶ seg33  mean  MSE:0.10989785194396973  MAE:0.25280100107192993\n",
      "\n",
      "―――― Inference  |  Segment 34 ――――\n",
      "  seg34-ch0  MSE:0.10932649672031403  MAE:0.2573496103286743\n",
      "▶ seg34  mean  MSE:0.10932649672031403  MAE:0.2573496103286743\n",
      "\n",
      "―――― Inference  |  Segment 35 ――――\n",
      "  seg35-ch0  MSE:0.11702549457550049  MAE:0.26325076818466187\n",
      "▶ seg35  mean  MSE:0.11702549457550049  MAE:0.26325076818466187\n",
      "\n",
      "―――― Inference  |  Segment 36 ――――\n",
      "  seg36-ch0  MSE:0.2927631735801697  MAE:0.4205121397972107\n",
      "▶ seg36  mean  MSE:0.2927631735801697  MAE:0.4205121397972107\n",
      "\n",
      "―――― Inference  |  Segment 37 ――――\n",
      "  seg37-ch0  MSE:0.14635467529296875  MAE:0.2997848093509674\n",
      "▶ seg37  mean  MSE:0.14635467529296875  MAE:0.2997848093509674\n",
      "\n",
      "―――― Inference  |  Segment 38 ――――\n",
      "  seg38-ch0  MSE:0.20640933513641357  MAE:0.3595077693462372\n",
      "▶ seg38  mean  MSE:0.20640933513641357  MAE:0.3595077693462372\n",
      "\n",
      "―――― Inference  |  Segment 39 ――――\n",
      "  seg39-ch0  MSE:0.11813614517450333  MAE:0.2663426697254181\n",
      "▶ seg39  mean  MSE:0.11813614517450333  MAE:0.2663426697254181\n",
      "\n",
      "―――― Inference  |  Segment 40 ――――\n",
      "  seg40-ch0  MSE:0.11702854931354523  MAE:0.2605739235877991\n",
      "▶ seg40  mean  MSE:0.11702854931354523  MAE:0.2605739235877991\n",
      "\n",
      "―――― Inference  |  Segment 41 ――――\n",
      "  seg41-ch0  MSE:0.1232529729604721  MAE:0.2672123610973358\n",
      "▶ seg41  mean  MSE:0.1232529729604721  MAE:0.2672123610973358\n",
      "\n",
      "―――― Inference  |  Segment 42 ――――\n",
      "  seg42-ch0  MSE:0.1085755005478859  MAE:0.25070929527282715\n",
      "▶ seg42  mean  MSE:0.1085755005478859  MAE:0.25070929527282715\n",
      "\n",
      "―――― Inference  |  Segment 43 ――――\n",
      "  seg43-ch0  MSE:0.11867383867502213  MAE:0.2707197666168213\n",
      "▶ seg43  mean  MSE:0.11867383867502213  MAE:0.2707197666168213\n",
      "\n",
      "―――― Inference  |  Segment 44 ――――\n",
      "  seg44-ch0  MSE:0.18067441880702972  MAE:0.32588908076286316\n",
      "▶ seg44  mean  MSE:0.18067441880702972  MAE:0.32588908076286316\n",
      "\n",
      "―――― Inference  |  Segment 45 ――――\n",
      "  seg45-ch0  MSE:0.11011308431625366  MAE:0.25572293996810913\n",
      "▶ seg45  mean  MSE:0.11011308431625366  MAE:0.25572293996810913\n",
      "\n",
      "―――― Inference  |  Segment 46 ――――\n",
      "  seg46-ch0  MSE:0.11191969364881516  MAE:0.258942186832428\n",
      "▶ seg46  mean  MSE:0.11191969364881516  MAE:0.258942186832428\n",
      "\n",
      "―――― Inference  |  Segment 47 ――――\n",
      "  seg47-ch0  MSE:0.12936128675937653  MAE:0.2703545093536377\n",
      "▶ seg47  mean  MSE:0.12936128675937653  MAE:0.2703545093536377\n",
      "\n",
      "―――― Inference  |  Segment 48 ――――\n",
      "  seg48-ch0  MSE:0.13406169414520264  MAE:0.28200000524520874\n",
      "▶ seg48  mean  MSE:0.13406169414520264  MAE:0.28200000524520874\n",
      "\n",
      "―――― Inference  |  Segment 49 ――――\n",
      "  seg49-ch0  MSE:0.12131708860397339  MAE:0.26831844449043274\n",
      "▶ seg49  mean  MSE:0.12131708860397339  MAE:0.26831844449043274\n",
      "\n",
      "―――― Inference  |  Segment 50 ――――\n",
      "  seg50-ch0  MSE:0.13333463668823242  MAE:0.2853188216686249\n",
      "▶ seg50  mean  MSE:0.13333463668823242  MAE:0.2853188216686249\n",
      "\n",
      "―――― Inference  |  Segment 51 ――――\n",
      "  seg51-ch0  MSE:0.12281721085309982  MAE:0.26943862438201904\n",
      "▶ seg51  mean  MSE:0.12281721085309982  MAE:0.26943862438201904\n",
      "\n",
      "―――― Inference  |  Segment 52 ――――\n",
      "  seg52-ch0  MSE:0.16772609949111938  MAE:0.3191078305244446\n",
      "▶ seg52  mean  MSE:0.16772609949111938  MAE:0.3191078305244446\n",
      "\n",
      "―――― Inference  |  Segment 53 ――――\n",
      "  seg53-ch0  MSE:0.11985901743173599  MAE:0.26438310742378235\n",
      "▶ seg53  mean  MSE:0.11985901743173599  MAE:0.26438310742378235\n",
      "\n",
      "―――― Inference  |  Segment 54 ――――\n",
      "  seg54-ch0  MSE:0.13699272274971008  MAE:0.3011387586593628\n",
      "▶ seg54  mean  MSE:0.13699272274971008  MAE:0.3011387586593628\n",
      "\n",
      "―――― Inference  |  Segment 55 ――――\n",
      "  seg55-ch0  MSE:0.29336655139923096  MAE:0.44896191358566284\n",
      "▶ seg55  mean  MSE:0.29336655139923096  MAE:0.44896191358566284\n",
      "\n",
      "―――― Inference  |  Segment 56 ――――\n",
      "  seg56-ch0  MSE:0.1302734762430191  MAE:0.2693948447704315\n",
      "▶ seg56  mean  MSE:0.1302734762430191  MAE:0.2693948447704315\n",
      "\n",
      "―――― Inference  |  Segment 57 ――――\n",
      "  seg57-ch0  MSE:0.1431078463792801  MAE:0.2972687780857086\n",
      "▶ seg57  mean  MSE:0.1431078463792801  MAE:0.2972687780857086\n",
      "\n",
      "―――― Inference  |  Segment 58 ――――\n",
      "  seg58-ch0  MSE:0.162652850151062  MAE:0.3060952126979828\n",
      "▶ seg58  mean  MSE:0.162652850151062  MAE:0.3060952126979828\n",
      "\n",
      "―――― Inference  |  Segment 59 ――――\n",
      "  seg59-ch0  MSE:0.18560487031936646  MAE:0.34476447105407715\n",
      "▶ seg59  mean  MSE:0.18560487031936646  MAE:0.34476447105407715\n",
      "\n",
      "―――― Inference  |  Segment 60 ――――\n",
      "  seg60-ch0  MSE:0.1276276707649231  MAE:0.28204697370529175\n",
      "▶ seg60  mean  MSE:0.1276276707649231  MAE:0.28204697370529175\n",
      "\n",
      "―――― Inference  |  Segment 61 ――――\n",
      "  seg61-ch0  MSE:0.11522635817527771  MAE:0.25592735409736633\n",
      "▶ seg61  mean  MSE:0.11522635817527771  MAE:0.25592735409736633\n",
      "\n",
      "―――― Inference  |  Segment 62 ――――\n",
      "  seg62-ch0  MSE:0.2567936182022095  MAE:0.39371007680892944\n",
      "▶ seg62  mean  MSE:0.2567936182022095  MAE:0.39371007680892944\n",
      "\n",
      "―――― Inference  |  Segment 63 ――――\n",
      "  seg63-ch0  MSE:0.15721094608306885  MAE:0.3001052439212799\n",
      "▶ seg63  mean  MSE:0.15721094608306885  MAE:0.3001052439212799\n",
      "\n",
      "―――― Inference  |  Segment 64 ――――\n",
      "  seg64-ch0  MSE:0.12711459398269653  MAE:0.2745022177696228\n",
      "▶ seg64  mean  MSE:0.12711459398269653  MAE:0.2745022177696228\n",
      "\n",
      "seg10 ch0 MSE : 0.12007299\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import r2_score\n",
    "from pathlib import Path\n",
    "\n",
    "C        = 1                                # 채널 수\n",
    "P        = base_cfg.pred_len                # 96\n",
    "seg_cnt  = 65\n",
    "batch_sz = 8\n",
    "\n",
    "results2_ER_E1_test_1E = {}  # 수정 x3   # {seg: { 'pred':(N,P,C), 'true':(N,P,C), 'metrics':{ch:(mse,mae,r2)} } }\n",
    "\n",
    "for seg in range(seg_cnt):\n",
    "    print(f\"\\n―――― Inference  |  Segment {seg} ――――\")\n",
    "\n",
    "    # ── 세그먼트 전용 DataLoader (pv 포함) ─────────────────────\n",
    "    pv = test_pred_segments_E1[:, seg, :, :]         # 수정         # (N,P,C)\n",
    "    ds = TensorDataset(test_sequences, test_labels, pv) # 수정\n",
    "    dl = DataLoader(ds, batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "    # ── 예측 컨테이너 ────────────────────────────────────────\n",
    "    pred_ch, true_ch, metrics = [], [], {}\n",
    "\n",
    "    # ── 채널 루프 ────────────────────────────────────────────\n",
    "    for ch in range(C):\n",
    "        ckpt = Path(base_cfg.save_path) / f\"seg{seg}\" / f\"ch{ch}\" / \"checkpoint.pth\"\n",
    "        if not ckpt.exists():\n",
    "            print(f\"[Warn] seg{seg}-ch{ch} ckpt 없음 → skip\");  continue\n",
    "\n",
    "        # ① 모델 생성 & ckpt 로드\n",
    "        model = Model(base_cfg).to(device)\n",
    "        model.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        preds, trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, pv_batch in dl:                 # xb:[B,S,C], yb:[B,P,C]\n",
    "                xb  = xb.float().to(device)\n",
    "                yb  = yb.float()        # CPU로 두어도 OK\n",
    "                pv_ = pv_batch.float().to(device)\n",
    "\n",
    "                out = model(xb, pv_)                     # [B,P,C]\n",
    "                preds.append(out[:, -P:, ch].cpu())\n",
    "                trues.append(yb[:, -P:, ch])\n",
    "\n",
    "        preds = torch.cat(preds, 0)     # (N,P)\n",
    "        trues = torch.cat(trues, 0)\n",
    "        pred_ch.append(preds)\n",
    "        true_ch.append(trues)\n",
    "\n",
    "        # ② 지표\n",
    "        p, t = preds.reshape(-1).cpu().numpy(), trues.reshape(-1).cpu().numpy()\n",
    "        mse  = np.mean((p - t)**2)\n",
    "        mae  = np.mean(np.abs(p - t))\n",
    "        metrics[ch] = (mse, mae)\n",
    "\n",
    "        print(f\"  seg{seg}-ch{ch}  MSE:{mse}  MAE:{mae}\")\n",
    "\n",
    "        del model; torch.cuda.empty_cache()\n",
    "\n",
    "    # ── (N,P,C) 텐서로 스택 ─────────────────────────────────\n",
    "    pred_all = torch.stack(pred_ch,  dim=2)   # (N,P,C)\n",
    "    true_all = torch.stack(true_ch,  dim=2)\n",
    "\n",
    "    # 세그먼트별 평균 지표\n",
    "    mse_avg = np.mean([m for m,_ in metrics.values()])\n",
    "    mae_avg = np.mean([a for _,a in metrics.values()])\n",
    "    print(f\"▶ seg{seg}  mean  MSE:{mse_avg}  MAE:{mae_avg}\")\n",
    "\n",
    "    # 저장(메모리)\n",
    "    results2_ER_E1_test_1E[seg] = {\n",
    "        \"pred2_E1_test_1E\"    : pred_all,   # 수정    # (N,P,C) tensor\n",
    "        \"true2_E1_test_1E\"    : true_all,   # 수정\n",
    "        \"metrics2_E1_test_1E\" : metrics     # 수정           # {ch:(mse,mae,r2)}\n",
    "    }\n",
    "\n",
    "# 예시: 세그먼트 10, 채널 3 의 MSE\n",
    "seg10_ch0_mse = results2_ER_E1_test_1E[10][\"metrics2_E1_test_1E\"][0][0]\n",
    "print(\"\\nseg10 ch0 MSE :\", seg10_ch0_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e19ddff",
   "metadata": {},
   "source": [
    "# Rank Models (by 2nd validation performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab794b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1_ER_train = torch.load(\"./1st_results_ER/train_1st_results.pt\")\n",
    "results1_ER_val = torch.load(\"./1st_results_ER/val_1st_results.pt\")\n",
    "results1_ER_test = torch.load(\"./1st_results_ER/test_1st_results.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01aee13",
   "metadata": {},
   "source": [
    "### ES->1E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f742cae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Train-set  Per-Channel  Top-N  MSE\n",
      "\n",
      "=== Channel 0 ===\n",
      "Vanilla MSE : 0.217507\n",
      "\n",
      "  Top  1 | seg 05 | MSE 0.211462 (+0.006046)\n",
      "  Top  2 | seg 29 | MSE 0.216269 (+0.001238)\n",
      "  Top  3 | seg 53 | MSE 0.218803 (-0.001296)\n",
      "  Top  4 | seg 24 | MSE 0.218826 (-0.001318)\n",
      "  Top  5 | seg 57 | MSE 0.221429 (-0.003921)\n",
      "  Top  6 | seg 42 | MSE 0.222881 (-0.005373)\n",
      "  Top  7 | seg 36 | MSE 0.222911 (-0.005403)\n",
      "  Top  8 | seg 19 | MSE 0.223763 (-0.006255)\n",
      "  Top  9 | seg 39 | MSE 0.224822 (-0.007315)\n",
      "  Top 10 | seg 14 | MSE 0.225524 (-0.008016)\n",
      "  Top 11 | seg 47 | MSE 0.230050 (-0.012542)\n",
      "  Top 12 | seg 48 | MSE 0.231416 (-0.013908)\n",
      "  Top 13 | seg 46 | MSE 0.231695 (-0.014188)\n",
      "  Top 14 | seg 21 | MSE 0.234102 (-0.016594)\n",
      "  Top 15 | seg 61 | MSE 0.234487 (-0.016980)\n",
      "  Top 16 | seg 23 | MSE 0.235043 (-0.017535)\n",
      "  Top 17 | seg 04 | MSE 0.235912 (-0.018405)\n",
      "  Top 18 | seg 07 | MSE 0.236777 (-0.019270)\n",
      "  Top 19 | seg 55 | MSE 0.238088 (-0.020580)\n",
      "  Top 20 | seg 56 | MSE 0.239110 (-0.021602)\n",
      "  Top 21 | seg 01 | MSE 0.239608 (-0.022100)\n",
      "  Top 22 | seg 62 | MSE 0.240100 (-0.022593)\n",
      "  Top 23 | seg 02 | MSE 0.242962 (-0.025454)\n",
      "  Top 24 | seg 45 | MSE 0.244129 (-0.026622)\n",
      "  Top 25 | seg 16 | MSE 0.244146 (-0.026638)\n",
      "  Top 26 | seg 40 | MSE 0.244866 (-0.027359)\n",
      "  Top 27 | seg 58 | MSE 0.245845 (-0.028337)\n",
      "  Top 28 | seg 52 | MSE 0.246305 (-0.028798)\n",
      "  Top 29 | seg 32 | MSE 0.246472 (-0.028965)\n",
      "  Top 30 | seg 38 | MSE 0.248013 (-0.030506)\n",
      "  Top 31 | seg 10 | MSE 0.250146 (-0.032638)\n",
      "  Top 32 | seg 06 | MSE 0.250450 (-0.032943)\n",
      "  Top 33 | seg 13 | MSE 0.250499 (-0.032992)\n",
      "  Top 34 | seg 15 | MSE 0.250706 (-0.033199)\n",
      "  Top 35 | seg 09 | MSE 0.252511 (-0.035003)\n",
      "  Top 36 | seg 22 | MSE 0.257869 (-0.040361)\n",
      "  Top 37 | seg 18 | MSE 0.264311 (-0.046803)\n",
      "  Top 38 | seg 63 | MSE 0.265900 (-0.048392)\n",
      "  Top 39 | seg 43 | MSE 0.267324 (-0.049817)\n",
      "  Top 40 | seg 37 | MSE 0.267513 (-0.050006)\n",
      "  Top 41 | seg 25 | MSE 0.267958 (-0.050450)\n",
      "  Top 42 | seg 54 | MSE 0.269345 (-0.051838)\n",
      "  Top 43 | seg 50 | MSE 0.270307 (-0.052799)\n",
      "  Top 44 | seg 59 | MSE 0.271002 (-0.053495)\n",
      "  Top 45 | seg 33 | MSE 0.272493 (-0.054985)\n",
      "  Top 46 | seg 51 | MSE 0.274134 (-0.056626)\n",
      "  Top 47 | seg 12 | MSE 0.281349 (-0.063842)\n",
      "  Top 48 | seg 08 | MSE 0.284768 (-0.067260)\n",
      "  Top 49 | seg 11 | MSE 0.287312 (-0.069804)\n",
      "  Top 50 | seg 27 | MSE 0.288195 (-0.070688)\n",
      "  Top 51 | seg 26 | MSE 0.292081 (-0.074573)\n",
      "  Top 52 | seg 41 | MSE 0.293647 (-0.076139)\n",
      "  Top 53 | seg 00 | MSE 0.316741 (-0.099234)\n",
      "  Top 54 | seg 17 | MSE 0.323528 (-0.106020)\n",
      "  Top 55 | seg 64 | MSE 0.329958 (-0.112450)\n",
      "  Top 56 | seg 35 | MSE 0.331786 (-0.114279)\n",
      "  Top 57 | seg 60 | MSE 0.342311 (-0.124803)\n",
      "  Top 58 | seg 28 | MSE 0.356381 (-0.138874)\n",
      "  Top 59 | seg 34 | MSE 0.360648 (-0.143140)\n",
      "  Top 60 | seg 31 | MSE 0.374650 (-0.157143)\n",
      "  Top 61 | seg 30 | MSE 0.398045 (-0.180537)\n",
      "  Top 62 | seg 44 | MSE 0.398570 (-0.181063)\n",
      "  Top 63 | seg 20 | MSE 0.409005 (-0.191498)\n",
      "  Top 64 | seg 03 | MSE 0.441194 (-0.223686)\n",
      "  Top 65 | seg 49 | MSE 0.522518 (-0.305011)\n",
      "\n",
      "Saved top segment indices per channel:\n",
      "Channel 0: [5, 29, 53, 24, 57, 42, 36, 19, 39, 14, 47, 48, 46, 21, 61, 23, 4, 7, 55, 56, 1, 62, 2, 45, 16, 40, 58, 52, 32, 38, 10, 6, 13, 15, 9, 22, 18, 63, 43, 37, 25, 54, 50, 59, 33, 51, 12, 8, 11, 27, 26, 41, 0, 17, 64, 35, 60, 28, 34, 31, 30, 44, 20, 3, 49]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ──────────────────────────────────────────────\n",
    "# 0. 설정\n",
    "# ──────────────────────────────────────────────\n",
    "TOP_N       = 65\n",
    "SEG_CNT     = 65\n",
    "CH_CNT      = 1\n",
    "metric_idx  = 0          # (mse, mae, r2) 중 0 = MSE\n",
    "\n",
    "# ──────────────────────────────────────────────\n",
    "# 1. 증강 모델 MSE 테이블 수집 → (SEG_CNT, CH_CNT)\n",
    "# ──────────────────────────────────────────────\n",
    "mse_table = np.full((SEG_CNT, CH_CNT), np.inf)\n",
    "\n",
    "for seg in range(SEG_CNT):\n",
    "    if seg not in results2_ER_ES_val_1E:\n",
    "        continue\n",
    "    for ch in range(CH_CNT):\n",
    "        if ch in results2_ER_ES_val_1E[seg][\"metrics2_ES_val_1E\"]:\n",
    "            mse_table[seg, ch] = results2_ER_ES_val_1E[seg][\"metrics2_ES_val_1E\"][ch][metric_idx]\n",
    "\n",
    "# ──────────────────────────────────────────────\n",
    "# 2. 채널별 Top-N 인덱스 추출 & 저장\n",
    "# ──────────────────────────────────────────────\n",
    "print(\"\\n▶ Train-set  Per-Channel  Top-N  MSE\\n\")\n",
    "top_seg_idx_ES_val_1E = {}                       # ← 여기 저장\n",
    "\n",
    "for ch in range(CH_CNT):\n",
    "    print(f\"=== Channel {ch} ===\")\n",
    "    v_mse = results1_ER_val[1]['mse_val_E1']\n",
    "    print(f\"Vanilla MSE : {v_mse:.6f}\\n\")\n",
    "\n",
    "    # (seg, mse) 중 유효 값만 골라 MSE 오름차순\n",
    "    pairs = [(seg, mse_table[seg, ch]) for seg in range(SEG_CNT)\n",
    "             if np.isfinite(mse_table[seg, ch])]\n",
    "    top   = sorted(pairs, key=lambda x: x[1])[:TOP_N]\n",
    "\n",
    "    # ── 인덱스만 따로 저장 ─────────────────────\n",
    "    top_seg_idx_ES_val_1E[ch] = [seg for seg, _ in top]   # e.g. {0:[12,5,7,…], 1:[3,8,…]}\n",
    "\n",
    "    # ── 출력 ─────────────────────────────────\n",
    "    for rank, (seg_id, mse_val) in enumerate(top, 1):\n",
    "        delta = v_mse - mse_val\n",
    "        sign  = \"+\" if delta > 0 else \"-\"\n",
    "        print(f\"  Top {rank:2d} | seg {seg_id:02d} | MSE {mse_val:.6f} \"\n",
    "              f\"({sign}{abs(delta):.6f})\")\n",
    "    print()\n",
    "\n",
    "# ──────────────────────────────────────────────\n",
    "# 3. 확인\n",
    "# ──────────────────────────────────────────────\n",
    "print(\"Saved top segment indices per channel:\")\n",
    "for ch, seg_list in top_seg_idx_ES_val_1E.items():\n",
    "    print(f\"Channel {ch}: {seg_list}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1264fc",
   "metadata": {},
   "source": [
    "### 1E->1E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e98d44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Train-set  Per-Channel  Top-N  MSE\n",
      "\n",
      "=== Channel 0 ===\n",
      "Vanilla MSE : 0.217507\n",
      "\n",
      "  Top  1 | seg 61 | MSE 0.216221 (+0.001286)\n",
      "  Top  2 | seg 53 | MSE 0.218959 (-0.001451)\n",
      "  Top  3 | seg 02 | MSE 0.219129 (-0.001621)\n",
      "  Top  4 | seg 63 | MSE 0.219528 (-0.002021)\n",
      "  Top  5 | seg 42 | MSE 0.220670 (-0.003163)\n",
      "  Top  6 | seg 45 | MSE 0.220875 (-0.003368)\n",
      "  Top  7 | seg 56 | MSE 0.221263 (-0.003755)\n",
      "  Top  8 | seg 46 | MSE 0.222764 (-0.005257)\n",
      "  Top  9 | seg 40 | MSE 0.222912 (-0.005404)\n",
      "  Top 10 | seg 21 | MSE 0.222979 (-0.005472)\n",
      "  Top 11 | seg 47 | MSE 0.223130 (-0.005622)\n",
      "  Top 12 | seg 33 | MSE 0.223336 (-0.005828)\n",
      "  Top 13 | seg 58 | MSE 0.224638 (-0.007131)\n",
      "  Top 14 | seg 05 | MSE 0.224755 (-0.007247)\n",
      "  Top 15 | seg 25 | MSE 0.225851 (-0.008343)\n",
      "  Top 16 | seg 28 | MSE 0.226484 (-0.008976)\n",
      "  Top 17 | seg 41 | MSE 0.226782 (-0.009274)\n",
      "  Top 18 | seg 64 | MSE 0.228383 (-0.010875)\n",
      "  Top 19 | seg 34 | MSE 0.230000 (-0.012493)\n",
      "  Top 20 | seg 44 | MSE 0.233962 (-0.016454)\n",
      "  Top 21 | seg 43 | MSE 0.234836 (-0.017329)\n",
      "  Top 22 | seg 35 | MSE 0.240357 (-0.022849)\n",
      "  Top 23 | seg 06 | MSE 0.243218 (-0.025711)\n",
      "  Top 24 | seg 13 | MSE 0.246287 (-0.028780)\n",
      "  Top 25 | seg 10 | MSE 0.247131 (-0.029623)\n",
      "  Top 26 | seg 60 | MSE 0.249499 (-0.031992)\n",
      "  Top 27 | seg 49 | MSE 0.250088 (-0.032581)\n",
      "  Top 28 | seg 39 | MSE 0.251920 (-0.034412)\n",
      "  Top 29 | seg 01 | MSE 0.253880 (-0.036372)\n",
      "  Top 30 | seg 48 | MSE 0.254359 (-0.036852)\n",
      "  Top 31 | seg 31 | MSE 0.254709 (-0.037201)\n",
      "  Top 32 | seg 32 | MSE 0.254748 (-0.037240)\n",
      "  Top 33 | seg 51 | MSE 0.255399 (-0.037891)\n",
      "  Top 34 | seg 27 | MSE 0.257889 (-0.040381)\n",
      "  Top 35 | seg 54 | MSE 0.262209 (-0.044702)\n",
      "  Top 36 | seg 07 | MSE 0.265696 (-0.048189)\n",
      "  Top 37 | seg 16 | MSE 0.265824 (-0.048317)\n",
      "  Top 38 | seg 22 | MSE 0.266092 (-0.048584)\n",
      "  Top 39 | seg 18 | MSE 0.274669 (-0.057162)\n",
      "  Top 40 | seg 57 | MSE 0.276091 (-0.058583)\n",
      "  Top 41 | seg 50 | MSE 0.278498 (-0.060990)\n",
      "  Top 42 | seg 17 | MSE 0.281520 (-0.064013)\n",
      "  Top 43 | seg 37 | MSE 0.287874 (-0.070367)\n",
      "  Top 44 | seg 04 | MSE 0.290394 (-0.072886)\n",
      "  Top 45 | seg 52 | MSE 0.290570 (-0.073063)\n",
      "  Top 46 | seg 09 | MSE 0.301310 (-0.083803)\n",
      "  Top 47 | seg 12 | MSE 0.303377 (-0.085869)\n",
      "  Top 48 | seg 00 | MSE 0.315652 (-0.098145)\n",
      "  Top 49 | seg 19 | MSE 0.318403 (-0.100896)\n",
      "  Top 50 | seg 08 | MSE 0.320774 (-0.103266)\n",
      "  Top 51 | seg 23 | MSE 0.331957 (-0.114450)\n",
      "  Top 52 | seg 59 | MSE 0.333725 (-0.116217)\n",
      "  Top 53 | seg 29 | MSE 0.339772 (-0.122264)\n",
      "  Top 54 | seg 24 | MSE 0.343892 (-0.126385)\n",
      "  Top 55 | seg 38 | MSE 0.344959 (-0.127452)\n",
      "  Top 56 | seg 11 | MSE 0.347996 (-0.130489)\n",
      "  Top 57 | seg 26 | MSE 0.350541 (-0.133034)\n",
      "  Top 58 | seg 62 | MSE 0.367395 (-0.149888)\n",
      "  Top 59 | seg 30 | MSE 0.373911 (-0.156404)\n",
      "  Top 60 | seg 15 | MSE 0.376400 (-0.158893)\n",
      "  Top 61 | seg 03 | MSE 0.421521 (-0.204014)\n",
      "  Top 62 | seg 55 | MSE 0.425437 (-0.207930)\n",
      "  Top 63 | seg 36 | MSE 0.440052 (-0.222545)\n",
      "  Top 64 | seg 20 | MSE 0.450161 (-0.232654)\n",
      "  Top 65 | seg 14 | MSE 0.453122 (-0.235615)\n",
      "\n",
      "Saved top segment indices per channel:\n",
      "Channel 0: [61, 53, 2, 63, 42, 45, 56, 46, 40, 21, 47, 33, 58, 5, 25, 28, 41, 64, 34, 44, 43, 35, 6, 13, 10, 60, 49, 39, 1, 48, 31, 32, 51, 27, 54, 7, 16, 22, 18, 57, 50, 17, 37, 4, 52, 9, 12, 0, 19, 8, 23, 59, 29, 24, 38, 11, 26, 62, 30, 15, 3, 55, 36, 20, 14]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ──────────────────────────────────────────────\n",
    "# 0. 설정\n",
    "# ──────────────────────────────────────────────\n",
    "TOP_N       = 65\n",
    "SEG_CNT     = 65\n",
    "CH_CNT      = 1\n",
    "metric_idx  = 0          # (mse, mae, r2) 중 0 = MSE\n",
    "\n",
    "# ──────────────────────────────────────────────\n",
    "# 1. 증강 모델 MSE 테이블 수집 → (SEG_CNT, CH_CNT)\n",
    "# ──────────────────────────────────────────────\n",
    "mse_table = np.full((SEG_CNT, CH_CNT), np.inf)\n",
    "\n",
    "for seg in range(SEG_CNT):\n",
    "    if seg not in results2_ER_E1_val_1E:\n",
    "        continue\n",
    "    for ch in range(CH_CNT):\n",
    "        if ch in results2_ER_E1_val_1E[seg][\"metrics2_E1_val_1E\"]:\n",
    "            mse_table[seg, ch] = results2_ER_E1_val_1E[seg][\"metrics2_E1_val_1E\"][ch][metric_idx]\n",
    "\n",
    "# ──────────────────────────────────────────────\n",
    "# 2. 채널별 Top-N 인덱스 추출 & 저장\n",
    "# ──────────────────────────────────────────────\n",
    "print(\"\\n▶ Train-set  Per-Channel  Top-N  MSE\\n\")\n",
    "top_seg_idx_E1_val_1E = {}                       # ← 여기 저장\n",
    "\n",
    "for ch in range(CH_CNT):\n",
    "    print(f\"=== Channel {ch} ===\")\n",
    "    v_mse = results1_ER_val[1]['mse_val_E1']\n",
    "    print(f\"Vanilla MSE : {v_mse:.6f}\\n\")\n",
    "\n",
    "    # (seg, mse) 중 유효 값만 골라 MSE 오름차순\n",
    "    pairs = [(seg, mse_table[seg, ch]) for seg in range(SEG_CNT)\n",
    "             if np.isfinite(mse_table[seg, ch])]\n",
    "    top   = sorted(pairs, key=lambda x: x[1])[:TOP_N]\n",
    "\n",
    "    # ── 인덱스만 따로 저장 ─────────────────────\n",
    "    top_seg_idx_E1_val_1E[ch] = [seg for seg, _ in top]   # e.g. {0:[12,5,7,…], 1:[3,8,…]}\n",
    "\n",
    "    # ── 출력 ─────────────────────────────────\n",
    "    for rank, (seg_id, mse_val) in enumerate(top, 1):\n",
    "        delta = v_mse - mse_val\n",
    "        sign  = \"+\" if delta > 0 else \"-\"\n",
    "        print(f\"  Top {rank:2d} | seg {seg_id:02d} | MSE {mse_val:.6f} \"\n",
    "              f\"({sign}{abs(delta):.6f})\")\n",
    "    print()\n",
    "\n",
    "# ──────────────────────────────────────────────\n",
    "# 3. 확인\n",
    "# ──────────────────────────────────────────────\n",
    "print(\"Saved top segment indices per channel:\")\n",
    "for ch, seg_list in top_seg_idx_E1_val_1E.items():\n",
    "    print(f\"Channel {ch}: {seg_list}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75920cbd",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15005745",
   "metadata": {},
   "source": [
    "## ES->1E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e30a37df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Channel 0 ===\n",
      "[Vanilla]   MSE : 0.111791 | MAE : 0.255528\n",
      "  — Var / |Corr| / Score —\n",
      "   K= 5 | Var=1.253e-02 | |ρ|=0.9807 | S=0.9577 \n",
      "   K=10 | Var=1.466e-02 | |ρ|=0.9813 | S=1.0926 \n",
      "   K=15 | Var=1.721e-02 | |ρ|=0.9774 | S=0.9249 <- pick\n",
      "   K=20 | Var=1.740e-02 | |ρ|=0.9775 | S=0.9427 \n",
      "   K=25 | Var=1.851e-02 | |ρ|=0.9775 | S=0.9900 \n",
      "   K=30 | Var=1.839e-02 | |ρ|=0.9776 | S=0.9910 \n",
      "   K=35 | Var=1.849e-02 | |ρ|=0.9769 | S=0.9465 \n",
      "   K=40 | Var=1.947e-02 | |ρ|=0.9761 | S=0.9356 \n",
      "   K=45 | Var=2.089e-02 | |ρ|=0.9757 | S=0.9694 \n",
      "   K=50 | Var=2.181e-02 | |ρ|=0.9749 | S=0.9480 \n",
      "   K=55 | Var=2.388e-02 | |ρ|=0.9739 | S=0.9712 \n",
      "   K=60 | Var=2.759e-02 | |ρ|=0.9725 | S=1.0295 \n",
      "   K=65 | Var=3.548e-02 | |ρ|=0.9672 | S=1.0000 \n",
      "[Var-Corr]  K=15\n",
      "  MSE = 0.104257 | Δ = +0.007533 | Δ% = +6.74%\n",
      "  MAE = 0.245495 | Δ = +0.010033 | Δ% = +3.93%\n",
      "\n",
      "──────── Summary (Var-Corr) ───────\n",
      "Vanilla  mean MSE : 0.111791\n",
      "Ensemble mean MSE : 0.104257\n",
      "Average Δ MSE     : +0.007533\n",
      "Average Δ MSE (%) : +6.74%\n",
      "\n",
      "Vanilla  mean MAE : 0.255528\n",
      "Ensemble mean MAE : 0.245495\n",
      "Average Δ MAE     : +0.010033\n",
      "Average Δ MAE (%) : +3.93%\n"
     ]
    }
   ],
   "source": [
    "import torch, os, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "TOP_K    = 65\n",
    "CH_CNT   = 1\n",
    "batch_sz = 8\n",
    "\n",
    "def infer_one(model, loader, ch):\n",
    "    buf = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb, pv in loader:\n",
    "            xb, pv = xb.to(device), pv.to(device)\n",
    "            buf.append(model(xb, pv)[:, :, ch].cpu())   # [B,P]\n",
    "    return torch.cat(buf, 0)   # [N,P]\n",
    "\n",
    "\n",
    "van_mse_list, ens_mse_list, delta_mse_list, delta_mse_pct_list = [], [], [], []\n",
    "van_mae_list, ens_mae_list, delta_mae_list, delta_mae_pct_list = [], [], [], []\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 채널 루프\n",
    "# ─────────────────────────────────────────────\n",
    "for ch in range(CH_CNT):\n",
    "    print(f\"\\n=== Channel {ch} ===\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1) Vanilla MSE & MAE\n",
    "    # -----------------------------\n",
    "    v_mse = results1_ER_test['ES']['mse_test_EES']\n",
    "    v_mae = results1_ER_test['ES']['mae_test_EES']\n",
    "\n",
    "    print(f\"[Vanilla]   MSE : {v_mse:.6f} | MAE : {v_mae:.6f}\")\n",
    "\n",
    "    van_mse_list.append(v_mse)\n",
    "    van_mae_list.append(v_mae)\n",
    "\n",
    "    preds_test_arr = []\n",
    "    ok_segs = []\n",
    "\n",
    "    # ─────────────── Top-K 모델 로드 및 예측 ───────────────\n",
    "    for seg in top_seg_idx_ES_val_1E[ch][:TOP_K]:\n",
    "        ckpt = f\"./model2_ER_EES_1E/seg{seg}/ch{ch}/checkpoint.pth\"\n",
    "        if not os.path.exists(ckpt):\n",
    "            print(f\"  [skip] ckpt missing : seg{seg}\")\n",
    "            continue\n",
    "\n",
    "        pv_seg = test_pred_segments_ES[:, seg, :, :]\n",
    "        dl     = DataLoader(TensorDataset(test_sequences, test_labels, pv_seg),\n",
    "                            batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "        mdl = Model(base_cfg).to(device)\n",
    "        mdl.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "\n",
    "        preds_test_arr.append(infer_one(mdl, dl, ch))   # [N,P]\n",
    "        ok_segs.append(seg)\n",
    "\n",
    "    if len(preds_test_arr) < 5:\n",
    "        print(\"  Not enough valid models.\")\n",
    "        continue\n",
    "\n",
    "    # ─────────────────────────────────────────────\n",
    "    # Var / Corr 계산\n",
    "    # ─────────────────────────────────────────────\n",
    "    step = 5\n",
    "    Ks = list(range(step, len(preds_test_arr)+1, step))\n",
    "\n",
    "    var_list, rho_list = [], []\n",
    "\n",
    "    for K in Ks:\n",
    "        F = torch.stack(preds_test_arr[:K], dim=0)\n",
    "\n",
    "        V = torch.var(F, dim=0).mean().item()\n",
    "        var_list.append(V)\n",
    "\n",
    "        flat = F.reshape(K, -1).numpy()\n",
    "        corr = np.corrcoef(flat)\n",
    "        R = np.mean(np.abs(corr[np.triu_indices(K, 1)]))\n",
    "        rho_list.append(R)\n",
    "\n",
    "    # 정규화\n",
    "    V_min, V_max = min(var_list), max(var_list)\n",
    "    R_min, R_max = min(rho_list), max(rho_list)\n",
    "\n",
    "    V_norm = [(v - V_min)/(V_max - V_min + 1e-12) for v in var_list]\n",
    "    R_norm = [(r - R_min)/(R_max - R_min + 1e-12) for r in rho_list]\n",
    "\n",
    "    alpha, beta = 1, 1\n",
    "    scores = [alpha*v + beta*r for v, r in zip(V_norm, R_norm)]\n",
    "\n",
    "    best_K = Ks[int(np.argmin(scores))]\n",
    "\n",
    "    print(\"  — Var / |Corr| / Score —\")\n",
    "    for k, v, r, s in zip(Ks, var_list, rho_list, scores):\n",
    "        tag = \"<- pick\" if k == best_K else \"\"\n",
    "        print(f\"   K={k:2d} | Var={v:.3e} | |ρ|={r:.4f} | S={s:.4f} {tag}\")\n",
    "\n",
    "    # ─────────────────────────────────────────────\n",
    "    # Ensemble 결과 계산\n",
    "    # ─────────────────────────────────────────────\n",
    "    ens_pred = torch.mean(torch.stack(preds_test_arr[:best_K]), dim=0)\n",
    "    y_true   = test_labels[:, -base_cfg.pred_len:, ch].cpu()\n",
    "\n",
    "    mse_ens = torch.mean((ens_pred - y_true)**2).item()\n",
    "    mae_ens = torch.mean(torch.abs(ens_pred - y_true)).item()\n",
    "\n",
    "    ens_mse_list.append(mse_ens)\n",
    "    ens_mae_list.append(mae_ens)\n",
    "\n",
    "    # Δ (절대 변화량)\n",
    "    delta_mse = v_mse - mse_ens\n",
    "    delta_mae = v_mae - mae_ens\n",
    "\n",
    "    # Δ% (퍼센트 변화량)\n",
    "    delta_mse_pct = (delta_mse / v_mse) * 100\n",
    "    delta_mae_pct = (delta_mae / v_mae) * 100\n",
    "\n",
    "    delta_mse_list.append(delta_mse)\n",
    "    delta_mae_list.append(delta_mae)\n",
    "\n",
    "    delta_mse_pct_list.append(delta_mse_pct)\n",
    "    delta_mae_pct_list.append(delta_mae_pct)\n",
    "\n",
    "    print(f\"[Var-Corr]  K={best_K}\")\n",
    "    print(f\"  MSE = {mse_ens:.6f} | Δ = {delta_mse:+.6f} | Δ% = {delta_mse_pct:+.2f}%\")\n",
    "    print(f\"  MAE = {mae_ens:.6f} | Δ = {delta_mae:+.6f} | Δ% = {delta_mae_pct:+.2f}%\")\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# Summary\n",
    "# ─────────────────────────────────────────────\n",
    "if ens_mse_list:\n",
    "    print(\"\\n──────── Summary (Var-Corr) ───────\")\n",
    "    print(f\"Vanilla  mean MSE : {np.mean(van_mse_list):.6f}\")\n",
    "    print(f\"Ensemble mean MSE : {np.mean(ens_mse_list):.6f}\")\n",
    "    print(f\"Average Δ MSE     : {np.mean(delta_mse_list):+.6f}\")\n",
    "    print(f\"Average Δ MSE (%) : {np.mean(delta_mse_pct_list):+.2f}%\\n\")\n",
    "\n",
    "    print(f\"Vanilla  mean MAE : {np.mean(van_mae_list):.6f}\")\n",
    "    print(f\"Ensemble mean MAE : {np.mean(ens_mae_list):.6f}\")\n",
    "    print(f\"Average Δ MAE     : {np.mean(delta_mae_list):+.6f}\")\n",
    "    print(f\"Average Δ MAE (%) : {np.mean(delta_mae_pct_list):+.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8c7dbb",
   "metadata": {},
   "source": [
    "## 1E->1E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "238e7aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2555276155471802"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1_ER_test['ES']['mae_test_EES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a8a2d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Channel 0 ===\n",
      "[Vanilla]   MSE : 0.111791 | MAE : 0.255528\n",
      "  — Var / |Corr| / Score —\n",
      "   K= 5 | Var=1.413e-02 | |ρ|=0.9855 | S=1.1100 \n",
      "   K=10 | Var=1.379e-02 | |ρ|=0.9850 | S=1.0690 \n",
      "   K=15 | Var=1.458e-02 | |ρ|=0.9840 | S=1.0350 \n",
      "   K=20 | Var=1.618e-02 | |ρ|=0.9839 | S=1.0796 \n",
      "   K=25 | Var=1.904e-02 | |ρ|=0.9828 | S=1.0998 \n",
      "   K=30 | Var=2.141e-02 | |ρ|=0.9791 | S=0.9542 \n",
      "   K=35 | Var=2.361e-02 | |ρ|=0.9784 | S=0.9761 \n",
      "   K=40 | Var=2.537e-02 | |ρ|=0.9773 | S=0.9656 \n",
      "   K=45 | Var=2.832e-02 | |ρ|=0.9745 | S=0.8885 <- pick\n",
      "   K=50 | Var=3.193e-02 | |ρ|=0.9730 | S=0.9070 \n",
      "   K=55 | Var=3.586e-02 | |ρ|=0.9719 | S=0.9605 \n",
      "   K=60 | Var=4.062e-02 | |ρ|=0.9693 | S=0.9513 \n",
      "   K=65 | Var=4.715e-02 | |ρ|=0.9668 | S=1.0000 \n",
      "[Var-Corr]  K=45\n",
      "   MSE = 0.102114 | Δ = +0.009677 | Δ% = +8.66%\n",
      "   MAE = 0.245830 | Δ = +0.009697 | Δ% = +3.79%\n",
      "\n",
      "──────── Summary (Var-Corr) ───────\n",
      "Vanilla  mean MSE  : 0.111791\n",
      "Ensemble mean MSE  : 0.102114\n",
      "Average Δ MSE      : +0.009677\n",
      "Average Δ MSE (%)  : +8.66%\n",
      "\n",
      "Vanilla  mean MAE  : 0.255528\n",
      "Ensemble mean MAE  : 0.245830\n",
      "Average Δ MAE      : +0.009697\n",
      "Average Δ MAE (%)  : +3.79%\n"
     ]
    }
   ],
   "source": [
    "import torch, os, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "TOP_K    = 65\n",
    "CH_CNT   = 1\n",
    "batch_sz = 8\n",
    "\n",
    "def infer_one(model, loader, ch):\n",
    "    buf = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb, pv in loader:\n",
    "            xb, pv = xb.to(device), pv.to(device)\n",
    "            buf.append(model(xb, pv)[:, :, ch].cpu())   # [B,P]\n",
    "    return torch.cat(buf, 0)    # [N,P]\n",
    "\n",
    "\n",
    "# 저장 리스트\n",
    "van_mse_list, ens_mse_list, delta_mse_list, delta_mse_pct_list = [], [], [], []\n",
    "van_mae_list, ens_mae_list, delta_mae_list, delta_mae_pct_list = [], [], [], []\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 채널 루프\n",
    "# ─────────────────────────────────────────────\n",
    "for ch in range(CH_CNT):\n",
    "\n",
    "    print(f\"\\n=== Channel {ch} ===\")\n",
    "\n",
    "    # 1) Vanilla Scores\n",
    "    v_mse = results1_ER_test['ES']['mse_test_EES']\n",
    "    v_mae = results1_ER_test['ES']['mae_test_EES']\n",
    "\n",
    "    print(f\"[Vanilla]   MSE : {v_mse:.6f} | MAE : {v_mae:.6f}\")\n",
    "\n",
    "    van_mse_list.append(v_mse)\n",
    "    van_mae_list.append(v_mae)\n",
    "\n",
    "    preds_test_arr = []\n",
    "    ok_segs = []\n",
    "\n",
    "    # ─────────────────────────────────────────────\n",
    "    # Top-K 모델 로드\n",
    "    # ─────────────────────────────────────────────\n",
    "    for seg in top_seg_idx_E1_val_1E[ch][:TOP_K]:\n",
    "\n",
    "        ckpt = f\"./model2_ER_E1_1E/seg{seg}/ch{ch}/checkpoint.pth\"\n",
    "        if not os.path.exists(ckpt):\n",
    "            print(f\"  [skip] missing checkpoint : seg{seg}\")\n",
    "            continue\n",
    "\n",
    "        mdl = Model(base_cfg).to(device)\n",
    "        mdl.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "\n",
    "        pv_seg = test_pred_segments_E1[:, seg, :, :]\n",
    "        dl = DataLoader(\n",
    "            TensorDataset(test_sequences, test_labels, pv_seg),\n",
    "            batch_size=batch_sz, shuffle=False\n",
    "        )\n",
    "\n",
    "        preds_test_arr.append(infer_one(mdl, dl, ch))\n",
    "        ok_segs.append(seg)\n",
    "\n",
    "    if len(preds_test_arr) < 5:\n",
    "        print(\"  Not enough valid models.\")\n",
    "        continue\n",
    "\n",
    "    # ─────────────────────────────────────────────\n",
    "    # K 후보 (예: 5, 10, 15...)\n",
    "    # ─────────────────────────────────────────────\n",
    "    step = 5\n",
    "    Ks = list(range(step, len(preds_test_arr)+1, step))\n",
    "\n",
    "    var_list = []\n",
    "    rho_list = []\n",
    "\n",
    "    for K in Ks:\n",
    "        F = torch.stack(preds_test_arr[:K], dim=0)   # [K,N,P]\n",
    "\n",
    "        # 분산\n",
    "        V = torch.var(F, dim=0).mean().item()\n",
    "        var_list.append(V)\n",
    "\n",
    "        # 상관\n",
    "        flat = F.reshape(K, -1).numpy()\n",
    "        corr = np.corrcoef(flat)\n",
    "        R    = np.mean(np.abs(corr[np.triu_indices(K, 1)]))\n",
    "        rho_list.append(R)\n",
    "\n",
    "    # ─────────────────────────────────────────────\n",
    "    # 정규화\n",
    "    # ─────────────────────────────────────────────\n",
    "    V_min, V_max = min(var_list), max(var_list)\n",
    "    R_min, R_max = min(rho_list), max(rho_list)\n",
    "\n",
    "    V_norm = [(v - V_min) / (V_max - V_min + 1e-12) for v in var_list]\n",
    "    R_norm = [(r - R_min) / (R_max - R_min + 1e-12) for r in rho_list]\n",
    "\n",
    "    alpha, beta = 1, 1.1   # weight\n",
    "\n",
    "    scores = [alpha*v + beta*r for v, r in zip(V_norm, R_norm)]\n",
    "    best_K = Ks[int(np.argmin(scores))]\n",
    "\n",
    "    # ─────────────────────────────────────────────\n",
    "    # K Table 출력\n",
    "    # ─────────────────────────────────────────────\n",
    "    print(\"  — Var / |Corr| / Score —\")\n",
    "    for k, v, r, s in zip(Ks, var_list, rho_list, scores):\n",
    "        tag = \"<- pick\" if k == best_K else \"\"\n",
    "        print(f\"   K={k:2d} | Var={v:.3e} | |ρ|={r:.4f} | S={s:.4f} {tag}\")\n",
    "\n",
    "    # ─────────────────────────────────────────────\n",
    "    # 최종 Test Ensemble\n",
    "    # ─────────────────────────────────────────────\n",
    "    ens_pred = torch.mean(torch.stack(preds_test_arr[:best_K]), dim=0)  # [N,P]\n",
    "    y_true   = test_labels[:, -base_cfg.pred_len:, ch].cpu()\n",
    "\n",
    "    mse_ens = torch.mean((ens_pred - y_true)**2).item()\n",
    "    mae_ens = torch.mean(torch.abs(ens_pred - y_true)).item()\n",
    "\n",
    "    ens_mse_list.append(mse_ens)\n",
    "    ens_mae_list.append(mae_ens)\n",
    "\n",
    "    # Δ absolute\n",
    "    delta_mse = v_mse - mse_ens\n",
    "    delta_mae = v_mae - mae_ens\n",
    "\n",
    "    # Δ percent\n",
    "    delta_mse_pct = (delta_mse / v_mse) * 100\n",
    "    delta_mae_pct = (delta_mae / v_mae) * 100\n",
    "\n",
    "    delta_mse_list.append(delta_mse)\n",
    "    delta_mae_list.append(delta_mae)\n",
    "    delta_mse_pct_list.append(delta_mse_pct)\n",
    "    delta_mae_pct_list.append(delta_mae_pct)\n",
    "\n",
    "    sign = \"+\" if delta_mse > 0 else \"-\"\n",
    "    print(f\"[Var-Corr]  K={best_K}\")\n",
    "    print(f\"   MSE = {mse_ens:.6f} | Δ = {delta_mse:+.6f} | Δ% = {delta_mse_pct:+.2f}%\")\n",
    "    print(f\"   MAE = {mae_ens:.6f} | Δ = {delta_mae:+.6f} | Δ% = {delta_mae_pct:+.2f}%\")\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# Summary\n",
    "# ─────────────────────────────────────────────\n",
    "if ens_mse_list:\n",
    "    print(\"\\n──────── Summary (Var-Corr) ───────\")\n",
    "    print(f\"Vanilla  mean MSE  : {np.mean(van_mse_list):.6f}\")\n",
    "    print(f\"Ensemble mean MSE  : {np.mean(ens_mse_list):.6f}\")\n",
    "    print(f\"Average Δ MSE      : {np.mean(delta_mse_list):+.6f}\")\n",
    "    print(f\"Average Δ MSE (%)  : {np.mean(delta_mse_pct_list):+.2f}%\\n\")\n",
    "\n",
    "    print(f\"Vanilla  mean MAE  : {np.mean(van_mae_list):.6f}\")\n",
    "    print(f\"Ensemble mean MAE  : {np.mean(ens_mae_list):.6f}\")\n",
    "    print(f\"Average Δ MAE      : {np.mean(delta_mae_list):+.6f}\")\n",
    "    print(f\"Average Δ MAE (%)  : {np.mean(delta_mae_pct_list):+.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2349d0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sunho_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
